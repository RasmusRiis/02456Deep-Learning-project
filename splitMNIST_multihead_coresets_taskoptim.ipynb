{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VCL PYTORCH IMPL \n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------This class extends the Dataset class and basicly takes a Dataset [images,labels] and sort out the indexes with a specified sub_labels\n",
    "#------see how it it used later to make more sense of it.\n",
    "class SubDataset(Dataset): #FROM https://github.com/GMvandeVen/continual-learning/blob/master/data.py\n",
    "    '''To sub-sample a dataset, taking only those samples with label in [sub_labels].\n",
    "    After this selection of samples has been made, it is possible to transform the target-labels,\n",
    "    which can be useful when doing continual learning with fixed number of output units.'''\n",
    "\n",
    "    def __init__(self, original_dataset, sub_labels, target_transform=None):\n",
    "        super().__init__()\n",
    "        self.dataset = original_dataset\n",
    "        self.sub_indeces = []\n",
    "        for index in range(len(self.dataset)):\n",
    "            if hasattr(original_dataset, \"train_labels\"):\n",
    "                if self.dataset.target_transform is None:\n",
    "                    label = self.dataset.train_labels[index]\n",
    "                else:\n",
    "                    label = self.dataset.target_transform(self.dataset.train_labels[index])\n",
    "            elif hasattr(self.dataset, \"test_labels\"):\n",
    "                if self.dataset.target_transform is None:\n",
    "                    label = self.dataset.test_labels[index]\n",
    "                else:\n",
    "                    label = self.dataset.target_transform(self.dataset.test_labels[index])\n",
    "            else:\n",
    "                label = self.dataset[index][1]\n",
    "            if label in sub_labels:\n",
    "                self.sub_indeces.append(index)\n",
    "        self.target_transform = target_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ralle\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "n_tasks = 5 #one for each number\n",
    "classes_per_task = 2 #because n_task = 10\n",
    "\n",
    "\n",
    "# prepare permutation to shuffle label-ids (to create different class batches for each random seed)\n",
    "#permutation = np.random.permutation(list(range(10)))\n",
    "#--------WE ACTUALLY DONT DO THE ABOVE. we always want the tasks to be the same so no permutation.\n",
    "permutation = list(range(10))\n",
    "#print(\"random permutation of labels\",permutation)\n",
    "#Lambda transform is a user defined transform.\n",
    "#-------nothhing really happens here\n",
    "target_transform = transforms.Lambda(lambda y, x=permutation: int(permutation[y]))\n",
    "\n",
    "dataset_transform = transforms.Compose([transforms.ToTensor()])#A lambda transform to random permutation of pixels can be added here in the permutetMNIST\n",
    "\n",
    "#-------Here the entire MNIST dataset is loaded\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\"/\", train=True,\n",
    "                            download=True, transform=dataset_transform, target_transform=target_transform)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\"/\", train=False,\n",
    "                            download=True, transform=dataset_transform, target_transform=target_transform)\n",
    "\n",
    "#---------- generate labels-per-task. \n",
    "labels_per_task = [list(np.array(range(classes_per_task)) + classes_per_task * task_id) for task_id in range(n_tasks)]\n",
    "#print(labels_per_task)# [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n",
    "\n",
    "#----------- split them up into sub-tasks\n",
    "#-------we make a list where all sub dataset get put in.\n",
    "#HERE IS HOW WE take out one task data and labels. this is used in the training loop:\n",
    "#xtrain_set = train_datasets[task_no].dataset.data[train_datasets[task_no].sub_indeces]\n",
    "#ytrain_set = train_datasets[task_no].dataset.targets[train_datasets[task_no].sub_indeces]\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "for labels in labels_per_task:\n",
    "    #target_transform = transforms.Lambda(lambda y, x=labels[0]: y - x) if scenario=='domain' else None #We are Task-IL: task is given, is it 1 or not\n",
    "    target_transform = None\n",
    "    train_datasets.append(SubDataset(mnist_train, labels, target_transform=target_transform))\n",
    "    test_datasets.append(SubDataset(mnist_test, labels, target_transform=target_transform))\n",
    "    \n",
    "#train_datasets is a list of 5 tasks with the entire dataset in each.\n",
    "#Each task has the sub_indicies that is the indicies where the target value fits the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Gotta do some coresets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: /\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "Target transform: Lambda()\n",
      "12000\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is just BS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(train_datasets[1].dataset)\n",
    "print(len(train_datasets[1].sub_indeces))\n",
    "\n",
    "for i in range(20):\n",
    "    print(train_datasets[1].dataset.targets[train_datasets[1].sub_indeces[i]])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(1,5):\n",
    "    for j in range(1,5):\n",
    "        plt.subplot(4,4,(j-1)*4+i)\n",
    "        plt.imshow(train_datasets[3].dataset.data[train_datasets[3].sub_indeces[i*j]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(train_datasets[i].dataset.targets[train_datasets[i].sub_indeces]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_true(pred,y):\n",
    "    n = len(y)\n",
    "    prec=0\n",
    "    for i in range(n):\n",
    "        pred_index = torch.argmax(pred[i])\n",
    "        true_index = torch.argmax(y[i])\n",
    "        if  pred_index == true_index:\n",
    "            prec +=1\n",
    "    return prec\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####THE CORESET THING  ##inspired by paper\n",
    "def k_center(x_coreset, y_coreset, x_train, y_train, coreset_size):\n",
    "    # Select K centers from (x_train, y_train) and add to current coreset (x_coreset, y_coreset)\n",
    "    dists = np.full(x_train.shape[0], np.inf) #all dists are inf\n",
    "    current_id = 0\n",
    "    \n",
    "    for j in range(x_train.shape[0]):\n",
    "            current_dist = np.linalg.norm(x_train[j,:]-x_train[current_id,:])\n",
    "            dists[j] = np.minimum(current_dist, dists[j])\n",
    "            \n",
    "    idx = [ current_id ]\n",
    "\n",
    "    for i in range(1, coreset_size):\n",
    "        current_id = np.argmax(dists)\n",
    "        \n",
    "        for j in range(x_train.shape[0]):\n",
    "            current_dist = np.linalg.norm(x_train[j,:]-x_train[current_id,:])\n",
    "            dists[j] = np.minimum(current_dist, dists[j])\n",
    "        \n",
    "        idx.append(current_id)\n",
    "\n",
    "    x_coreset.append(x_train[idx,:])\n",
    "    y_coreset.append(y_train[idx])\n",
    "    x_train = np.delete(x_train, idx, axis=0)\n",
    "    y_train = np.delete(y_train, idx, axis=0)\n",
    "\n",
    "    return x_coreset, y_coreset, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (criterion): BCEWithLogitsLoss()\n",
      "  (hidden_w_mean): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 784x256]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 256x256]\n",
      "  )\n",
      "  (hidden_b_mean): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 256x1]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 256x1]\n",
      "  )\n",
      "  (hidden_w_var): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 784x256]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 256x256]\n",
      "  )\n",
      "  (hidden_b_var): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 256x1]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 256x1]\n",
      "  )\n",
      "  (out_layers_w_mean): ParameterList()\n",
      "  (out_layers_b_mean): ParameterList()\n",
      "  (out_layers_w_var): ParameterList()\n",
      "  (out_layers_b_var): ParameterList()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as tdist\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# FOR THE SPLITMNSIST MULTIHEAD PROBLEM\n",
    "input_size = 28*28 #size of images\n",
    "hidden_size = 256 #hidden layers size\n",
    "n_hidden_layers = 2\n",
    "output_size = 2\n",
    "n_tasks = n_tasks # also the number of heads\n",
    "init_var = 0   #This is the log(var) we use when we initiate layers. 0 works well with the other hyper parameters.\n",
    "init_var_hid = 0\n",
    "init_var_pri = 0 #Priors are initiated with this log(var)\n",
    "n_samples = 10 #The number of samples we take from the posterior distribution to sample a new weight to use when training\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        #Empty parameters to hold layers when these are added\n",
    "        \n",
    "        #notice that posteriors is Parameter list, so they get updated and priors is just a list.\n",
    "        #i may fuck this up when i add layers or something, but as long as the priors are not updated by the optimizer we are good\n",
    "        self.hidden_w_mean = torch.nn.ParameterList([])\n",
    "        self.hidden_b_mean = torch.nn.ParameterList([])\n",
    "        self.hidden_w_var = torch.nn.ParameterList([])\n",
    "        self.hidden_b_var = torch.nn.ParameterList([])\n",
    "\n",
    "        #And the priors\n",
    "        self.pri_hidden_w_mean = []\n",
    "        self.pri_hidden_b_mean = []\n",
    "        self.pri_hidden_w_var = []\n",
    "        self.pri_hidden_b_var = []\n",
    "\n",
    "        #initiating hidden layers. weights are initiatet with N(0,0.1)\n",
    "        for i in range(n_hidden_layers):\n",
    "            if i == 0:\n",
    "                inp_size = input_size\n",
    "            else:\n",
    "                inp_size = hidden_size\n",
    "            self.hidden_w_mean.append(torch.nn.Parameter(torch.randn(inp_size,hidden_size)*0.1, requires_grad=True))\n",
    "            self.hidden_b_mean.append(torch.nn.Parameter(torch.randn(hidden_size,1)*0.1, requires_grad=True))\n",
    "            self.hidden_w_var.append(torch.nn.Parameter(torch.ones(inp_size,hidden_size)*init_var_hid, requires_grad=True))\n",
    "            self.hidden_b_var.append(torch.nn.Parameter(torch.ones(hidden_size,1)*init_var_hid, requires_grad=True))\n",
    "\n",
    "            #And the priors\n",
    "            self.pri_hidden_w_mean.append(torch.zeros(inp_size,hidden_size))\n",
    "            self.pri_hidden_b_mean.append(torch.zeros(hidden_size,1))\n",
    "            self.pri_hidden_w_var.append(torch.ones(inp_size,hidden_size)*init_var_pri)\n",
    "            self.pri_hidden_b_var.append(torch.ones(hidden_size,1)*init_var_pri)\n",
    "\n",
    "       #Empty parameters to hold output layers when these are added in the add_task function. again \n",
    "        #priors will just be a list(or maybe not when we addtask() but it does not matter as long as they are not updated by optimizer)\n",
    "        self.out_layers_w_mean = torch.nn.ParameterList([])\n",
    "        self.out_layers_b_mean = torch.nn.ParameterList([])\n",
    "        self.out_layers_w_var = torch.nn.ParameterList([])\n",
    "        self.out_layers_b_var = torch.nn.ParameterList([])\n",
    "        \n",
    "        self.pri_out_layers_w_mean = None\n",
    "        self.pri_out_layers_b_mean = None\n",
    "        self.pri_out_layers_w_var = None\n",
    "        self.pri_out_layers_b_var = None\n",
    "        \n",
    "           \n",
    "    def forward(self, x, y, task_no, train=True):#y must be 1 of k encoded\n",
    "        #sample from posterior using the reparameterization trick\n",
    "        #from hidden layer\n",
    "        batch_size = x.shape[0] \n",
    "        \n",
    "        x = x.view(-1,input_size) #make it a vector\n",
    "        x = x/256\n",
    "        \n",
    "        for i in range(n_hidden_layers):\n",
    "            if train == False:   #if we are validating the network we just use the current mean of the weights. no need to sample\n",
    "                hidden_w = self.hidden_w_mean[i]\n",
    "                hidden_b = self.hidden_b_mean[i]\n",
    "            else:\n",
    "                with torch.no_grad(): #sample from N(0,1). nograd because of reparameterization trick. SEE TAHT WE take n_samples!\n",
    "                    inp_size,out_size = self.hidden_w_mean[i].size()\n",
    "                    hidden_w = torch.nn.Parameter(torch.randn(n_samples,inp_size,out_size))\n",
    "                    hidden_b = torch.nn.Parameter(torch.randn(n_samples,out_size,1))\n",
    "                \n",
    "                #WE MEAN THE SAMPLES AND generate weights from them\n",
    "                hidden_w = torch.add(self.hidden_w_mean[i],torch.mul(torch.mean(hidden_w,dim=0),torch.exp(0.5*self.hidden_w_var[i])))\n",
    "                hidden_b = torch.add(self.hidden_b_mean[i],torch.mul(torch.mean(hidden_b,dim=0),torch.exp(0.5*self.hidden_b_var[i])))\n",
    "            #then we put data through the layer. ReLU is shit when network is randomly initiatet, but sigmoid works well.(paper uses relu)\n",
    "            x = F.relu(torch.tensordot(torch.transpose(hidden_w,0,1),x,([1],[1]))+hidden_b)\n",
    "            x = torch.transpose(x,0,1)\n",
    "        \n",
    "        # WE DO the same thing as above with the output layer.\n",
    "        #here we chose the layer that maches the task_no\n",
    "        if train == False:\n",
    "            out_w = self.out_layers_w_mean[task_no]\n",
    "            out_b = self.out_layers_b_mean[task_no]\n",
    "        else:        \n",
    "            with torch.no_grad():\n",
    "                inp_size,out_size = self.out_layers_w_mean[task_no].size()\n",
    "                out_w = torch.nn.Parameter(torch.randn(n_samples,inp_size,out_size))\n",
    "                out_b = torch.nn.Parameter(torch.randn(n_samples,out_size,1))\n",
    "            out_w = torch.add(self.out_layers_w_mean[task_no],torch.mul(torch.mean(out_w,dim=0),torch.exp(0.5*self.out_layers_w_var[task_no])))\n",
    "            out_b = torch.add(self.out_layers_b_mean[task_no],torch.mul(torch.mean(out_b,dim=0),torch.exp(0.5*self.out_layers_b_var[task_no])))\n",
    "           \n",
    "        #predict\n",
    "        #print(\"x shape input\",x.shape)\n",
    "        \n",
    "        #print(\"x shape input after view\",x.shape)\n",
    "        #print(\"x shape after unsqueeze\",x.shape)\n",
    "        #print(\"x type\",x.type())\n",
    "        \n",
    "        #print(hidden_w.shape,x.shape,hidden_b.shape)\n",
    "        \n",
    "        x = torch.tensordot(torch.transpose(out_w,0,1),x,([1],[1]))+out_b\n",
    "        \n",
    "        #print(x.shape) # [2xbatch]\n",
    "        #x = torch.transpose(x,0,1)\n",
    "        #print(\"before softmax: \",x)\n",
    "        pred = x\n",
    "        #print(\"after softmax: \",pred)\n",
    "        pred = torch.transpose(pred, 0, 1)\n",
    "        #print(\"after softmax: \",pred)\n",
    "        #Eq*log(likelyhood)-Eq*KL(estimated_prior/prior)\n",
    "        \n",
    "        \n",
    "        # SEE THE loss function\n",
    "        loss, kl = self.calc_loss(pred,y,task_no,batch_size)\n",
    "        \n",
    "        \n",
    "        return pred, loss, kl\n",
    "            \n",
    "    def calc_loss(self,y,t,task_no,batch_size):#FROM EX 7.2:\n",
    "        # \n",
    "        \n",
    "        likelihood = self.criterion(y, t)\n",
    "        \n",
    "        kl = torch.tensor(0.)\n",
    "        \n",
    "        #For the KL loss i use the formula for two multivariate gaussians(but ours is just a single gaussian for each weight)\n",
    "        #for i in range(n_hidden_layers):\n",
    "        #    kl += torch.sum(0.5*(torch.exp(self.hidden_w_var[i]-self.pri_hidden_w_var[i]) + (self.pri_hidden_w_mean[i]-self.hidden_w_mean[i])**2/(torch.exp(self.pri_hidden_w_var[i]))-1+self.pri_hidden_w_var[i]-self.hidden_w_var[i]))\n",
    "        #    kl += torch.sum(0.5*(torch.exp(self.hidden_b_var[i]-self.pri_hidden_b_var[i]) + (self.pri_hidden_b_mean[i]-self.hidden_b_mean[i])**2/(torch.exp(self.pri_hidden_b_var[i]))-1+self.pri_hidden_b_var[i]-self.hidden_b_var[i]))\n",
    "        \n",
    "        ##also for output layers\n",
    "        #kl += torch.sum(0.5*(torch.exp(self.out_layers_w_var[task_no]-self.pri_out_layers_w_var[task_no]) + (self.pri_out_layers_w_mean[task_no]-self.out_layers_w_mean[task_no])**2/(torch.exp(self.pri_out_layers_w_var[task_no]))-1+self.pri_out_layers_w_var[task_no]-self.out_layers_w_var[task_no]))\n",
    "        #kl += torch.sum(0.5*(torch.exp(self.out_layers_b_var[task_no]-self.pri_out_layers_b_var[task_no]) + (self.pri_out_layers_b_mean[task_no]-self.out_layers_b_mean[task_no])**2/(torch.exp(self.pri_out_layers_b_var[task_no]))-1+self.pri_out_layers_b_var[task_no]-self.out_layers_b_var[task_no]))\n",
    "        #print(\"kl\",kl)\n",
    "        \n",
    "        ################THEIR KL ALGO\n",
    "        for i in range(n_hidden_layers):\n",
    "            if i == 0:\n",
    "                inp_size = input_size\n",
    "            else:\n",
    "                inp_size = hidden_size\n",
    "            const_term = -0.5 * hidden_size * inp_size\n",
    "            log_std_diff = 0.5 * torch.sum(self.pri_hidden_w_var[i] - self.hidden_w_var[i])\n",
    "            mu_diff_term = 0.5 * torch.sum((torch.exp(self.hidden_w_var[i]) + (self.pri_hidden_w_mean[i] - self.hidden_w_mean[i])**2) / torch.exp(self.pri_hidden_w_var[i]))\n",
    "            kl += const_term + log_std_diff + mu_diff_term\n",
    "            \n",
    "            const_term = -0.5 * hidden_size\n",
    "            log_std_diff = 0.5 * torch.sum(self.pri_hidden_b_var[i] - self.hidden_b_var[i])\n",
    "            mu_diff_term = 0.5 * torch.sum((torch.exp(self.hidden_b_var[i]) + (self.pri_hidden_b_mean[i] - self.hidden_b_mean[i])**2) / torch.exp(self.pri_hidden_b_var[i]))\n",
    "            kl += const_term + log_std_diff + mu_diff_term\n",
    "        \n",
    "        \n",
    "        const_term = -0.5 * hidden_size * output_size\n",
    "        log_std_diff = 0.5 * torch.sum(self.pri_out_layers_w_var[task_no] - self.out_layers_w_var[task_no])\n",
    "        mu_diff_term = 0.5 * torch.sum((torch.exp(self.out_layers_w_var[task_no]) + (self.pri_out_layers_w_mean[task_no] - self.out_layers_w_mean[task_no])**2) / torch.exp(self.pri_out_layers_w_var[task_no]))\n",
    "        kl += const_term + log_std_diff + mu_diff_term\n",
    "        \n",
    "        const_term = -0.5  * output_size\n",
    "        log_std_diff = 0.5 * torch.sum(self.pri_out_layers_b_var[task_no] - self.out_layers_b_var[task_no])\n",
    "        mu_diff_term = 0.5 * torch.sum((torch.exp(self.out_layers_b_var[task_no]) + (self.pri_out_layers_b_mean[task_no] - self.out_layers_b_mean[task_no])**2) / torch.exp(self.pri_out_layers_b_var[task_no]))\n",
    "        kl += const_term + log_std_diff + mu_diff_term\n",
    "        \n",
    "        kl = kl/batch_size\n",
    "        ############################\n",
    "\n",
    "        # Combining the two terms in the evidence lower bound objective (ELBO) \n",
    "        #I DONT KNOW IF THE KL needs some kind of scaling since we just added up for every weight in the network\n",
    "        ELBO = torch.add(likelihood, kl) ############################\n",
    "        \n",
    "        #print(\"elbo: \",likelihood, \"kl\", kl)\n",
    "        return ELBO, -kl\n",
    "    \n",
    "    def add_task(self):\n",
    "        if self.pri_out_layers_w_mean is None: #if we need to add the first output layer (initiates as the hidden layers)\n",
    "            self.out_layers_w_mean.append(torch.nn.Parameter(torch.randn(hidden_size,output_size)*0.1, requires_grad=True))\n",
    "            self.out_layers_b_mean.append(torch.nn.Parameter(torch.randn(output_size,1)*0.1, requires_grad=True))\n",
    "            self.out_layers_w_var.append(torch.nn.Parameter(torch.ones(hidden_size,output_size)*init_var, requires_grad=True))\n",
    "            self.out_layers_b_var.append(torch.nn.Parameter(torch.ones(output_size,1)*init_var, requires_grad=True))\n",
    "            \n",
    "            self.pri_out_layers_w_mean = [torch.nn.Parameter(torch.zeros(hidden_size,output_size), requires_grad=False)]\n",
    "            self.pri_out_layers_b_mean = [torch.nn.Parameter(torch.zeros(output_size,1), requires_grad=False)]\n",
    "            self.pri_out_layers_w_var = [torch.nn.Parameter(torch.ones(hidden_size,output_size)*init_var_pri, requires_grad=False)]\n",
    "            self.pri_out_layers_b_var = [torch.nn.Parameter(torch.ones(output_size,1)*init_var_pri, requires_grad=False)]\n",
    "            \n",
    "        else:#if it is not the first we initiate the means as the means for the prev layer, but the variance as we defined so we allow it to change more\n",
    "            self.out_layers_w_mean.append(torch.nn.Parameter(torch.randn(hidden_size,output_size)*0.1, requires_grad=True))\n",
    "            self.out_layers_b_mean.append(torch.nn.Parameter(torch.randn(output_size,1)*0.1, requires_grad=True))\n",
    "            self.out_layers_w_var.append(torch.nn.Parameter(torch.ones(hidden_size,output_size)*init_var, requires_grad=True))#initialize new head as the same as previous\n",
    "            self.out_layers_b_var.append(torch.nn.Parameter(torch.ones(output_size,1)*init_var, requires_grad=True))#initialize new head as the same as previous\n",
    "            \n",
    "            #self.out_layers_w_mean.append(torch.nn.Parameter(self.out_layers_w_mean[-1].clone().detach()))#initialize new head as the same as previous\n",
    "            #self.out_layers_b_mean.append(torch.nn.Parameter(self.out_layers_b_mean[-1].clone().detach()))#initialize new head as the same as previous\n",
    "            #self.out_layers_w_var.append(torch.nn.Parameter(self.out_layers_w_var[-1].clone().detach()))#initialize new head as the same as previous\n",
    "            #self.out_layers_b_var.append(torch.nn.Parameter(self.out_layers_b_var[-1].clone().detach()))#initialize new head as the same as previous\n",
    "            \n",
    "            #self.out_layers_w_var.append(torch.nn.Parameter(torch.ones(hidden_size,output_size)*init_var, requires_grad=True))\n",
    "            #self.out_layers_b_var.append(torch.nn.Parameter(torch.ones(output_size,1)*init_var, requires_grad=True))\n",
    "            \n",
    "            #AND THE priors as always:\n",
    "            self.pri_out_layers_w_mean.append(torch.nn.Parameter(torch.zeros(hidden_size,output_size), requires_grad=False))\n",
    "            self.pri_out_layers_b_mean.append(torch.nn.Parameter(torch.zeros(output_size,1), requires_grad=False))\n",
    "            self.pri_out_layers_w_var.append(torch.nn.Parameter(torch.ones(hidden_size,output_size)*init_var_pri, requires_grad=False))\n",
    "            self.pri_out_layers_b_var.append(torch.nn.Parameter(torch.ones(output_size,1)*init_var_pri, requires_grad=False))\n",
    "            \n",
    "            #self.pri_out_layers_w_mean.append(self.pri_out_layers_w_mean[-1])\n",
    "            #self.pri_out_layers_b_mean.append(self.pri_out_layers_b_mean[-1])\n",
    "            #self.pri_out_layers_w_var.append(self.pri_out_layers_w_var[-1])\n",
    "            #self.pri_out_layers_b_var.append(self.pri_out_layers_b_var[-1])\n",
    "            \n",
    "    def update_prior(self,task_no):#call before backward and after forward so we have used the old ones to get loss but copy the old posterior before it is updated in backward\n",
    "        for i in range(n_hidden_layers):# just copies the current mean and var into the priors in a weird way to make shure they requires grad =False\n",
    "            self.pri_hidden_w_mean[i] = self.hidden_w_mean[i].clone().detach()\n",
    "            self.pri_hidden_b_mean[i] = self.hidden_b_mean[i].clone().detach()\n",
    "            self.pri_hidden_w_var[i] = self.hidden_w_var[i].clone().detach()\n",
    "            self.pri_hidden_b_var[i] = self.hidden_b_var[i].clone().detach()\n",
    "\n",
    "            self.pri_hidden_w_mean[i].requires_grad = False\n",
    "            self.pri_hidden_b_mean[i].requires_grad = False\n",
    "            self.pri_hidden_w_var[i].requires_grad = False\n",
    "            self.pri_hidden_b_var[i].requires_grad = False\n",
    "\n",
    "        self.pri_out_layers_w_mean[task_no] = self.out_layers_w_mean[task_no].clone().detach()\n",
    "        self.pri_out_layers_b_mean[task_no] = self.out_layers_b_mean[task_no].clone().detach()\n",
    "        self.pri_out_layers_w_var[task_no] = self.out_layers_w_var[task_no].clone().detach()\n",
    "        self.pri_out_layers_b_var[task_no] = self.out_layers_b_var[task_no].clone().detach()\n",
    "            \n",
    "        self.pri_out_layers_w_mean[task_no].requires_grad = False\n",
    "        self.pri_out_layers_b_mean[task_no].requires_grad = False\n",
    "        self.pri_out_layers_w_var[task_no].requires_grad = False\n",
    "        self.pri_out_layers_b_var[task_no].requires_grad = False\n",
    "    \n",
    "    def reset_var_and_priors(self): #This only resets the first output layer\n",
    "        print(init_var_hid,init_var,init_var_pri)\n",
    "        for i in range(n_hidden_layers):\n",
    "            if i == 0:\n",
    "                inp_size = input_size\n",
    "            else:\n",
    "                inp_size = hidden_size\n",
    "            self.hidden_w_var[i] = torch.nn.Parameter(torch.ones(inp_size,hidden_size)*init_var_hid, requires_grad=True)\n",
    "            self.hidden_b_var[i] = torch.nn.Parameter(torch.ones(hidden_size,1)*init_var_hid, requires_grad=True)\n",
    "            \n",
    "            self.pri_hidden_w_mean[i] = self.hidden_w_mean[i].clone().detach()\n",
    "            self.pri_hidden_b_mean[i]= self.hidden_b_mean[i].clone().detach()\n",
    "            self.pri_hidden_w_mean[i].requires_grad = False\n",
    "            self.pri_hidden_b_mean[i].requires_grad = False\n",
    "            \n",
    "            self.pri_hidden_w_var[i] = torch.ones(inp_size,hidden_size)*init_var_pri\n",
    "            self.pri_hidden_b_var[i] = torch.ones(hidden_size,1)*init_var_pri\n",
    "\n",
    "            \n",
    "        \n",
    "        self.out_layers_w_var[0] = torch.nn.Parameter(torch.ones(hidden_size,output_size)*init_var, requires_grad=True)\n",
    "        self.out_layers_b_var[0] = torch.nn.Parameter(torch.ones(output_size,1)*init_var, requires_grad=True)\n",
    "        \n",
    "        self.pri_out_layers_w_mean[0] = self.out_layers_w_mean[0].clone().detach()\n",
    "        self.pri_out_layers_b_mean[0] = self.out_layers_b_mean[0].clone().detach()\n",
    "        self.pri_out_layers_w_mean[0].requires_grad = False\n",
    "        self.pri_out_layers_b_mean[0].requires_grad = False\n",
    "        \n",
    "        self.pri_out_layers_w_var[0] = torch.nn.Parameter(torch.ones(hidden_size,output_size)*init_var_pri, requires_grad=False)\n",
    "        self.pri_out_layers_b_var[0] = torch.nn.Parameter(torch.ones(output_size,1)*init_var_pri, requires_grad=False)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1]) [tensor(1), tensor(0)]\n"
     ]
    }
   ],
   "source": [
    "a = [0,1]\n",
    "a =torch.tensor(a)\n",
    "print([a][0],list(reversed(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_optimal_class_thing(x_data_from,y_data_from, x_data_to,y_data_to,n_samples_per_class):\n",
    "    #the two classes in the new set does not need dist to each other\n",
    "    #use k center to take out data_points from new set\n",
    "    #x must be split into each class\n",
    "    unique_classes_from = np.unique(np.array(y_data_from))\n",
    "    unique_classes_to = np.unique(np.array(y_data_to))\n",
    "    coreset_1_from_idx = []\n",
    "    coreset_2_from_idx = []\n",
    "    coreset_1_to_idx = []\n",
    "    coreset_2_to_idx = []\n",
    "    for i in range(len(y_data_from)):\n",
    "        if y_data_from[i] == unique_classes_from[0]:\n",
    "            coreset_1_from_idx.append(i)\n",
    "        elif y_data_from[i] == unique_classes_from[1]:\n",
    "            coreset_2_from_idx.append(i)\n",
    "    for i in range(len(y_data_to)):\n",
    "        if y_data_to[i] == unique_classes_to[0]:\n",
    "            coreset_1_to_idx.append(i)\n",
    "        elif y_data_to[i] == unique_classes_to[1]:\n",
    "            coreset_2_to_idx.append(i)\n",
    "            \n",
    "    x1_from ,_ ,_ ,_ = k_center([], [], x_data_from[coreset_1_from_idx], y_data_from[coreset_1_from_idx], n_samples_per_class)\n",
    "    x2_from ,_ ,_ ,_ = k_center([], [], x_data_from[coreset_2_from_idx], y_data_from[coreset_2_from_idx], n_samples_per_class)\n",
    "    x1_to ,_ ,_ ,_ = k_center([], [], x_data_to[coreset_1_to_idx], y_data_to[coreset_1_to_idx], n_samples_per_class)\n",
    "    x2_to ,_ ,_ ,_ = k_center([], [], x_data_to[coreset_2_to_idx], y_data_to[coreset_2_to_idx], n_samples_per_class)\n",
    "        \n",
    "    #Now get distance from from1 and 2 to to1 and 2\n",
    "    dist11=0\n",
    "    dist12=0\n",
    "    dist21=0\n",
    "    dist22=0\n",
    "    for i in range(n_samples_per_class):  \n",
    "        for j in range(n_samples_per_class):\n",
    "            dist11 += (np.linalg.norm(x1_from[0][i,:]-x1_to[0][j,:]))/(n_samples_per_class*n_samples_per_class)\n",
    "            dist12 += (np.linalg.norm(x1_from[0][i,:]-x2_to[0][j,:]))/(n_samples_per_class*n_samples_per_class)\n",
    "            dist21 += (np.linalg.norm(x2_from[0][i,:]-x1_to[0][j,:]))/(n_samples_per_class*n_samples_per_class)\n",
    "            dist22 += (np.linalg.norm(x2_from[0][i,:]-x2_to[0][j,:]))/(n_samples_per_class*n_samples_per_class)\n",
    "    \n",
    "    min_dist = np.argmin([dist11+dist22, dist12+dist21])\n",
    "    \n",
    "    if min_dist == 0 or min_dist == 3:\n",
    "        return unique_classes_from, unique_classes_to\n",
    "    else:\n",
    "        return list(reversed(unique_classes_from)), unique_classes_to\n",
    "    return \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2, 3], dtype=int64), array([0, 1], dtype=int64))\n",
      "(array([4, 5], dtype=int64), array([0, 1], dtype=int64))\n",
      "(array([6, 7], dtype=int64), array([0, 1], dtype=int64))\n",
      "(array([8, 9], dtype=int64), array([0, 1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#This code finds a hopefully better way to arange classes measured in relation to 0 and 1\n",
    "for i in range(1,5):\n",
    "    print(the_optimal_class_thing(train_datasets[i].dataset.data[train_datasets[i].sub_indeces], train_datasets[i].dataset.targets[train_datasets[i].sub_indeces],train_datasets[0].dataset.data[train_datasets[0].sub_indeces],train_datasets[0].dataset.targets[train_datasets[0].sub_indeces], 100))\n",
    "#for MNIST compared to task1\n",
    "#0 1\n",
    "#3 2\n",
    "#4 5\n",
    "#7 6\n",
    "#9 8\n",
    "#for fashion compared to task1\n",
    "#no change\n",
    "#for fashion compared to task i-1\n",
    "#0,1\n",
    "#2,3\n",
    "#4,5\n",
    "#7,6\n",
    "#9,8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAD8CAYAAABjNPKeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xmcm2XV//HPSWbfO0un0073hbaUQqG0lK1lX2QHFRAFVFAQRB5R8ZGfIm6P6+OGSx9FZFFAUAStIBawgCxtKS3d92Vm2s60M519yXL9/kgyzUy3TJs2Teb7fr36apL7TuaayZ3k5NznOpc55xARERERkb3zJHoAIiIiIiJHMwXMIiIiIiL7oYBZRERERGQ/FDCLiIiIiOyHAmYRERERkf1QwCwiIiIish8KmEVERERE9kMBs4iIiIjIfhwwYDazh8ys1syW7mO7mdlPzWytmS0xsxOjtt1oZmvC/26M58BFRERERI4EO9BKf2Z2JtACPOKcm7SX7RcDdwIXA9OBnzjnpptZMbAAmAo4YCFwknOuYX8/r7S01I0YMeIgfhURERERkdgtXLhwh3Ou7ED7pR1oB+fcPDMbsZ9dLicUTDvgLTMrMrMKYBbwknOuHsDMXgIuBP64v583YsQIFixYcKBhiYiIiIgcEjPbFMt+8ahhHgJsibpeFb5tX7fvwcxuNbMFZragrq4uDkMSEREREYmPeATMtpfb3H5u3/NG52Y756Y656aWlR0wKy4iIiIicsTEI2CuAoZGXa8EavZzu4iIiIhI0ohHwPwc8LFwt4xTgEbn3FbgReB8MxtgZgOA88O3iYiIiIgkjQNO+jOzPxKawFdqZlXA14B0AOfcr4A5hDpkrAXagJvD2+rN7BvA/PBDPRCZACgiIiIikixi6ZJx3QG2O+Az+9j2EPDQwQ1NRERERCTxtNKfiIiIiMh+KGCWpNfW5eextzaxvakj0UMRERGRFHTAkgyRfWnr8tPS6WdgftZ+9/MFgmyub2N0WR4Anf4AizbvIhB05GelMaGigEWbd/Helgb+8PZm0rwefv/xaQwpygZgxdYm7n7yPZrafWRlePnmFZM4dXQpAM0dPi752ets2tnG429v5pnbZpCTsedh7Zzj4w/P56oTK7n0+MFx/kuIiIhIKlPALH322po6llY38df3qqlr7uSVL8yiICuddzbU88Q7mxk9MI/bZ43GLNSK+5t/W87v39zEGWNLKcnNYHFVIxt2tHY/XkluBjtbuwCYPrKYBZsaePTNTdx70XjqW7u45ZEFdPqDzBpXxjsb67ntsXeZc9cZDCnK5i+Lqtm0s407zhrDL15dy91PvsfQATnsaOkEwOMxPnrKcNp9AV5ZVcfKbc0KmEVERKRPFDBLn937zPtU72rHYxB08KtX13HViUP4+MPzMeDPi6rp8AX4r/PGsWFHK4+/vZlJQwqobmhnc30bRTkZ/Pz6KQzMz+K9LQ3MeX8b910ygXHl+UysKOBTjy7kTwu28NlzxnD74wupbe7kT5+awfFDi9i4o5Wzf/gqT76zmbvPG8djb23iuCGF3HPBMRRkp/HtOStJ9xqDw9np+tYuXl5Zy9iBoez2GWNLE/iXExERkWSkgFn20NLpZ1tjB0OKsvF4wDnISvcCsGZ7M9W72rns+MFcc1Ilf1lUzW9f38Arq+rITPPw/J2n88N/ruZnL69lwcYGmjt9ZKV7+d1N0yjLz9zjZ00bWcytZ47ucdvHZozgn8u3c8Nv3ubdzbv44QeP5/ihRQCMKM1l2shi5izdxhnjyli9vYXvXn0cALecMYrygiwmDSnsLv/YtLOVq3/5H+ZvbAAgI01l+yIiItI3CphTRDDo+POiamYdU8a/lm/nuMpCjh1cuMd+f363isoBOUwbWQxAIOh4ZmEV63a0AODzO555t4rGdh+leZk45xhbnscTt84A4B9LtwHwlQ9MoLwgi5Glufx9yVZWbG3i21cex+CibL53zWROHF7Ed/+xkuZOP7M/OnWvwfK+nDamhGkji3lnQz2nji7hqhOH9Nh+8XEVfPWvy/jm31eQn5XWXWJhZlx+Qs99h5fk8vqXzqap3cfFP32N4F4XZxcRERHZNwXMSWx9XQt3P/ked549ljZfgHv+tJgRJTls3NmGx6AsP5NPnj6Kfy7fxjGD8inPz+KHL60GQnXDZtDpD9Lc4ScjzYOFH3fqiAFcOaWSP76zmeqGdt5aX8+ymkZGluby6FubmDGqhPKC0ES/ocU5fP78cby+dgcfmloJgNdjfGT6cC48dhBVDe3d2eFYmRlfvWQi9/xpMV/5wITuWuiIiyZV8KOXVrN4yy5uOnXEXif5RctK95KV7sVjRqhtuIiISGoLBB3bmjrwmhFwjrZOP7mZaZQXZOH1GMGgY3VtM6u2NdPU7gNCn5cleRkYPT93M9I8lOZlkpXuYVBhFplp3u5tXf4gq7c3U9fSSacvyIYdrazZ3kxZfiZDi3M4cdgAxpXnsa2pg4rCbLweo8MXIBj+PPYHHbVNHZTlZVGYk37k/kB9ZEdbADF16lS3YMGCRA8j4ZxzPQLFnS2d/HTuGi6fMoQThw2grcvPpT97nXV1reRkeMnJSKOxvQtfwDG6LJdLJg9m3po6Fm3eRbrXCAQdQQdnjivj1NElbKlv637s08eUcuGkQXsEpgC72rqY/u25zDqmjPKCLB55cxPP3DaDk4YXH5G/w77UNnfw5DtbuHbasJiz19O//S/OOmYg/3P15MM8OhGR5BEMOtp9AQAy0zykeT0Eg46tTR3sDE+gjmjp8NPU4cc5x/odreRnpdHhC3DKqBKGl+SS5gl9jqR5rUdQtT8dvgCdviDVu9rxB4MAGEZFURZ5mWndJYH9nXOOtbUtPP72ZnyBIJUDcjh2cAHlBVl0+YM8t7iaqoZ2drZ20d4VYMOOVlo6/Xs8TprHyM9Ko7UzQFcg2OdxpHuNMQPzSfeGAt/N9W10+Ho+zqCCLOrbuujyh273ekJxSHa6lzSv0dyx57h+/OETuGLKkD1uP9zMbKFzbuqB9lOG+Sj02po6PvXoQm44ZTh3nTMWgNsee5d3NtbzyFub+N1NJ/N+VSPr6lr50YeO5+mFVTR3+PnJtSfwh7c3c+OpI5g2sphbzhzFPU8t5pLjK5gybAA7WzqZWFFAmjf2Ot6inAw+PXM0P5m7BoDrpw9LeLAMMDA/izvDf5tYecy6v9GKiKQy5xwrtzVT19zJ9qYO1u9oZUNdK82dPpyDnS1dNLb7cDga2nzdgU2axyjJy6Cp3d8dRB+s0rwM0jy7P2+8HmNIUTbpaUaXP0jNrg46fIHuLkn78tBNUzl7fPkhjeVo19juY2l1I3mZaWSm9/yMzs1I45VVtfzmtQ1srm8jM81DdoaXXW2+HvuleYyRpbkU5aRTmpfB5HBpZtA5PBYKkps6fFQ3tNPc4Scn08vYgflMrixkQE7orHNrp5+GXo8LoTay9eFAfG1tC2tqW3DOke71cMbYMqYMK6KiMJvMNA+VA7IpyskgGHRU72pn/sZ6Vm1rZsiAbDbsaCUYdJTlZ5IejkXMQp/pJ49MfGyxP8owH0Wcc6yra+H2x99l664Omjv9lOZlhN7cWrv4zlXHMXveeoLOsbOli9PGlPDrjx7wS1FcvLOhnk5/gDPGlh2Rn3c4nPY/LzNjdAk/+ODxiR6KiMSZLxBk5dZmfvnvtVx8XAWXTO4f7SNbOv08s7CKl5ZvZ2drF7VNHbR2+Qk6uoNgCAVTw0pyKM7JAKAoJ53i3NCp94LsNErzMjGDhjYf9S1d5GamMaosl0EFWUSffMxO95KXlYYvEGRceT6tnQE8Bu9srGfrrg4coZiivSvItqZ2glGJx65AKIscDDq8nlA3o6x0L4MLs8jO8FJRmE1WOFj0Bx3Lqhv56ctr+fplx3LjqSMO+9/ySHHO0dTup2pXG5t2tvHyylqeXVSN/wCTbE4YWsTVJw7hwkkVlOVn0tThY8mWRpo6QgHu8UOLutcvkNgpw5xkaps6+OwTi3hrfT0Av/jIiZQXZPLQ6xvB4OOnjeSk4QMoyk7ntsffZWRpLl+5eOIRG9+0o/ybXyzMUIZZJAV1+YNc8rPXWL09NHn59TU7mDGqhJK82CcbHy2cc9Q0dvDWup20dPqpaWynvSvA1sYOuvxBgs5Rs6udTn8Q52B7Uwf+oGNceR7DinM4YWghBVmhOtDRZXmMKsulODeDocU53Rm9eMoP/6zD8QVl+shifvry2pR5395S38bPX17Li8u39cgOZ6d7uX76MM6bWE6HL4g/qkwi6KC+rYvJQwqZXFnYo3SyICud09Uq9YhRwHyEzVtdx7fnrODOs8fygckVdPmDvLFuBz9+aTVralu47wMTmDJsACcNHwCwR/nDRcdV8OxnTmNCRX7M9WESYgakxvuuiESZu2I7q7e38F/njeOUUSVc/39vcdUv/8Pd547j8hMG73V+xuEQDDre2rCTFVubSfMYr66qZWlNE0OKshlWnEN2upeKoizSvR7SPEZpXiZ1LZ0Egg5fIMja2hZeX7ujRzCVkeYhKy000So7Iw0Dxg7MJycz9P4/qCCLcyeWc+KwAUfkdzySIs9bIInbGwWCjrkrtvPY25t5a/1OvGZcNGkQEyoKGDIgm8oB2YwfVKCWp0lAAfMR9ux71azc1sxn/vAu7b7j+ffqOp5fXIPH4Fc3nMT5xw464GOc0MeuExKiGmaR1PTkgi0MKsjiM2eNwesxfnPjVH7wz1V87sn3WFrdyH2XHN6zcc0dPuat3sHs19azeMuu7tuHFmdzxphStjZ28N6WXbT7AtQ1d+7zcSoKszhnfDnHDSnglNEllOZlUpyTgcdzZAL+o403/Hsn29t2e1eAp9+t4uUV21lW00RtcyeVA7K5ftowbj1zVPfCWpJcFDAfYQs3NXDWMWW0doXawAF89uwxXDd9GBWFehEdTqGAOdGjkCMtEHR0+AJUNbRTOSCb3Ey97aWS+Rvr+ffqOu4MB8sAs44ZyJljy/jSM0v43X82cv30YYwKL2Z0KFo6/ayva6GuuZOqhnZWbG2ielc7b63fiS/gGJifyfevmczMcWV0+oNUDsjeI7vtC4TKKrr8QWqbOxmYn0lGmgeP2WEpmUhmke8JgSSKmN9Yu4MvPbOEqoZ2RpXlcvLIYi6eVMEFx5b3acK9HH1i+uQwswuBnwBe4DfOuf/ptX048BBQBtQDNzjnqsLbvgd8APAALwF3uaNtpuERUtvcwaadbdwwfTgfOnkof1+ylaKcdC7aR0s3iS/VMPdPV/3iDRZXNQJQOSCbh246mXHl+QkeVXxF3lIDwVCrr6XVjT3aSVUUZjO5srC7f3qqcM7x5T+/z+DCbD41s+eKoR6P8cULxzPn/a3c9Lv5/OhDxzN1RN/nYrR2+lmwqYHf/2cjL6+s7bGtNC+D4twMbj5tJOdOKOek4QO6g/Z9iQTFmWne7vpf2TtP+HMx+n27yx/kql++gceML104ntPGHB01vB2+AP/zj5U8/J+NjCrL5Q+3TGfGqBJ9tqeQAwbMZuYFHgTOA6qA+Wb2nHNuedRuPwAecc793szOBr4DfNTMTgVOAyKNb18HZgKvxu9XSB4Lw8szTx0xgMLsdK6fPizBI+pfjOQ7tSeHxjnH+9WN5Gemce/F4/nxv9Zw22ML+cddZyZNzeCW+jbaugKhLhDbmlmxtYlOfwB/IBQct3T42bCjNaYWYBMqCrho0iBmHVPG5Moi6po72dHSyRtrd/DG2h04YEhRdmiS2IAceq1dQF1zJ1sb27tbkg0vySU6aZad7qU0L5OqhnY27mxl4aYGhhXnkJHmoaXTT3VDO+PK8xk/KJ/MdA/tXUFqdrVz1vgyjq8soqaxnbrmTl5dVUdFYTbHDMpjW2MnrZ1+1u9oocsfZHhJqG3WjFElnDq6lLW1Ldx70fi9njkoy8/kdzdP454/Lebmh+fzl9tPY8zA2DLNdc2dPLe4hl//ex21zZ3kZni546wxTBpSwKDCbAbkpDO8JDemx5KD0x0wR50afHnldpZWN1Gal8GnHl3IE7eewqQhe65qe6T4A0FeXLadH720inV1rdx06gjuvWi8ekenoFgyzNOAtc659QBm9gRwORAdME8E7g5ffgV4NnzZAVlABqG33nRg+6EPOzn8acEWZs9bz5cvHs/Z48tZvrUJr8f2umS1HH4es+6WR9I/tPsCBB185uwxfGT6cAYXZnPzw/P5/J8W88ULjmFocU6ih9jDtsYOHn97E7vafKzf0cKO5i5WbW/usU9WuofcjDTMQku/DyrMYtrIYorCK2QNHZDD5MpCinND7cOCDjbXt7Jo8y7++l4NP3ppNT96aTUZaZ4ebcfGDszD6zHer2pkV7tvnxOtBuSkU5gd+vfPZdt6bGvp9NPpD1KYnc6AnHQuP2EItU0dBJ2jojCLM8eWsaa2mVdX1xEMOtK8RlF2Bt+es7LH44wdmMfq7c08824V2elecjPTGFmaQ0F2Ogs3NdDY7uORNzdx26xQVnngfhYvmjaymMc/OZ3LH3yDKx58g4/OGM51Jw9jWMnen/tdbV388Z0t/OKVtTR3+jlhaBHfu2YyU4aFEh1y5ESy9dGH4tMLqxmYn8kzt53KNb/6D1c8+AaXHj+Yj80YzpQjPPExEHTc9eR7/H3JVoYUZfPoJ6YldetV2b9YAuYhwJao61XA9F77LAauJlS2cSWQb2Ylzrk3zewVYCuhgPnnzrkVhz7so49zoZX0ok/HPfTGRtbUtvDpx95lydfOZ9PONgYXZSVNZivVeMx69ASV1BfpNlAUDnTOGj+QT80cxe9e38irq2r59Q0ncWqCTukurW7k+cU1rN7eHK6NbaWpIxSohnrg5jGwIJMPTq1kcFE2Hou0Ccs74Gn/3sryMzlpeDGfPGMUjW0+/vZ+DZvr2xiYn8WggizGDMzjmEG7y1TauwLsbN1zclp+Vvp+g0Z/IEhzh58B4WA9Vlvq21hb28LQ4mzys9IpL8jCudCCGkXZ6XtMegsEHZPvf5HX1tQBUHqA9nFDi3N49vbTeOBvy5k9bz1Pzd/CY5+czoSKAjr9ARpafdQ1d/Kreet4Yek2AkHHrGPK+O+LJ6Rc+U4y6a5hDkfM/kCQV1fV8rEZIxhanMMLd53Jj/+1mj8vquYvi6q5+9xx3HVu3xa0OhjBoOM3r6/nV/9eT31rF1+88Bg+deboPr8uJbnEEjDv7QjonXq4B/i5md0EzAOqAb+ZjQEmAJXh/V4yszOdc/N6/ACzW4FbAYYNS84yhf99aTWvrKrj+TtPB0IfACu2NjG5spAlVY1s2NHKpvo2hhfrFF6iqIa5/+kOmHN2B3lfvmgCN0wfzs0Pz+fup97j1XvOIjvj8J8+dc6xvamTJVW7ePa9aua8v40Mr4cxA/PIy0zjvInlFGan85Hpw/eZ/YyHwpzQz9if7AwvlRl9H0Oa19PnYBlCAW3vbL+ZdWfJe/N6jPLCLFZvC/VdLsk78M8cVpLDb26cytraFj786ze56CevMaQom4a2Ltq6di8L/YnTR3LFCUOYOLigz7+HxJeZ9Xjf7goE8QcdAwtCX5AG5Gbw9csn8cULx/OFpxfz81fWcNkJgxlZeng/Z781ZwW/fX0DM8eVce3JQ7nouIrD+vPk6BBLwFwFDI26XgnURO/gnKsBrgIwszzgaudcYzgQfss51xLe9g/gFEJBdfT9ZwOzIbTS38H9Kon1XlUj71c30uELkJXu5YWloVOVd549llseWcCa2hY272zVCyuBTF0y+p3G9lDAXNArKzq0OIdvX3kcH/r1m9z95HtcO20oZ4wtOywZorW1zTz21mbmvL+V2nBLscw0D587dyw3nzqSwhyd5j8YgwqyWF/XCkBZHxYoGTMwjzl3ncHzi2tYWt1IflY64yvyKcxOZ+rwYgYVptbEyGQX3Q7UFwj9n9brdZqbmcb9lx3LvNU7uO/Z93n049MPWyu+vyyq4revb+BjM4bz9cuO1aS+fiSWgHk+MNbMRhLKHF8LXB+9g5mVAvXOuSDwZUIdMwA2A7eY2XcIZapnAj+O09iPKlUNbQBs3NnK+EEFvLq6lmPK8zlzXCkeg3c3NdDQ5mP4UVYz2Z+E3j8VMR+NfIEgb67biRnMGFUSt/ZLje1dABRl75mBnDaymJtPG8Ef3t7MC8u2cdqYEh6+eVpcWnt1+gO8uGw7j7+1ibc31JPuNc6bWM60EcVMHlrExIoCTQo6RNEdP/aVid7ffT95xqh4D0kOA68ZkYXvIivg7e01OjA/i/++eAL//Zf3eeiNDYfl+X30zY38v78uY9rIYr7ygQkKlvuZAwbMzjm/md0BvEiordxDzrllZvYAsMA59xwwC/iOmTlC2ePPhO/+NHA28D6hSOUF59zz8f81Ess5R3VDOwAb6loZXpzL/A0NfGzGcDLTvIwoyWXuytBcx+GH8VSr7F+y9GHu8AV4c91OTh9bmpJ9Wdu7AryzsZ7ygkzeXLeT+RvrWbmtuTtbOKQom7qWTjK8Hn784RM4d2L5Qf+svZVkRPvapcfy5Ysm8Pjbm/j688v5f88u5TtXHXdIH4SvrKzlC08vZkdLF8OKc7j3ovFcc1LlAetspW8iAfOAnHT1t01hHs/uton+8Bt4mnfvr8/rpg3l1VW1fGvOCoYW53BBDAuBxepfy7fzteeWce6EgTz4kRO10m4/FFMfZufcHGBOr9u+GnX5aULBce/7BYBPHeIYj3p1LZ10hmebr9/RSk5mPV2BIGeMC82WHT0wj5eWhwLmo21Wfn/iOcprmNu6/PzujY08OX8Lm+vbOHv8QO46Zyy/eX0Dt54xirHleby4bBvnTijn1VV17Gzt5NLJgw+qZjQRIi3evvbcMhZt3r0a2rDiHErzMvjZdVMIBB1PLdjCeRPLeXtDPZ99YhEnjyjmumlD+duSrVw4aRDnTSznhaXbGDMwj9++toHLThjMrGMGAlDb1MGb63dy6uhSyvIz2RUuydjfRLWMNA83nzaS+tYufvbyWpo6fPzXecfE3H4s2tLqRu74w7sMK8nlhx86gTPGlPbbVdoOt/JwHau+iKQ2j1n3pD9fJMPs2fsXJDPjJ9dO4cOz3+Qrf1nKqaNLDrnXtS8QZO6KWu5+8j0mDSnkp9dNUbDcT2nJqzjYUt/efXl9XSuN7T4yvB6mhZvkjx+Uz0vLt+P1mPp2JtJRnGFuaO3i5ofn896WXZw4rIhLJlfwq3+v614o4V/Lt5ObmcaOlk5Gl+WyLpyNffiNjfzhllP2qLt8bnENU4YWHZEvaC2dfoLOkZPuZdX2ZpyDml3tbGlo5+zxAxlZmkttcwd3P/keb6zdSWaah29eMYmMtNBrZESvCTpXTBkChFqsfe25pSzavItPP/YuAH9bsnWPdmh/XVzDZccPZsOOVt4LL0v8uXPH8rlzx9HY7iPda+TEMKnvv84bR5rHw6/+vY75GxuY+/mZFMTwYeucY21tC/9cvp2fv7yWopx0Hr755JRbJORoMyj891XAnNq8Ue/b/sD+M8wQmrD6zSsmcfmDb3DvM+/z/Q9OJiej76FOza52fvPaBp5bXM2Oli6Gl+Twm49NPajHktSgZz4OIvXLpXmZbNjRwpYGDxMHF3TPvP/k6aMYVZbLoIJs8rQsb8J4bPepvaNFIOh4afk2fvjP1Wyqb+PXHz2p+zTixcdV8Pjbm7js+CE8824V7b4AHjOeX1zDjFEl3HnOGD7+8Hy++ffl/Pz6E7sfs6qhjc/+cRETKwr46x2nHdayjqcXVvHff34fjyfU8mxZTVOP7d97YSVzPz+T776wigUbG/jqJRO5csqQmLLigwqz+PVHp1Lb3MHP5q7lwycPZW1tC29v2Mm0kcUs2NjABccO4vnFNfxrxXaGFedwz/nj+N9/rekOqHe1+SjMzoipxMLMuOvcsZw9fiCXPfg6tz/2LhcfV8HpY0r32rXCOUdTh5/7nl3K84tD86DPHFfGD66ZzEAFy4dd5G8cS4cMSV7RXTL8wX3XMEebXFnEFy44hu+/uIq65k4e++T0PrVzbe3089Hfvs2W+nbOmTCQq06sZOa4MrWE7ecUvcVBVbh+eea4Ml5ctg3nHFefVNm9vTAnnSunVO7r7nKEeMyOqpX+2rsCfO7JRby4bDuleRn8/uZpzBhd0r190pBCvnNVaJHMyO0dvgDjB+Vz1YlDqCjM5tYzRvHTl9fyidMbupv2Rzq0LN/axDf+tpz7Lz22T2UBVQ1tPPHOFqoa2jhpRDFnji3lL4uqae8KkJORxtyV21lb28KUYUVs3NHGuEGh0oVV25r52qUTqRyQQ0FWGkU5GXzgp6/xxaeX8J91O7njrDF8/PSRff47DczP4htXTOr+m0Qy0JHX1Jnjei4U8NO5a7undja2d1GY3be3ueMqC/nCBcfw63+v5/W1O0j3Gh89ZQQXHFtOQ1sXNbs6WFrdyNyVtd1dOO48ewzXnFSpM0hHUOSsijLMqc3r2bNLRvp+MswRt88aw5CibO564j2u+7+3+Ow5Y5k57sCLimypb+Pzf1rM+h2tPP6J6Qnr0y5HHwXMcbClvo2S3AwuPm4Qz7xbBYS+4crR5WiqYV5X18KND71DVUM7931gAjedOiKmiUtZ6V4+c9aY7uu3zhzNE/O38OU/v89zd5xOW5ef5xbXMKGigNNGl/Cb1zewYUcr37h80h6lD3vjnOPm381n/Y5WyvIyefa9mlBmnlDdoC8YZMrQIi6dPJgnF4TWM7rvAxM4a/xA6lu7GFyU3ePxLj8hlB0fMzCPT808Ql0Jop7nxnYfRTl9z0DePmsMt80czcadbfzilbX8/s2NPPTGhu7teZlpXDRpEGPL8xgzMI+zxx/8xEQ5OAPzMxmQk87Y8r7XmkvyiK5h7i7J2EcNc2+XnzCElk4/v3hlHTc+9A53nTOWu88bt9d9tzd18NT8Lfzq3+swM374weMVLEsPCpjjYFlNE8cMyuf0saXkZabR0ulncqWWvz7aGHZEA2ZfIBgK2LLT2VzfRmF2OiXhbNjXn19Oc4efJ289hemjSg7wSPuWl5nGN67gWYBtAAAgAElEQVSYxKceXchp332Z+tYuAkHH/ZdO5MZTRzC8JIfvvrCK8388jytPGMINpwxnWHEOGWkeOv0BanZ18Njbm2jvCuALBMlI87CmtoUffPB4rpoyhB/PXcP2xg7uPm8c+VlpdPqD3S28HI631tdz7sRy0r2ePYJlgK98YAIzRpdwyeSKI9ZGzWN0dw/c1ebrrnXtKzNjZGku3//g8dxzwTGs2tZMYXY6w4pzyM1M0+nZBEv3epj3xbNUU5riPJ7dNcxd4Ul/+6th7u0j04dz9YmV3PfsUn4ydw3rd7QyflA+48rz8Ri8vaGeFVubeHt9aLL+rGPK+OYVk6gcoAn60pPeaQ5Rpz/Aym1NfOL0UWSmeTlvYjn/WrGd0WXKehxtzDhiJRmPvrWJ772wkuYOP9npXtp9AdI8xnevnozXY8xbXcd9H5hwSMFyxAXHDuLn10/hhaXbGFGSyzkTBnLC0CLMjI/OGMH5xw7iBy+uYs77W3lqYSgrnOH14AsECbrQ5dxML0EXysgWZqdzyeQKPB7jv3plY3Kjzn7/z1WT8QWD+60nLM7N4JqTjmw5kmHdJRm72nwcE4eljcsLsjSJ7yh0qB0Q5OjnsdBS1LD/Psz7k5Xu5btXTyYzzcMLS7d1zzmA0PvfuEF5fPjkoXzi9JExnYmT/kkB8yFaubUZX8B1Z5S/dulEPj1Ta8ofjaJP7R0uzjn+919r+OncNZw+ppQZo0vY2tjOCUMH8PTCLXz+T4sBmDp8ADecsv/lifviksmDuWTy4L1uKy/I4vsfPJ7/d+lEfvvaBsygucNPXmYaowfmcUJlEcNKcnAu1NKtMDs9pmywx2Nkeo6+9krRH7DNHT7ys/Q2J5KsvFEr/XX3YT6Iz1evx/jWlcfxrSuPo63Lz9LqJoLOccLQIi0iJDHRJ8khWlLdCMBxQ0IBc1FOxkHVTMrh5/HsnjRyOOxs6eQrf1nKC8u28cGTKvnOVcf1qEu+9PgK5ry/le1Nndw4Y8QRf5MuyErfZ/0ehEoQPnzysCM4osPDbHeGORB0WtRCJImZGQHXsw/zob6mczLSmDay+JDHJv2LAuaDtGlnKzW7Onhx6TaKczOoHLBn/aYcXQ53DfMDf1vOy6tq+dKF4/n0zFF7tDLLTPOqW8oREN2GKuCczvaIJDGvZ3d3I38fumSIxJsC5oN05x8XsaQqlF2+/9KJWlM+CZh1zwWLux0tncx5fys3nDKc22aNPkw/RWJh7K5VDwZDpTgikpw8xu4uGeE+zLF2yRCJJwXMB2FbYwdLqhopyknnljNGceOpIxI9JImB5zCt9Oec42dz1+ALOD4yPflLGpKdx2PdC9SEMswJHpCIHDTPQfZhFok3BcwH4cVloYUhnv70qYwZqG4YySJeK/35AkHuf24Z25s6+OUNJ3H/c8t4/O3NfPSU4YwZeOgdGeTQRHWVIxB0eJVhFklanh6T/uJTwyxyMBQwH4S5K2sZXZarYDnJmMWnhvkrf3mfpxaEFqi59Gevs3JbM7fNGs0XLzjmkB9bDl3kAzbSKaMvqxyKyNHFa0Y4Tu7OMB9MlwyRQ6WAuY8CQce7mxq4YsreW3jJ0ctzCH2YWzv9/PLVdazY2sTclbV8euZoXl9bx9LqJr5y8QRuOfMIrWInBxTptx35cqQaZpHkZUZ3l4zdk/6UYZYjTwFzH63c1kRLp5+TR6glTbKxqBrm+tYucjK8MbV26/AFuP7/3mJxVSOleRlMrCjg7vPG8rEZw9lS3xaXxUckfiLPc+RDVl0yRJKX12O7Fy4J9n2lP5F4UcDcRws2NgAwVQFz0omuYb7gx/NobPOx5P7zDxg0f2fOChZXNfKrG07kgmMHAaGgbHBR9l6Xg5bECn2Uuu7TuMowiySv6Brm7kl/6pIhCRDTUWdmF5rZKjNba2b37mX7cDOba2ZLzOxVM6uM2jbMzP5pZivMbLmZjYjf8I+8BZsaqCjMYogCpaQT/cZb19xJVyDIN/++fL/3aevy86eFVVxzUiUXTqrAzNRC8CjnCdc87s4wJ3hAInLQPB4j0N2HWRlmSZwDfpSYmRd4ELgImAhcZ2YTe+32A+AR59xk4AHgO1HbHgG+75ybAEwDauMx8ERZV9vCMYPUCSEZWVQNc2Za6NB/7K3N/Gfdjn3e55/LttPWFeCak7TgSLII9dt23b1blWEWSV7eqDOD3UtjK2CWBIgl9zINWOucW++c6wKeAC7vtc9EYG748iuR7eHAOs059xKAc67FOdcWl5EngHOOzfVtDC/OSfRQ5CBYVPeETn+QT505imHFOXztr8u6MxcRTR0+nl5YxXdfWMmQomymqQQnaUT6bUfqHlXDLJK8PGbdX34jS2OrJEMSIZYa5iHAlqjrVcD0XvssBq4GfgJcCeSbWQkwDthlZn8GRgL/Au51zgUOdeCJUN/aRUunn2EluYkeihwEj4WWWO3whw6/AbkZfPmi8dz2+Lt87sn3KC/IYnlNE16PsaymkYY2H2MH5vH9Dx6v1mRJxmnSn0hKiF64xB8ILXWv92NJhFgC5r0dmb2bc90D/NzMbgLmAdWAP/z4ZwBTgM3Ak8BNwG97/ACzW4FbAYYNO3pXSttUH0qOK8OcnDwWajXW3hUKmLPTvVw4aRAfOK6Cl1eGKoWGFecQdI5jBxdy93ljmTJ0gN6ck4zHEzobFFRJhkjS8xhRfZiD6sEsCRNLwFwFDI26XgnURO/gnKsBrgIwszzgaudco5lVAYucc+vD254FTqFXwOycmw3MBpg6dephWLw4PjbvDAfMJQqYk1FkBbh23+6A2cx48CMnJnRcEl+G4VCGWSQVeD3WXTLnCzj1YJaEieXImw+MNbORZpYBXAs8F72DmZWaWeSxvgw8FHXfAWZWFr5+NrD/tgRHsU3hgHmoMsxJKdIloyMcMGdlHLgHsySfyJmE3ZP+EjwgETloHrPdC5cEg5rwJwlzwIDZOecH7gBeBFYATznnlpnZA2Z2WXi3WcAqM1sNlAPfCt83QKhcY66ZvU8oyfd/cf8tjpBN9a0MKsiKabELOfpYuN1Ye1coW5Gt5zElWbhWPdIRRSUZIsnLE7XglC/gSNOEP0mQmBYucc7NAeb0uu2rUZefBp7ex31fAiYfwhiPCoGg4+319YyvUEu5ZBVZuCS6JENSj/XKMKskQyR5hWqYI5P+gqQrwywJoq9qMXp1VS3Vu9r50NShB95Zjkqh/rxRNcwqyUhJkVp11TCLJD9vdJeMoFNJhiSMAuYYPbVgC2X5mZw3sTzRQ5GDFKlhju6SIakn1D5QXTJEUoH16sOsHsySKDryYuCcY+GmBs4cW6YZuknMwrVwHcowp7TIio7KMIskP294TgKE+jArwyyJougvBlsbO9jR0sXxQwsTPRQ5BKph7h8iZxK0NLZI8vN46NklQxlmSRAdeTFYUrULgOOGKGBOZpHMo0oyUp9zuxc7UIZZJHlFvgBDpA+zXs+SGAqYY7CkqpE0jzGhoiDRQ5FD0F3D3N2HWYd/Koq0odpdkpHgAYnIQfOY7e6SEQySphe0JIiOvBgsrtrFuPJ89V9OcpFAqr0rgMcgQ2+8KSlUgbG7JMNUkiGStEJdMkKXQ32Y9XqWxFDEcAAdvgALNjZwyqiSRA9FDlGkP2+7L9C9LLakntDzHKpXh9CkIRFJTmZ0f/kN9WFW2CKJoSPvAOZvrKfTH+SMcaWJHoocIiPUiLndF1CHjBQWaSunhUtEkp/X1IdZjg4KmHtZV9dCXXNn9/XX1uwgw+th+sjiBI5K4sETzjB3dAVUXpPCDHrUMKtLhkjy6j3pT10yJFF05EV58JW1nPujf3PT794hGAwtfPDPZds4eeQAcjJiWkVcjmKecC1cpCRDUpOZ4VCXDJFU4PEYgfBr2aelsSWBFAWGOeeYPW89FQVZLKtp4v7nlzG4KJuNO9u469yxiR6exEGPGmaVZKQsC/fbVpcMkeTn9eyej6AaZkkkBcxhdS2dNLb7+Ny5Y3lp+XYeeXMTAANy0rloUkWCRyfxYIQyj+1dyjCnMk94ZTAtjS2S/Dxm3V9+fVrpTxJIAXPY2u0tAIwrz+fGGSNo6vDxh3c2M6IkV/WuKSKy0l+HL8CA3IxED0cOk1ANsyb9iaSC3n2Y01XDLAmigDlsTW0oYB47MA+PxyjKyeD2WWMSPCqJp+4+zL4Ag/UlKGVFMsya9CeS/CLv2wB+ZZglgfRVLWxNbTMFWWmU5WcmeihymHh69WGWFGXgcN1ZKWWYRZKX10NUlwzVMEvixHTkmdmFZrbKzNaa2b172T7czOaa2RIze9XMKnttLzCzajP7ebwGHm9rtrcwtjxfi1mksnDmscMXJDNdb7qpyhNeuCSSlVKGWSR5ecx2L1wS1Ep/kjgHjBrMzAs8CFwETASuM7OJvXb7AfCIc24y8ADwnV7bvwH8+9CHe/hUNbQzdmBeoochh1HkfdYfCCrrmMIiC9SoS4ZI8vN4QokOiJRk6AUtiRFLDfM0YK1zbj2AmT0BXA4sj9pnInB3+PIrwLORDWZ2ElAOvABMjcOYD4vXvngW7b5Aoochh1Ek0+gPOC2XnMI8ntBsenXJEEl+Htv95dcXVB9mSZxYvqoNAbZEXa8K3xZtMXB1+PKVQL6ZlZiZB/gh8IVDHejh5vEYuZmaA5nKujPMQYdHGeaUFWkfqC4ZIskvsjR2IOhwDq30JwkTy5G3t08b1+v6PcBMM1sEzASqAT9wOzDHObeF/TCzW81sgZktqKuri2FIIn0XqU/3B4PKMKewyAI16pIhkvwsPPfEF17uT10yJFFiSalWAUOjrlcCNdE7OOdqgKsAzCwPuNo512hmM4AzzOx2IA/IMLMW59y9ve4/G5gNMHXq1N7BuEhcROImX8Ap65jCrNfCJXquRZJX5PXb6QsFzBmqYZYEiSVgng+MNbORhDLH1wLXR+9gZqVAvXMuCHwZeAjAOfeRqH1uAqb2DpZFjpToTKNKMlJXZIGa3ZP+9FyLJKvIy7fDH5pjpBpmSZQDflVzzvmBO4AXgRXAU865ZWb2gJldFt5tFrDKzFYTmuD3rcM0XpGDFh03qSQjdRmhmjFN+hNJfp7eGeY09dCXxIhplptzbg4wp9dtX426/DTw9AEe42Hg4T6PUCROlGHuHzxRk4RAGWaRZBZ531aGWRJNxUDSLynDnLrMCNUwdy9cktjxiMjBi7xX784wK2yRxNCRJ/1GdIZZ80ZSl5mFV/oLl2QoYhZJWrZHDbPevCUxdORJvxEdNymISl1GeNJfpCRDZxNEklakpKojvLCYumRIoujIk34jOkhWEJW6POG2cuqSIZL8umuYwyUZ6SrJkATRkSf9RnTYpCAqdZmBQ0tji6QCT68Msyb9SaIoYJZ+w6K7ZCiISlmecA1zeGEwfTkSSWLdk/78WrhEEktHnvQbPSf9KYhKWb0WLtFTLZK8uhcu8WnSnySWjjzpNzTpr3/wRC2N7bGeZxZEJLn0LslQWzlJFB150m9Ex02a9Je6Iiv9BZzTmQSRJOfpVZKhDLMkio486TdMfZj7BY+FejAHnVN2WSTJRd6rO9VWThJMR570Gx5N+usXLKokQ2cSRJLb7qWxI23l9JqWxFDALP1G9Nl5napPXRbOMAeCep5Fkt3uPszKMEti6ciTfsMUMPcLRjjD7Jw6ZIgkud4BsxYukUTRkSf9hkoy+gez3Utj64uRSHLrrmFWH2ZJMB150m+Y+jD3Cx5TlwyRVGG9M8wKmCVBdORJv9GjD7MyzCnLsFCXjKDT8yyS5LzdAXMQr8f0JVgSJqaA2cwuNLNVZrbWzO7dy/bhZjbXzJaY2atmVhm+/QQze9PMloW3fTjev4BIrIzdb7RpetNNWR4POIdKMkRSgCccpXT4AqR79XqWxDlgwGxmXuBB4CJgInCdmU3stdsPgEecc5OBB4DvhG9vAz7mnDsWuBD4sZkVxWvwIn2hLhn9hRF0oZIMZZhFklv0wiUqx5BEiuXomwasdc6td851AU8Al/faZyIwN3z5lch259xq59ya8OUaoBYoi8fARfoquoZZS2OnrtBT63Bud3ZKRJJTdJcMTfiTRIrl6BsCbIm6XhW+Ldpi4Orw5SuBfDMrid7BzKYBGcC6gxuqyKHpkWFW5jFlhfowh0sy9DyLJLXI2cAuZZglwWI5+vb2ieN6Xb8HmGlmi4CZQDXg734AswrgUeBm51xwjx9gdquZLTCzBXV1dTEPXqQvemaYEzgQOaw8ZqG2cs7pTIJIkou8bXf4AmSoB7MkUCxHXxUwNOp6JVATvYNzrsY5d5VzbgrwlfBtjQBmVgD8HbjPOffW3n6Ac262c26qc25qWZkqNuTwUIa5fzBCGWYtjS2S/LxRS2Nr0p8kUiwB83xgrJmNNLMM4FrguegdzKzUzCKP9WXgofDtGcBfCE0I/FP8hi3Sdx71Ye4XLJJhVpcMkaQXOUsU6pKhDLMkzgGPPuecH7gDeBFYATzlnFtmZg+Y2WXh3WYBq8xsNVAOfCt8+4eAM4GbzOy98L8T4v1LiMQiOtmoU/WpK7TSX2RpbD3PIsmsx6Q/lWRIAqXFspNzbg4wp9dtX426/DTw9F7u9xjw2CGOUSQueqz0p0AqZXnMQiv9KcMskvQir+Gg07LYklg6+qTfUB/m/iFUw+wIOJ1JEEl20S9hlWRIIunok34j+vS8TtWnLo/HQiUZQYfmCIkkt+j36nSVZEgC6eiTfsOUYe4XDHA4gk4lGSLJLjpgztA3YEkgBczSbxjRXTISOBA5rMyse+ES05kEkaQW/aVXk/4kkXT0Sb8RnWxUSUbqslCKOZRh1vMsktRUwyxHCx190m9ETwDTqfrU5bHwpD91yRBJetHv2wqYJZF09Em/oQxz/2CE28qpS4ZI0usx6U8BsySQjj7pN0wr/fULkQyzumSIJD+vJv3JUUIBs/Qb0W+1CphTmIXayqkkQyT5RZ8M1KQ/SSQdfdJvqA9z/xCJkbU0tkjy86qGWY4SOvqk3/CoJKNfiLQP9AWCep5FkpxqmOVooaNP+o0eC5co85iyIjFyIOg06U8kyXmiohSVZEgi6eiTfiM6RvboyE9ZkefZH1RJhkiyi34NZypglgTS0Sf9hkoy+odIN5SAumSIJL3oIPmSyYMTOBLp79ISPQCRI0WT/vqHyFPrC6gkQyTZ5Wel8/gnpzNpcCGFOemJHo70YwqYpd+Ijp3SFEilLE93hjmoWnWRFHDamNJED0EktpIMM7vQzFaZ2Vozu3cv24eb2VwzW2Jmr5pZZdS2G81sTfjfjfEcvEhf9Jj0p4A5ZUWeWX9AfZhFRCQ+Dhgwm5kXeBC4CJgIXGdmE3vt9gPgEefcZOAB4Dvh+xYDXwOmA9OAr5nZgPgNXyR2kdpWs56r/klq6THpTwGziIjEQSwZ5mnAWufceudcF/AEcHmvfSYCc8OXX4nafgHwknOu3jnXALwEXHjowxbpu8ipep2mT22R59mvkgwREYmTWALmIcCWqOtV4duiLQauDl++Esg3s5IY74uZ3WpmC8xsQV1dXaxjF+mTSLJRWcf+wa+lsUVEJE5iCZj39onjel2/B5hpZouAmUA14I/xvjjnZjvnpjrnppaVlcUwJJG+i6wAp6xjaotkmJ1TNxQREYmPWLpkVAFDo65XAjXROzjnaoCrAMwsD7jaOddoZlXArF73ffUQxity0CKxk7KOqa3HAjV6qkVEJA5iyTDPB8aa2UgzywCuBZ6L3sHMSs0s8lhfBh4KX34RON/MBoQn+50fvk3kiIuUYiiISm09FqjRyiUiIhIHBwyYnXN+4A5Cge4K4Cnn3DIze8DMLgvvNgtYZWargXLgW+H71gPfIBR0zwceCN8mcsR5lGHuF3q0D1RJhoiIxEFMC5c45+YAc3rd9tWoy08DT+/jvg+xO+MskjDdNcwKmFOaaQl0ERGJs5gWLhFJBd1dMpR1TGnRz64CZhERiQcFzNJvRDKPCqJSW48aZn05EhGROFDALP2GMsz9Q48uGfpyJCIicaCAWfoNZZj7h+inV8+1iIjEgwJm6TfUJaN/sKgq5jQ91yIiEgcKmKXfiGSYFUOltp4Ll+jJFhGRQ6eAWfoNZZj7B7WVExGReFPALP3G7gyzgqhUphpmERGJNwXM0m8ow9w/mAJmERGJMwXM0m941CWjX1AfZhERiTcFzNJvmPow9zvqwywiIvGggFn6jUi7MWWYU1v0FyK1lRMRkXhQwCz9RncNszLMKU0r/YmISLwpYJZ+QzXM/YNqmEVEJN4UMEu/YeqS0S9EP7tevcOJiEgc6ONE+o3uPswKmFNaz4VL9BYnIiKHLqZPEzO70MxWmdlaM7t3L9uHmdkrZrbIzJaY2cXh29PN7Pdm9r6ZrTCzL8f7FxDpC4+BV/FySuvZhzlx4xARkdRxwI8TM/MCDwIXAROB68xsYq/d7gOecs5NAa4FfhG+/YNApnPuOOAk4FNmNiI+QxfpO4+ZSjJSXHQNs1oIiohIPMSSf5kGrHXOrXfOdQFPAJf32scBBeHLhUBN1O25ZpYGZANdQNMhj1rkIHnMFESluJ41zHquRUTk0MUSMA8BtkRdrwrfFu1+4AYzqwLmAHeGb38aaAW2ApuBHzjn6nv/ADO71cwWmNmCurq6vv0GIn1gpiAq1UWXLeu5FhGReIglYN7bJ47rdf064GHnXCVwMfComXkIZacDwGBgJPB5Mxu1x4M5N9s5N9U5N7WsrKxPv4BIX5hp0l+qM9RWTkRE4iuWgLkKGBp1vZLdJRcRnwCeAnDOvQlkAaXA9cALzjmfc64WeAOYeqiDFjlYHjMFUSmu56Q/PdciInLoYgmY5wNjzWykmWUQmtT3XK99NgPnAJjZBEIBc1349rMtJBc4BVgZr8GL9JUm/aW+nm3l9FyLiMihO2DA7JzzA3cALwIrCHXDWGZmD5jZZeHdPg/cYmaLgT8CNznnHKHuGnnAUkKB9++cc0sOw+8hEhMzdU5IdZr0JyIi8ZYWy07OuTmEJvNF3/bVqMvLgdP2cr8WQq3lRI4Khnrzpjq1lRMRkXhT6CD9isejkoxUpxpmERGJNwXM0q+keYw0LZec0qID5jQFzCIiEgcxlWSIpIpvX3kco8pyEz0MOYyi28qphaCIiMSDAmbpV84/dlCihyCHWXSMrBaCIiISDzo3LSIpRW3lREQk3hQwi0hK8WjSn4iIxJkCZhFJKeqSISIi8aaAWURSiqkPs4iIxJkCZhFJKVrpT0RE4k0Bs4ikFI8m/YmISJwpYBaRlKIaZhERiTcFzCKSUnpkmFXDLCIicaCAWURSljLMIiISDwqYRSSlqIZZRETiTQGziKSU6CoMxcsiIhIPCphFJKVEZ5hNNcwiIhIHMQXMZnahma0ys7Vmdu9etg8zs1fMbJGZLTGzi6O2TTazN81smZm9b2ZZ8fwFRESiKUYWEZF4SzvQDmbmBR4EzgOqgPlm9pxzbnnUbvcBTznnfmlmE4E5wAgzSwMeAz7qnFtsZiWAL+6/hYhImMowREQk3mLJME8D1jrn1jvnuoAngMt77eOAgvDlQqAmfPl8YIlzbjGAc26ncy5w6MMWEdkXRcwiIhJfsQTMQ4AtUderwrdFux+4wcyqCGWX7wzfPg5wZvaimb1rZl/c2w8ws1vNbIGZLairq+vTLyAiEk0ZZhERibdYAua9ffy4XtevAx52zlUCFwOPmpmHUMnH6cBHwv9faWbn7PFgzs12zk11zk0tKyvr0y8gIhJNE/1ERCTeYgmYq4ChUdcr2V1yEfEJ4CkA59ybQBZQGr7vv51zO5xzbYSyzyce6qBFRPZFGWYREYm3WALm+cBYMxtpZhnAtcBzvfbZDJwDYGYTCAXMdcCLwGQzywlPAJwJLEdE5DAx1TCLiEicHbBLhnPOb2Z3EAp+vcBDzrllZvYAsMA59xzweeD/zOxuQuUaNznnHNBgZj8iFHQ7YI5z7u+H65cREVFFhoiIxNsBA2YA59wcQuUU0bd9NerycuC0fdz3MUKt5UREDjsFzCIiEm9a6U9EUopHEbOIiMSZAmYRSSmKl0VEJN4UMItIStGkPxERiTcFzCKSUtRWTkRE4k0Bs4ikFgXMIiISZwqYRSSlaNKfiIjEmwJmEUkpCpdFRCTeFDCLSEpRhllEROJNAbOIpBTFyyIiEm8KmEUkpZgiZhERiTMFzCKSUhQvi4hIvClgFpGUohpmERGJt7REDyAWPp+PqqoqOjo6Ej2UlJSVlUVlZSXp6emJHorIIVO4LCIi8ZYUAXNVVRX5+fmMGDFC9Ylx5pxj586dVFVVMXLkyEQPR+SQKcMsIiLxlhQlGR0dHZSUlChYPgzMjJKSEmXvJWXobUJEROItpoDZzC40s1VmttbM7t3L9mFm9oqZLTKzJWZ28V62t5jZPQc7UAXLh4/+tpJKdDiLiEi8HTBgNjMv8CBwETARuM7MJvba7T7gKefcFOBa4Be9tv8v8I9DH66IyP6ZqphFRCTOYskwTwPWOufWO+e6gCeAy3vt44CC8OVCoCaywcyuANYDyw59uMkjLy8PgJqaGq655pq97jNr1iwWLFhwJIclkvI8ipdFRCTOYgmYhwBboq5XhW+Ldj9wg5lVAXOAOwHMLBf4EvD1Qx5pkho8eDBPP/10ooch0m+oxEhEROItli4Ze/v0cb2uXwc87Jz7oZnNAB41s0mEAuX/dc617O9DzMxuBW4FGDZs2H4H8/Xnl7G8pimGYcdu4uACvnbpsfvd50tf+hLDhw/n9ttvB+D+++/HzJg3bx4NDQ34fD6++c1vcvnlPZPvGzdu5JJLLmHp0qW0t7dz8803s3z5ciZMmEB7e/t+f+Ztt93G/PnzaW9v55prruHrXw9975g/fz533XUXra2tZGZmMnfuXHJycvjSl77Eiy++iMEMDW0AAAluSURBVJlxyy23cOeddzJixAgWLFhAaWkpCxYs4J577uHVV189+D+WyFFOGWYREYm3WALmKmBo1PVKokouwj4BXAjgnHvTzLKAUmA6cI2ZfQ8oAoJm1uGc+3n0nZ1zs4HZAFOnTu0djB8Vrr32Wj73uc91B8xPPfUUL7zwAnfffTcFBQXs2LGDU045hcsuu2yfGa5f/vKX5OTksGTJEpYsWcKJJ56435/5rW99i+LiYgKBAOeccw5Llixh/PjxfPjDH+bJJ5/k5JNPpqmpiezsbGbPns2GDRtYtGgRaWlp1NfXx/1vIJIMlGEWEZF4iyVgng+MNbORQDWhSX3X99pnM3AO8LCZTQCygDrn3BmRHczsfqCld7DcVwfKBB8uU6ZMoba2lpqaGurq6hgwYAAVFRXcfffdzJs3D4/HQ3V1Ndu3b2fQoEF7fYx58+bx2c9+FoDJkyczefLk/f7Mp556itmzZ+P3+9m6dSvLly/HzKioqODk/9/e/cZWdddxHH9/0hZrUP5uGEKHZYoWmrVAOsBUyGSOoJvOBzWpwTjYlmVkEjQzBn0guoRECXFqNCO6oZMUYSlOiTrdP4w+Edu6ydjQODdwDQMqbFA0Zal8fXB+sA7LhQj0nNv7eSXNved3T9tvzyc9/fac3zn3+usBGDcumzr+5JNPcvfdd1NdnUU6adKky/Wjm5mZmVW0CzbMETEo6bPAb4AqYHNEPC/pPqA7InYC9wI/kPR5sukaKyKikEeKL0VbWxudnZ0cOnSI9vZ2Ojo66Ovro6enh5qaGurr6y94P+OLPfr18ssvs3HjRrq6upg4cSIrVqxgYGCAiBj2a5xvvLq6mtOnTwP4XstmZmZm/4eLug9zRPwqIt4XEe+JiPVp7CupWSYiXoiI1ohojog5EfH4MF/jqxGx8fKWP7La29vZtm0bnZ2dtLW1cfz4caZMmUJNTQ27du3iwIEDJT9/8eLFdHR0ALB371727Nlz3nVPnDjB2LFjGT9+PIcPH+axx7K78jU0NHDw4EG6uroA6O/vZ3BwkKVLl7Jp0yYGBwcBzk7JqK+vp6enB4AdO3Zc2gYwMzMzq0Bl8U5/RdHY2Eh/fz/Tpk1j6tSpLF++nO7ublpaWujo6KChoaHk569atYqTJ0/S1NTEhg0bmD9//nnXbW5uZu7cuTQ2NnL77bfT2toKwJgxY9i+fTurV6+mubmZm266iYGBAe68806mT59OU1MTzc3NbN26FYB169axZs0aFi1aRFVV1eXbGGZmZmYVQkWbOdHS0hLn3pt43759zJo1K6eKKoO3sY0m9Wt/CcD+r9+ccyVmZlZkknoiouVC613MRX9mZmVl3cdms2DG5LzLMDOzUcINcwEsWLCAU6dOvWVsy5YtXHfddTlVZFbeVrbOyLsEMzMbRdwwF8Du3bvzLsHMzMzMzqNsLvor2lzr0cTb1szMzOz8yqJhrq2t5ejRo27sroCI4OjRo9TW1uZdipmZmVkhlcWUjLq6Onp7e+nr68u7lFGptraWurq6vMswMzMzK6SyaJhramqYMcMX8ZiZmZnZyCuLKRlmZmZmZnlxw2xmZmZmVoIbZjMzMzOzEgr31tiS+oADOX37q4B/5vS97fycS/E4k2JyLsXjTIrJuRRTHrm8OyKuvtBKhWuY8ySp+2LeT9xGlnMpHmdSTM6leJxJMTmXYipyLp6SYWZmZmZWghtmMzMzM7MS3DC/1ffzLsCG5VyKx5kUk3MpHmdSTM6lmAqbi+cwm5mZmZmV4CPMZmZmZmYluGEGJC2T9FdJL0pam3c9lUTSZklHJO0dMjZJ0hOS/pYeJ6ZxSfpOymmPpHn5VT56SbpG0i5J+yQ9L2lNGncuOZJUK+mPkv6ccvlaGp8haXfKZbukMWn8bWn5xfR6fZ71j2aSqiQ9I+kXadmZ5EzSfknPSXpWUnca8z4sZ5ImSOqU9Jf0N+YD5ZJLxTfMkqqA7wEfAWYDn5I0O9+qKsqPgGXnjK0FnoqImcBTaRmyjGamj7uAB0aoxkozCNwbEbOAhcA96XfCueTrFLAkIpqBOcAySQuBbwD3p1xeA+5I698BvBYR7wXuT+vZlbEG2Ddk2ZkUw4ciYs6Q25R5H5a/bwO/jogGoJns96Yscqn4hhmYD7wYES9FxBvANuDWnGuqGBHxO+DYOcO3Ag+n5w8Dnxgy/uPI/AGYIGnqyFRaOSLi1Yj4U3reT7ZDm4ZzyVXavifTYk36CGAJ0JnGz83lTF6dwI2SNELlVgxJdcDNwINpWTiTovI+LEeSxgGLgYcAIuKNiHidMsnFDXPWCLwyZLk3jVl+3hURr0LWvAFT0rizGmHplPFcYDfOJXfp1P+zwBHgCeDvwOsRMZhWGbrtz+aSXj8OTB7ZiivCt4AvAqfT8mScSREE8LikHkl3pTHvw/J1LdAH/DBNYXpQ0ljKJBc3zDDcf/e+dUgxOasRJOkdwA7gcxFxotSqw4w5lysgIv4TEXOAOrKzY7OGWy09OpcrTNItwJGI6Bk6PMyqzmTktUbEPLLT+vdIWlxiXecyMqqBecADETEX+BdvTr8YTqFyccOc/cdyzZDlOuBgTrVY5vCZ0y7p8Ugad1YjRFINWbPcERE/TcPOpSDSaczfks0xnyCpOr00dNufzSW9Pp7/nf5kl6YV+Lik/WTT+ZaQHXF2JjmLiIPp8QjwKNk/mN6H5asX6I2I3Wm5k6yBLotc3DBDFzAzXdU8BmgHduZcU6XbCdyWnt8G/HzI+GfSlbMLgeNnTuPY5ZPmVD4E7IuIbw55ybnkSNLVkiak528HPkw2v3wX0JZWOzeXM3m1AU+Hb7x/WUXElyKiLiLqyf52PB0Ry3EmuZI0VtI7zzwHlgJ78T4sVxFxCHhF0vvT0I3AC5RJLn7jEkDSR8mOClQBmyNifc4lVQxJPwFuAK4CDgPrgJ8BjwDTgX8An4yIY6mR+y7ZXTX+DayMiO486h7NJH0Q+D3wHG/Oy/wy2Txm55ITSU1kF8RUkR3seCQi7pN0LdnRzUnAM8CnI+KUpFpgC9kc9GNAe0S8lE/1o5+kG4AvRMQtziRfafs/mharga0RsV7SZLwPy5WkOWQXyI4BXgJWkvZnFDwXN8xmZmZmZiV4SoaZmZmZWQlumM3MzMzMSnDDbGZmZmZWghtmMzMzM7MS3DCbmZmZmZXghtnMzMzMrAQ3zGZmZmZmJbhhNjMzMzMr4b/3w313nYK1mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  4 \tloss:  tensor(0.1450)\n",
      "ex outvar:  tensor([-5.9882]) \tex hidvar:  tensor([-5.8984])\n",
      "ex pri outvar:  tensor([0.]) \tex pri hidvar:  tensor([-5.8916])\n",
      "ex out m:  tensor([-0.0815]) \tex hidmean:  tensor([-0.0042])\n",
      "ex pri out m:  tensor([0.]) \tex pri hidmean:  tensor([-0.0023])\n",
      "validation prec:  9884\n",
      "kl:  tensor(-0.7672, grad_fn=<NegBackward>)\n",
      "9884 10000\n"
     ]
    }
   ],
   "source": [
    "#THE TRAINING AND VALIDATION PART\n",
    "import torch.optim as optim\n",
    "\n",
    "no_epochs = 120\n",
    "batch_size = 60000\n",
    "lr = 0.001\n",
    "\n",
    "xtest_set = [test_datasets[0].dataset.data[test_datasets[0].sub_indeces]]\n",
    "xtrain_set = torch.tensor([])\n",
    "ytest_set = [test_datasets[0].dataset.targets[test_datasets[0].sub_indeces]]\n",
    "ytrain_set = torch.tensor([])\n",
    "\n",
    "coreset_size = 40\n",
    "\n",
    "#########PRE TRAINING\n",
    "print(\"pretraining\")\n",
    "pre_batch_size = 64\n",
    "net.add_task()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "xtrain_set = train_datasets[0].dataset.data[train_datasets[0].sub_indeces]\n",
    "ytrain_set = train_datasets[0].dataset.targets[train_datasets[0].sub_indeces]\n",
    "    \n",
    "for epoch in range(1):\n",
    "    print(\"pretraing epoch\", epoch)\n",
    "    num_samples = len(xtrain_set)\n",
    "    num_batches = int(np.ceil(num_samples / float(pre_batch_size)))\n",
    "    for batch in range(num_batches):\n",
    "        net.train()\n",
    "        #get indexes for current batch\n",
    "        idx = range(batch*pre_batch_size, np.minimum((batch+1)*pre_batch_size, num_samples))#indexes to use from batch\n",
    "        X_batch_tr = xtrain_set[idx]\n",
    "        y_batch_tr_raw = ytrain_set[idx]\n",
    "        #TRANSFORM Y:\n",
    "        y_batch_tr = torch.zeros((len(idx),2))\n",
    "        for i in range(len(y_batch_tr_raw)):\n",
    "            if y_batch_tr_raw[i] in [0,3,4,7,9]:\n",
    "                y_batch_tr[i,0] = 1\n",
    "            else: #i used this when i had 2 output neurons\n",
    "                y_batch_tr[i,1] = 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, batch_loss, _ = net(X_batch_tr.type(torch.FloatTensor),y_batch_tr.type(torch.FloatTensor),0)#task no so we choose correct head. calls forward function.\n",
    "        batch_loss.backward() #Update weights and biases to new posterior\n",
    "        optimizer.step()            \n",
    "#DONE PRE TRAINING\n",
    "\n",
    "init_var = -6   #This is the log(var) we use when we initiate layers.\n",
    "init_var_hid = -6\n",
    "init_var_pri = 0\n",
    "\n",
    "net.reset_var_and_priors()\n",
    "\n",
    "x_coresets = []\n",
    "y_coresets = []\n",
    "\n",
    "#for plotting\n",
    "test_vali = []\n",
    "test_iter = []\n",
    "test_i = 0\n",
    "test_vali_seperate = [[],[],[],[],[]]\n",
    "\n",
    "#target values to be class 1\n",
    "distances = []\n",
    "data_points = []\n",
    "\n",
    "for task_no in range(n_tasks):\n",
    "    print(\"TASK NUM: \",task_no)\n",
    "    #Get the train and test \n",
    "    xtrain_set = train_datasets[task_no].dataset.data[train_datasets[task_no].sub_indeces]\n",
    "    ytrain_set = train_datasets[task_no].dataset.targets[train_datasets[task_no].sub_indeces]\n",
    "        \n",
    "    \n",
    "    #####The coreset thing\n",
    "    if coreset_size > 0:  \n",
    "        x_coresets, y_coresets, xtrain_set, ytrain_set = k_center(x_coresets, y_coresets, xtrain_set, ytrain_set, coreset_size)\n",
    "    #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if task_no != 0: #Also whe a new taks comes we append this to the test set\n",
    "        xtest_set.append(test_datasets[task_no].dataset.data[test_datasets[task_no].sub_indeces])\n",
    "        ytest_set.append(test_datasets[task_no].dataset.targets[test_datasets[task_no].sub_indeces])\n",
    "        \n",
    "        net.add_task()#initialize a new head for the network\n",
    "\n",
    "    #TRAIN\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr) #REDEFINE OPTIMIZER AFTER LAYERS ARE ADDED!\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        num_samples = len(xtrain_set)\n",
    "        num_batches = int(np.ceil(num_samples / float(batch_size)))\n",
    "        print(\"num batches: \",num_batches)\n",
    "        \n",
    "        indexes = list(range(num_samples))\n",
    "        np.random.shuffle(list(indexes))\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            net.train()\n",
    "            #get indexes for current batch\n",
    "            idx = indexes[slice(batch*batch_size, np.minimum((batch+1)*batch_size, num_samples))]#indexes to use from batch\n",
    "            X_batch_tr = xtrain_set[idx]\n",
    "            y_batch_tr_raw = ytrain_set[idx]\n",
    "            #TRANSFORM Y:\n",
    "            y_batch_tr = torch.zeros((len(idx),2))\n",
    "            for i in range(len(y_batch_tr_raw)):\n",
    "                if y_batch_tr_raw[i] in [0,3,4,7,9]:\n",
    "                    y_batch_tr[i,0] = 1\n",
    "                else: #i used this when i had 2 output neurons\n",
    "                    y_batch_tr[i,1] = 1\n",
    "  \n",
    "            optimizer.zero_grad()\n",
    "            output, batch_loss, _= net(X_batch_tr.type(torch.FloatTensor),y_batch_tr.type(torch.FloatTensor),task_no)#task no so we choose correct head. calls forward function.\n",
    "            batch_loss.backward() #Update weights and biases to new posterior\n",
    "            optimizer.step()            \n",
    "            \n",
    "            if(batch%100 == 0):#THis is just for evaluation and plotting\n",
    "                #print(net)\n",
    "                net.eval()\n",
    "                vali_accu = 0\n",
    "                n_test_samples = 0\n",
    "                for i in range(len(xtest_set)):\n",
    "                    task_test_no = i\n",
    "                    \n",
    "                    ytest_set_onehot = torch.zeros((len(ytest_set[i]),2))\n",
    "                    for j in range(len(ytest_set[i])):\n",
    "                        if ytest_set[i][j] in [0,3,4,7,9]:\n",
    "                            ytest_set_onehot[j,0] = 1\n",
    "                        else:\n",
    "                            ytest_set_onehot[j,1] = 1       \n",
    "                    output, _, kl = net(xtest_set[task_test_no].type(torch.FloatTensor),ytest_set_onehot.type(torch.FloatTensor),task_test_no, False)#task no so we choose correct head. calls forward function.\n",
    "                    vali_accu += get_n_true(output,ytest_set_onehot)\n",
    "                    n_test_samples += len(ytest_set_onehot)\n",
    "                    \n",
    "                #for plotting\n",
    "                clear_output(wait=True)\n",
    "                test_vali.append(vali_accu/n_test_samples)#i is task_no\n",
    "                test_iter.append(test_i)\n",
    "                test_i += 1\n",
    "                                \n",
    "                fig = plt.figure(figsize=(12,4))\n",
    "                plt.plot(test_iter,test_vali, label='valid_accu')\n",
    "                #plt.plot(test_iter,batch_loss_list)\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                    \n",
    "                print(\"task: \",task_no,\"\\tloss: \",batch_loss.data)\n",
    "                print(\"ex outvar: \", net.out_layers_b_var[task_no][0].data, \"\\tex hidvar: \", net.hidden_b_var[0][0].data)\n",
    "                print(\"ex pri outvar: \", net.pri_out_layers_b_var[task_no][0].data, \"\\tex pri hidvar: \", net.pri_hidden_b_var[0][0].data)\n",
    "                print(\"ex out m: \", net.out_layers_b_mean[task_no][0].data, \"\\tex hidmean: \", net.hidden_b_mean[0][0].data)\n",
    "                print(\"ex pri out m: \", net.pri_out_layers_b_mean[task_no][0].data, \"\\tex pri hidmean: \", net.pri_hidden_b_mean[0][0].data)\n",
    "                print(\"validation prec: \",vali_accu)\n",
    "                print(\"kl: \",kl)\n",
    "                print(vali_accu,n_test_samples)\n",
    "    \n",
    "    net.update_prior(task_no)\n",
    "\n",
    "                \n",
    "    #### The coreset thing: We only use the coresets when predicting and not when updating!\n",
    "    for i in range(task_no+1):\n",
    "        net_coreset = copy.deepcopy(net)\n",
    "        optimizer = optim.Adam(net_coreset.parameters(), lr=lr)\n",
    "        #Train on coreset \n",
    "        for j in range(no_epochs):\n",
    "            num_samples = len(x_coresets[i])\n",
    "            num_batches = int(np.ceil(num_samples / float(batch_size)))\n",
    "            \n",
    "            for batch in range(num_batches):\n",
    "                net_coreset.train()\n",
    "                #get indexes for current batch\n",
    "                idx = range(batch*batch_size, np.minimum((batch+1)*batch_size, num_samples))#indexes to use from batch\n",
    "                X_batch_tr = x_coresets[i][idx]\n",
    "                y_batch_tr_raw = y_coresets[i][idx]\n",
    "                #TRANSFORM Y:\n",
    "                y_batch_tr = torch.zeros((len(idx),2))\n",
    "                for k in range(len(y_batch_tr_raw)):\n",
    "                    if y_batch_tr_raw[k] in [0,3,4,7,9]:\n",
    "                        y_batch_tr[k,0] = 1\n",
    "                    else:\n",
    "                        y_batch_tr[k,1] = 1 \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output, batch_loss, _ = net_coreset(X_batch_tr.type(torch.FloatTensor),y_batch_tr.type(torch.FloatTensor),i)#task no so we choose correct head. calls forward function.\n",
    "                #net_coreset.update_prior(i)\n",
    "                batch_loss.backward() #Update weights and biases to new posterior\n",
    "                optimizer.step() \n",
    "        \n",
    "        #RUN MODEL ON TEST SET\n",
    "        ##Transform y\n",
    "        y_batch_test_raw = test_datasets[i].dataset.targets[test_datasets[i].sub_indeces]\n",
    "        y_batch_test = torch.zeros((len(y_batch_test_raw),2))\n",
    "        for j in range(len(y_batch_test_raw)):\n",
    "            if y_batch_test_raw[j] in [0,3,4,7,9]:\n",
    "                y_batch_test[j,0] = 1\n",
    "            else:\n",
    "                y_batch_test[j,1] = 1  \n",
    "                \n",
    "        output, _, _ = net_coreset(test_datasets[i].dataset.data[test_datasets[i].sub_indeces].type(torch.FloatTensor), y_batch_test.type(torch.FloatTensor), i, False)\n",
    "        test_vali_seperate[i].append([task_no, get_n_true(output,y_batch_test)/len(y_batch_test)])\n",
    "        \n",
    "        \n",
    "        \n",
    "    ####\n",
    "                \n",
    "\n",
    "#    #THIS is used when we make the last plot of the end results for each taks\n",
    "#    for i in range(task_no+1):\n",
    "#        y_batch_test_raw = test_datasets[i].dataset.targets[test_datasets[i].sub_indeces]\n",
    "#        #TRANSFORM Y TO one hot:\n",
    "#        y_batch_test = torch.zeros((len(y_batch_test_raw),1))\n",
    "#        for j in range(len(y_batch_test_raw)):\n",
    "#            if y_batch_test_raw[j] in [0,2,4,6,8]:\n",
    "#                y_batch_test[j,0] = 1\n",
    "#            #else:\n",
    "#            #    y_batch_test[j,1] = 1\n",
    "#        output, _, _ = net(test_datasets[i].dataset.data[test_datasets[i].sub_indeces].type(torch.FloatTensor), y_batch_test.type(torch.FloatTensor), i, False)\n",
    "#        test_vali_seperate[i].append([task_no, get_precision(output,y_batch_test)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5):\n",
    "    plt.plot(np.transpose(test_vali_seperate[i])[0],np.transpose(test_vali_seperate[i])[1])\n",
    "    plt.plot(np.transpose(test_vali_seperate[i])[0],np.transpose(test_vali_seperate[i])[1],\"x\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('split_coreset40_fashion_taskoptim_4.pickle', 'wb') as f:\n",
    "    pickle.dump(test_vali_seperate, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('split_coreset40_fashion_taskoptim_4.pickle', 'rb') as f:\n",
    "   test_vali_seperate_1 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5):\n",
    "    plt.plot(np.transpose(test_vali_seperate_1[i])[0],np.transpose(test_vali_seperate_1[i])[1])\n",
    "    plt.plot(np.transpose(test_vali_seperate_1[i])[0],np.transpose(test_vali_seperate_1[i])[1],\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hidden_w_mean.0', Parameter containing:\n",
      "tensor([[-7.7002e-07, -1.1125e-05,  3.5185e-05,  ..., -3.2222e-06,\n",
      "          7.7186e-06, -1.6301e-05],\n",
      "        [ 9.3675e-06,  7.3920e-07, -1.0126e-05,  ...,  2.3370e-06,\n",
      "          5.6567e-06,  8.9074e-06],\n",
      "        [-6.6875e-06, -7.5122e-06,  8.8762e-05,  ..., -3.8555e-06,\n",
      "          6.0347e-07,  1.0872e-05],\n",
      "        ...,\n",
      "        [ 1.1420e-05,  5.1225e-06, -3.0159e-05,  ...,  9.8955e-06,\n",
      "          8.8219e-06, -1.0427e-05],\n",
      "        [ 1.2787e-05,  2.9288e-05, -7.8276e-06,  ...,  6.2296e-06,\n",
      "          8.0720e-06,  1.0121e-06],\n",
      "        [ 1.3437e-06,  2.5653e-06, -9.3707e-06,  ..., -9.3047e-05,\n",
      "         -6.5004e-06, -4.8943e-08]], requires_grad=True))\n",
      "('hidden_w_mean.1', Parameter containing:\n",
      "tensor([[-4.8701e-02, -6.9072e-02,  8.6756e-04,  ..., -1.7249e-02,\n",
      "          3.9870e-05,  5.6056e-02],\n",
      "        [ 6.9138e-04, -1.3394e-02, -3.3830e-03,  ..., -4.2165e-02,\n",
      "         -5.0604e-02, -1.4167e-03],\n",
      "        [ 1.3550e-04, -4.9942e-02, -1.9222e-01,  ...,  6.1378e-02,\n",
      "         -7.5422e-02, -1.7152e-02],\n",
      "        ...,\n",
      "        [-5.6476e-03, -1.2876e-01, -9.4528e-05,  ...,  3.8299e-03,\n",
      "          3.7547e-02, -3.3125e-02],\n",
      "        [-1.9961e-04,  5.6011e-02,  1.2960e-02,  ..., -9.6351e-04,\n",
      "          3.4159e-02,  1.0245e-05],\n",
      "        [ 2.4933e-04,  6.2012e-03,  2.6712e-05,  ...,  3.8762e-06,\n",
      "         -3.8346e-02, -2.2988e-05]], requires_grad=True))\n",
      "('hidden_b_mean.0', Parameter containing:\n",
      "tensor([[ 1.2581e-01],\n",
      "        [-4.6803e-02],\n",
      "        [ 5.6033e-02],\n",
      "        [ 1.5679e-01],\n",
      "        [-7.3346e-02],\n",
      "        [-1.2936e-01],\n",
      "        [ 1.5654e-02],\n",
      "        [-3.8651e-02],\n",
      "        [-2.7798e-04],\n",
      "        [ 6.9272e-02],\n",
      "        [-3.0800e-02],\n",
      "        [ 1.2413e-01],\n",
      "        [-8.6817e-02],\n",
      "        [-1.4957e-02],\n",
      "        [ 8.1762e-02],\n",
      "        [ 1.9068e-02],\n",
      "        [-4.7071e-02],\n",
      "        [-8.2052e-02],\n",
      "        [ 6.5665e-02],\n",
      "        [ 1.6250e-03],\n",
      "        [ 3.0708e-03],\n",
      "        [ 2.1514e-02],\n",
      "        [ 3.8128e-02],\n",
      "        [ 1.2744e-01],\n",
      "        [ 3.0708e-02],\n",
      "        [ 8.2306e-02],\n",
      "        [-2.6654e-02],\n",
      "        [ 1.4618e-01],\n",
      "        [ 4.4752e-02],\n",
      "        [ 1.2021e-01],\n",
      "        [-3.9002e-02],\n",
      "        [ 1.1042e-01],\n",
      "        [ 3.0754e-02],\n",
      "        [ 4.9733e-02],\n",
      "        [ 1.2503e-02],\n",
      "        [-8.0179e-04],\n",
      "        [ 4.0790e-02],\n",
      "        [ 7.2042e-02],\n",
      "        [-5.6777e-02],\n",
      "        [-1.0622e-01],\n",
      "        [-4.9108e-02],\n",
      "        [ 5.7583e-02],\n",
      "        [ 6.4836e-02],\n",
      "        [ 4.1686e-02],\n",
      "        [-1.0524e-02],\n",
      "        [-5.8032e-02],\n",
      "        [ 1.8744e-02],\n",
      "        [ 1.9054e-01],\n",
      "        [-2.8677e-02],\n",
      "        [-7.9630e-02],\n",
      "        [-2.4808e-02],\n",
      "        [ 3.9043e-02],\n",
      "        [-9.1032e-02],\n",
      "        [ 9.8657e-02],\n",
      "        [ 5.0162e-02],\n",
      "        [-7.8749e-02],\n",
      "        [ 1.4007e-02],\n",
      "        [-1.6100e-02],\n",
      "        [ 4.6416e-02],\n",
      "        [ 8.3835e-02],\n",
      "        [-7.9778e-03],\n",
      "        [-9.5140e-04],\n",
      "        [ 2.7448e-02],\n",
      "        [-2.8122e-02],\n",
      "        [ 7.6317e-05],\n",
      "        [-3.8156e-03],\n",
      "        [-3.2740e-03],\n",
      "        [ 4.5665e-02],\n",
      "        [-8.0336e-02],\n",
      "        [-2.1350e-01],\n",
      "        [-5.4065e-02],\n",
      "        [ 1.4365e-01],\n",
      "        [ 1.3164e-02],\n",
      "        [-4.8595e-02],\n",
      "        [-2.7571e-02],\n",
      "        [-2.6803e-02],\n",
      "        [-3.4570e-02],\n",
      "        [ 2.1998e-02],\n",
      "        [ 8.6930e-02],\n",
      "        [-1.8477e-01],\n",
      "        [ 4.1033e-02],\n",
      "        [-1.1637e-02],\n",
      "        [-1.0337e-01],\n",
      "        [-5.3908e-02],\n",
      "        [ 9.6991e-02],\n",
      "        [ 2.2368e-03],\n",
      "        [ 2.4192e-02],\n",
      "        [-4.4512e-02],\n",
      "        [-1.0486e-02],\n",
      "        [-5.2991e-03],\n",
      "        [-2.3581e-02],\n",
      "        [ 5.5778e-02],\n",
      "        [-8.9640e-02],\n",
      "        [-1.5189e-02],\n",
      "        [-2.6359e-02],\n",
      "        [ 6.8399e-02],\n",
      "        [ 2.4053e-02],\n",
      "        [ 1.5279e-02],\n",
      "        [ 2.3263e-02],\n",
      "        [-2.0312e-01],\n",
      "        [-1.3382e-01],\n",
      "        [ 2.5479e-02],\n",
      "        [ 7.2784e-02],\n",
      "        [-1.2616e-02],\n",
      "        [ 1.0205e-01],\n",
      "        [ 5.4921e-02],\n",
      "        [-8.2279e-02],\n",
      "        [ 2.2924e-03],\n",
      "        [ 6.1290e-03],\n",
      "        [-7.0098e-02],\n",
      "        [ 2.9121e-02],\n",
      "        [ 2.0252e-02],\n",
      "        [-3.7536e-02],\n",
      "        [-4.5078e-02],\n",
      "        [ 5.9949e-03],\n",
      "        [-1.6042e-01],\n",
      "        [ 3.5054e-02],\n",
      "        [-2.5688e-03],\n",
      "        [ 7.3669e-02],\n",
      "        [ 5.0597e-02],\n",
      "        [ 1.0763e-01],\n",
      "        [ 5.6273e-02],\n",
      "        [ 3.6259e-02],\n",
      "        [-8.3650e-02],\n",
      "        [ 7.3876e-02],\n",
      "        [-8.9800e-02],\n",
      "        [-3.2272e-02],\n",
      "        [-1.9993e-01],\n",
      "        [ 6.1558e-02],\n",
      "        [-1.1215e-01],\n",
      "        [-1.6265e-05],\n",
      "        [ 6.2158e-02],\n",
      "        [-7.6094e-02],\n",
      "        [-1.1973e-01],\n",
      "        [-2.9476e-02],\n",
      "        [ 3.1942e-03],\n",
      "        [ 8.0395e-02],\n",
      "        [-4.0353e-02],\n",
      "        [ 7.9005e-02],\n",
      "        [ 2.7361e-02],\n",
      "        [-4.2100e-02],\n",
      "        [ 1.1449e-02],\n",
      "        [ 1.9118e-01],\n",
      "        [-3.6251e-03],\n",
      "        [ 1.1114e-01],\n",
      "        [-3.3285e-02],\n",
      "        [ 5.0968e-02],\n",
      "        [ 2.4377e-03],\n",
      "        [ 2.3741e-02],\n",
      "        [ 9.1958e-02],\n",
      "        [ 6.2021e-02],\n",
      "        [ 6.2577e-02],\n",
      "        [ 2.0412e-02],\n",
      "        [-6.2733e-02],\n",
      "        [-4.9129e-02],\n",
      "        [-5.7277e-04],\n",
      "        [-6.2523e-02],\n",
      "        [ 2.5148e-01],\n",
      "        [ 3.8998e-03],\n",
      "        [-5.3617e-02],\n",
      "        [ 1.2609e-01],\n",
      "        [ 1.5387e-01],\n",
      "        [-4.2968e-02],\n",
      "        [-4.2364e-02],\n",
      "        [ 4.3640e-02],\n",
      "        [-1.3637e-02],\n",
      "        [ 9.0729e-02],\n",
      "        [-1.3629e-02],\n",
      "        [ 1.1592e-01],\n",
      "        [ 7.3834e-02],\n",
      "        [ 6.0543e-03],\n",
      "        [-3.0035e-03],\n",
      "        [ 1.3479e-01],\n",
      "        [-4.7470e-04],\n",
      "        [ 1.2457e-01],\n",
      "        [ 2.3565e-02],\n",
      "        [ 7.3850e-02],\n",
      "        [-1.1150e-02],\n",
      "        [ 9.7916e-02],\n",
      "        [-1.3275e-01],\n",
      "        [-2.0394e-02],\n",
      "        [ 2.9424e-02],\n",
      "        [-1.0093e-01],\n",
      "        [ 3.1324e-02],\n",
      "        [-7.4731e-02],\n",
      "        [-3.7466e-02],\n",
      "        [ 4.8397e-02],\n",
      "        [ 6.5614e-02],\n",
      "        [-6.4930e-02],\n",
      "        [ 1.6264e-01],\n",
      "        [ 3.4311e-02],\n",
      "        [-1.8747e-01],\n",
      "        [-7.2621e-02],\n",
      "        [-1.2781e-02],\n",
      "        [-1.0020e-01],\n",
      "        [-9.3253e-03],\n",
      "        [ 1.0874e-02],\n",
      "        [ 2.2829e-02],\n",
      "        [ 5.4288e-03],\n",
      "        [ 5.3807e-02],\n",
      "        [ 2.4620e-02],\n",
      "        [-4.1480e-02],\n",
      "        [-1.8539e-01],\n",
      "        [-1.8910e-02],\n",
      "        [-1.4453e-02],\n",
      "        [-4.1520e-03],\n",
      "        [-1.0041e-02],\n",
      "        [-1.1183e-01],\n",
      "        [-6.7215e-03],\n",
      "        [ 7.1836e-03],\n",
      "        [ 3.9122e-03],\n",
      "        [ 1.5751e-02],\n",
      "        [ 1.8118e-02],\n",
      "        [ 1.6847e-02],\n",
      "        [ 3.0333e-02],\n",
      "        [-2.1987e-02],\n",
      "        [ 1.8484e-02],\n",
      "        [-7.3441e-02],\n",
      "        [-2.0167e-03],\n",
      "        [-3.7900e-02],\n",
      "        [ 5.9823e-03],\n",
      "        [ 7.7834e-02],\n",
      "        [ 1.3569e-01],\n",
      "        [-1.9417e-01],\n",
      "        [ 9.9923e-03],\n",
      "        [-2.6412e-02],\n",
      "        [-1.5973e-02],\n",
      "        [ 8.6447e-02],\n",
      "        [-5.8717e-02],\n",
      "        [-6.1778e-03],\n",
      "        [-1.8886e-02],\n",
      "        [ 4.8119e-02],\n",
      "        [ 3.5106e-02],\n",
      "        [-1.5969e-02],\n",
      "        [-1.4198e-01],\n",
      "        [ 6.0864e-02],\n",
      "        [-5.6029e-02],\n",
      "        [ 5.7213e-02],\n",
      "        [-8.3906e-03],\n",
      "        [ 1.4145e-01],\n",
      "        [-6.0917e-02],\n",
      "        [ 6.1581e-03],\n",
      "        [ 2.3562e-02],\n",
      "        [-1.1788e-03],\n",
      "        [-1.9619e-01],\n",
      "        [-3.0953e-02],\n",
      "        [-2.8910e-02],\n",
      "        [ 1.1091e-01],\n",
      "        [ 7.5980e-02],\n",
      "        [ 4.8837e-02],\n",
      "        [-9.1631e-02],\n",
      "        [ 2.0129e-02],\n",
      "        [ 3.3922e-02],\n",
      "        [-2.3130e-02],\n",
      "        [ 3.6244e-02],\n",
      "        [ 5.1170e-04]], requires_grad=True))\n",
      "('hidden_b_mean.1', Parameter containing:\n",
      "tensor([[-3.6312e-02],\n",
      "        [ 2.8490e-02],\n",
      "        [ 1.7232e-02],\n",
      "        [-8.2028e-04],\n",
      "        [-2.0611e-02],\n",
      "        [ 5.2917e-06],\n",
      "        [-5.1921e-03],\n",
      "        [-4.5960e-02],\n",
      "        [-6.0339e-04],\n",
      "        [ 8.2919e-04],\n",
      "        [-8.6911e-02],\n",
      "        [ 5.5099e-02],\n",
      "        [ 3.9794e-02],\n",
      "        [ 9.0809e-04],\n",
      "        [ 1.9659e-02],\n",
      "        [-5.9163e-03],\n",
      "        [ 1.5546e-01],\n",
      "        [ 1.0398e-01],\n",
      "        [ 5.0915e-02],\n",
      "        [ 2.4693e-04],\n",
      "        [-6.1373e-02],\n",
      "        [-9.2126e-03],\n",
      "        [ 5.1024e-02],\n",
      "        [ 2.1770e-02],\n",
      "        [ 8.0736e-02],\n",
      "        [-1.4892e-03],\n",
      "        [-1.4570e-02],\n",
      "        [-1.4143e-02],\n",
      "        [ 7.5381e-04],\n",
      "        [-1.1055e-02],\n",
      "        [ 9.1714e-05],\n",
      "        [ 2.3212e-01],\n",
      "        [-1.3751e-01],\n",
      "        [-1.0486e-01],\n",
      "        [ 2.5238e-02],\n",
      "        [ 1.7165e-01],\n",
      "        [ 8.6688e-02],\n",
      "        [-5.2379e-02],\n",
      "        [-3.4369e-02],\n",
      "        [ 3.0196e-02],\n",
      "        [ 9.4098e-02],\n",
      "        [-1.4265e-01],\n",
      "        [ 3.8996e-02],\n",
      "        [ 1.5041e-02],\n",
      "        [-1.4892e-01],\n",
      "        [ 1.6451e-01],\n",
      "        [-1.1236e-02],\n",
      "        [-2.6780e-03],\n",
      "        [-8.5430e-02],\n",
      "        [ 5.0094e-02],\n",
      "        [-7.1993e-03],\n",
      "        [ 2.2133e-04],\n",
      "        [ 6.8571e-02],\n",
      "        [ 5.4122e-02],\n",
      "        [ 4.9634e-03],\n",
      "        [ 2.6668e-04],\n",
      "        [-3.0734e-02],\n",
      "        [ 5.7961e-02],\n",
      "        [ 3.7422e-02],\n",
      "        [-1.2301e-02],\n",
      "        [-1.1103e-02],\n",
      "        [-2.7504e-02],\n",
      "        [-8.7961e-02],\n",
      "        [ 7.0205e-03],\n",
      "        [-1.0324e-04],\n",
      "        [ 2.9333e-02],\n",
      "        [-1.8926e-02],\n",
      "        [-3.0135e-02],\n",
      "        [-7.0762e-02],\n",
      "        [-5.2723e-02],\n",
      "        [ 5.1823e-02],\n",
      "        [-4.0588e-03],\n",
      "        [-4.3188e-02],\n",
      "        [-3.4668e-02],\n",
      "        [-7.3843e-03],\n",
      "        [-1.0768e-01],\n",
      "        [-5.3480e-02],\n",
      "        [-1.6077e-02],\n",
      "        [ 2.1873e-02],\n",
      "        [-5.3538e-02],\n",
      "        [-5.6250e-03],\n",
      "        [ 3.6169e-02],\n",
      "        [ 9.9156e-02],\n",
      "        [ 4.7618e-02],\n",
      "        [ 1.0213e-01],\n",
      "        [-4.7445e-02],\n",
      "        [-2.8014e-05],\n",
      "        [ 5.6816e-02],\n",
      "        [-3.9200e-03],\n",
      "        [-1.3610e-01],\n",
      "        [ 1.6939e-04],\n",
      "        [-1.3684e-01],\n",
      "        [-2.1485e-01],\n",
      "        [ 1.0958e-01],\n",
      "        [ 3.8358e-02],\n",
      "        [ 7.6454e-02],\n",
      "        [-1.1474e-02],\n",
      "        [ 2.0180e-02],\n",
      "        [-1.8300e-02],\n",
      "        [-1.9262e-01],\n",
      "        [ 5.5978e-03],\n",
      "        [ 8.1850e-03],\n",
      "        [ 3.8791e-03],\n",
      "        [ 9.7516e-02],\n",
      "        [-1.0050e-02],\n",
      "        [ 1.2541e-02],\n",
      "        [ 8.8610e-02],\n",
      "        [ 5.4529e-02],\n",
      "        [ 5.5793e-02],\n",
      "        [-1.2293e-02],\n",
      "        [ 8.2965e-03],\n",
      "        [ 3.8768e-02],\n",
      "        [-4.0867e-02],\n",
      "        [-4.2411e-02],\n",
      "        [ 8.2871e-02],\n",
      "        [ 5.6029e-03],\n",
      "        [ 7.9852e-03],\n",
      "        [ 2.2684e-01],\n",
      "        [-8.4999e-02],\n",
      "        [ 2.8090e-02],\n",
      "        [-1.1743e-01],\n",
      "        [ 3.1628e-03],\n",
      "        [ 6.0619e-02],\n",
      "        [ 1.6872e-03],\n",
      "        [-1.2819e-02],\n",
      "        [-2.9211e-02],\n",
      "        [ 1.1010e-01],\n",
      "        [-8.6713e-02],\n",
      "        [-9.5553e-02],\n",
      "        [ 8.2845e-02],\n",
      "        [-7.3256e-02],\n",
      "        [ 1.5994e-02],\n",
      "        [-7.0682e-02],\n",
      "        [ 5.1481e-02],\n",
      "        [ 4.1300e-02],\n",
      "        [-2.6187e-02],\n",
      "        [-4.4337e-02],\n",
      "        [-1.0265e-02],\n",
      "        [-1.2699e-03],\n",
      "        [-6.1088e-03],\n",
      "        [ 4.4475e-02],\n",
      "        [ 4.9197e-02],\n",
      "        [ 5.8605e-02],\n",
      "        [ 2.1622e-02],\n",
      "        [ 2.2149e-05],\n",
      "        [ 1.0019e-02],\n",
      "        [-4.0957e-03],\n",
      "        [ 1.3224e-02],\n",
      "        [-1.7268e-02],\n",
      "        [ 9.9644e-02],\n",
      "        [-2.3726e-02],\n",
      "        [ 5.4157e-03],\n",
      "        [-8.2303e-03],\n",
      "        [ 3.4480e-02],\n",
      "        [ 9.0135e-05],\n",
      "        [-4.5870e-02],\n",
      "        [ 1.7120e-04],\n",
      "        [-1.9764e-02],\n",
      "        [ 7.0180e-02],\n",
      "        [ 4.6269e-02],\n",
      "        [ 3.7916e-03],\n",
      "        [-7.2907e-03],\n",
      "        [ 2.4986e-02],\n",
      "        [-3.1198e-02],\n",
      "        [-9.3255e-02],\n",
      "        [ 3.9664e-06],\n",
      "        [ 3.6444e-04],\n",
      "        [-2.3269e-02],\n",
      "        [-6.1975e-02],\n",
      "        [-2.6172e-02],\n",
      "        [-2.4171e-02],\n",
      "        [ 2.6749e-01],\n",
      "        [ 2.0323e-02],\n",
      "        [ 3.1143e-02],\n",
      "        [ 3.5388e-02],\n",
      "        [ 3.7654e-02],\n",
      "        [ 1.4578e-02],\n",
      "        [ 1.9712e-02],\n",
      "        [ 2.0862e-01],\n",
      "        [ 1.5437e-01],\n",
      "        [ 4.3546e-02],\n",
      "        [-6.3923e-02],\n",
      "        [ 9.5858e-02],\n",
      "        [-1.5360e-01],\n",
      "        [ 4.2456e-02],\n",
      "        [-7.5079e-02],\n",
      "        [ 4.7066e-02],\n",
      "        [-1.1735e-01],\n",
      "        [-6.5835e-02],\n",
      "        [-2.1895e-01],\n",
      "        [ 5.7294e-02],\n",
      "        [ 1.1232e-01],\n",
      "        [-8.3381e-02],\n",
      "        [-1.8704e-02],\n",
      "        [-4.0886e-02],\n",
      "        [-1.2013e-01],\n",
      "        [-7.9746e-02],\n",
      "        [-5.4271e-02],\n",
      "        [-4.9910e-02],\n",
      "        [ 1.0582e-01],\n",
      "        [ 4.3431e-02],\n",
      "        [ 2.1714e-02],\n",
      "        [ 3.2109e-02],\n",
      "        [-2.0517e-02],\n",
      "        [-1.0546e-06],\n",
      "        [ 3.2413e-04],\n",
      "        [-1.8422e-02],\n",
      "        [ 3.0385e-04],\n",
      "        [-4.9367e-02],\n",
      "        [ 1.1012e-01],\n",
      "        [ 3.7239e-03],\n",
      "        [-4.0507e-02],\n",
      "        [-3.2552e-02],\n",
      "        [ 2.6026e-02],\n",
      "        [-3.0286e-05],\n",
      "        [ 4.2261e-02],\n",
      "        [-4.6734e-02],\n",
      "        [ 1.8901e-03],\n",
      "        [ 4.2066e-02],\n",
      "        [-7.0516e-05],\n",
      "        [ 3.0497e-02],\n",
      "        [-2.0328e-02],\n",
      "        [-3.2713e-02],\n",
      "        [ 3.0314e-04],\n",
      "        [ 1.8779e-02],\n",
      "        [-3.4621e-02],\n",
      "        [-2.4500e-01],\n",
      "        [ 8.7792e-03],\n",
      "        [ 8.9310e-02],\n",
      "        [ 1.0115e-01],\n",
      "        [-2.0192e-02],\n",
      "        [-4.9037e-03],\n",
      "        [ 5.1146e-02],\n",
      "        [ 4.6662e-02],\n",
      "        [-4.5354e-02],\n",
      "        [-1.9046e-02],\n",
      "        [-7.4044e-03],\n",
      "        [-1.1601e-01],\n",
      "        [-1.6050e-01],\n",
      "        [-9.5554e-05],\n",
      "        [ 7.9434e-02],\n",
      "        [ 1.2204e-01],\n",
      "        [ 8.7203e-03],\n",
      "        [-3.7262e-02],\n",
      "        [ 1.4124e-02],\n",
      "        [ 6.1389e-05],\n",
      "        [-1.3399e-01],\n",
      "        [-3.9269e-03],\n",
      "        [ 5.3738e-02],\n",
      "        [-9.8267e-02],\n",
      "        [ 7.6763e-02],\n",
      "        [ 1.8124e-04],\n",
      "        [-3.0153e-02],\n",
      "        [ 1.7637e-02],\n",
      "        [ 2.8279e-04],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 6.7101e-03]], requires_grad=True))\n",
      "('hidden_w_var.0', Parameter containing:\n",
      "tensor([[-5.8802, -5.8802, -5.8802,  ..., -5.8802, -5.8802, -5.8802],\n",
      "        [-5.8802, -5.8802, -5.8802,  ..., -5.8802, -5.8802, -5.8802],\n",
      "        [-5.8802, -5.8802, -5.8802,  ..., -5.8802, -5.8802, -5.8802],\n",
      "        ...,\n",
      "        [-5.8802, -5.8802, -5.8802,  ..., -5.8802, -5.8802, -5.8802],\n",
      "        [-5.8802, -5.8802, -5.8802,  ..., -5.8802, -5.8802, -5.8802],\n",
      "        [-5.8802, -5.8802, -5.8802,  ..., -5.8802, -5.8802, -5.8802]],\n",
      "       requires_grad=True))\n",
      "('hidden_w_var.1', Parameter containing:\n",
      "tensor([[-5.8801, -5.8784, -5.8801,  ..., -5.8815, -5.8802, -5.8799],\n",
      "        [-5.8800, -5.8802, -5.8801,  ..., -5.8787, -5.8800, -5.8807],\n",
      "        [-5.8802, -5.8803, -5.8802,  ..., -5.8801, -5.8802, -5.8801],\n",
      "        ...,\n",
      "        [-5.8803, -5.8811, -5.8801,  ..., -5.8796, -5.8801, -5.8806],\n",
      "        [-5.8802, -5.8802, -5.8802,  ..., -5.8802, -5.8802, -5.8802],\n",
      "        [-5.8802, -5.8801, -5.8802,  ..., -5.8802, -5.8802, -5.8802]],\n",
      "       requires_grad=True))\n",
      "('hidden_b_var.0', Parameter containing:\n",
      "tensor([[-5.8710],\n",
      "        [-5.8713],\n",
      "        [-5.8802],\n",
      "        [-5.8796],\n",
      "        [-5.8801],\n",
      "        [-5.8805],\n",
      "        [-5.8778],\n",
      "        [-5.8797],\n",
      "        [-5.8696],\n",
      "        [-5.8805],\n",
      "        [-5.8817],\n",
      "        [-5.8749],\n",
      "        [-5.8819],\n",
      "        [-5.8794],\n",
      "        [-5.8729],\n",
      "        [-5.8823],\n",
      "        [-5.8800],\n",
      "        [-5.8743],\n",
      "        [-5.8743],\n",
      "        [-5.8803],\n",
      "        [-5.8800],\n",
      "        [-5.8841],\n",
      "        [-5.8686],\n",
      "        [-5.8775],\n",
      "        [-5.8771],\n",
      "        [-5.8768],\n",
      "        [-5.8761],\n",
      "        [-5.8799],\n",
      "        [-5.8808],\n",
      "        [-5.8790],\n",
      "        [-5.8811],\n",
      "        [-5.8841],\n",
      "        [-5.8792],\n",
      "        [-5.8750],\n",
      "        [-5.8802],\n",
      "        [-5.8800],\n",
      "        [-5.8824],\n",
      "        [-5.8803],\n",
      "        [-5.8757],\n",
      "        [-5.8802],\n",
      "        [-5.8747],\n",
      "        [-5.8739],\n",
      "        [-5.8751],\n",
      "        [-5.8771],\n",
      "        [-5.8613],\n",
      "        [-5.8805],\n",
      "        [-5.8814],\n",
      "        [-5.8795],\n",
      "        [-5.8753],\n",
      "        [-5.8805],\n",
      "        [-5.8784],\n",
      "        [-5.8831],\n",
      "        [-5.8701],\n",
      "        [-5.8649],\n",
      "        [-5.8762],\n",
      "        [-5.8824],\n",
      "        [-5.8800],\n",
      "        [-5.8801],\n",
      "        [-5.8740],\n",
      "        [-5.8728],\n",
      "        [-5.8846],\n",
      "        [-5.8814],\n",
      "        [-5.8782],\n",
      "        [-5.8827],\n",
      "        [-5.8808],\n",
      "        [-5.8804],\n",
      "        [-5.8825],\n",
      "        [-5.8755],\n",
      "        [-5.8738],\n",
      "        [-5.8739],\n",
      "        [-5.8783],\n",
      "        [-5.8866],\n",
      "        [-5.8807],\n",
      "        [-5.8798],\n",
      "        [-5.8781],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8803],\n",
      "        [-5.8801],\n",
      "        [-5.8794],\n",
      "        [-5.8853],\n",
      "        [-5.8809],\n",
      "        [-5.8781],\n",
      "        [-5.8736],\n",
      "        [-5.8685],\n",
      "        [-5.8785],\n",
      "        [-5.8791],\n",
      "        [-5.8802],\n",
      "        [-5.8792],\n",
      "        [-5.8780],\n",
      "        [-5.8807],\n",
      "        [-5.8780],\n",
      "        [-5.8777],\n",
      "        [-5.8790],\n",
      "        [-5.8681],\n",
      "        [-5.8797],\n",
      "        [-5.8818],\n",
      "        [-5.8802],\n",
      "        [-5.8710],\n",
      "        [-5.8799],\n",
      "        [-5.8835],\n",
      "        [-5.8837],\n",
      "        [-5.8849],\n",
      "        [-5.8808],\n",
      "        [-5.8873],\n",
      "        [-5.8791],\n",
      "        [-5.8706],\n",
      "        [-5.8802],\n",
      "        [-5.8808],\n",
      "        [-5.8908],\n",
      "        [-5.8791],\n",
      "        [-5.8780],\n",
      "        [-5.8805],\n",
      "        [-5.8720],\n",
      "        [-5.8809],\n",
      "        [-5.8756],\n",
      "        [-5.8801],\n",
      "        [-5.8803],\n",
      "        [-5.8805],\n",
      "        [-5.8803],\n",
      "        [-5.8785],\n",
      "        [-5.8759],\n",
      "        [-5.8830],\n",
      "        [-5.8836],\n",
      "        [-5.8762],\n",
      "        [-5.8777],\n",
      "        [-5.8803],\n",
      "        [-5.8804],\n",
      "        [-5.8711],\n",
      "        [-5.8781],\n",
      "        [-5.8801],\n",
      "        [-5.8829],\n",
      "        [-5.8804],\n",
      "        [-5.8801],\n",
      "        [-5.8801],\n",
      "        [-5.8803],\n",
      "        [-5.8805],\n",
      "        [-5.8791],\n",
      "        [-5.8797],\n",
      "        [-5.8886],\n",
      "        [-5.8818],\n",
      "        [-5.8834],\n",
      "        [-5.8768],\n",
      "        [-5.8802],\n",
      "        [-5.8840],\n",
      "        [-5.8803],\n",
      "        [-5.8779],\n",
      "        [-5.8801],\n",
      "        [-5.8801],\n",
      "        [-5.8646],\n",
      "        [-5.8715],\n",
      "        [-5.8769],\n",
      "        [-5.8891],\n",
      "        [-5.8765],\n",
      "        [-5.8814],\n",
      "        [-5.8798],\n",
      "        [-5.8747],\n",
      "        [-5.8718],\n",
      "        [-5.8806],\n",
      "        [-5.8816],\n",
      "        [-5.8796],\n",
      "        [-5.8868],\n",
      "        [-5.8896],\n",
      "        [-5.8704],\n",
      "        [-5.8849],\n",
      "        [-5.8807],\n",
      "        [-5.8728],\n",
      "        [-5.8790],\n",
      "        [-5.8771],\n",
      "        [-5.8787],\n",
      "        [-5.8822],\n",
      "        [-5.8810],\n",
      "        [-5.8701],\n",
      "        [-5.8806],\n",
      "        [-5.8749],\n",
      "        [-5.8671],\n",
      "        [-5.8796],\n",
      "        [-5.8717],\n",
      "        [-5.8755],\n",
      "        [-5.8751],\n",
      "        [-5.8746],\n",
      "        [-5.8795],\n",
      "        [-5.8757],\n",
      "        [-5.8768],\n",
      "        [-5.8802],\n",
      "        [-5.8816],\n",
      "        [-5.8889],\n",
      "        [-5.8758],\n",
      "        [-5.8799],\n",
      "        [-5.8699],\n",
      "        [-5.8720],\n",
      "        [-5.8812],\n",
      "        [-5.8802],\n",
      "        [-5.8823],\n",
      "        [-5.8824],\n",
      "        [-5.8802],\n",
      "        [-5.8822],\n",
      "        [-5.8899],\n",
      "        [-5.8816],\n",
      "        [-5.8752],\n",
      "        [-5.8797],\n",
      "        [-5.8804],\n",
      "        [-5.8850],\n",
      "        [-5.8803],\n",
      "        [-5.8792],\n",
      "        [-5.8780],\n",
      "        [-5.8790],\n",
      "        [-5.8801],\n",
      "        [-5.8724],\n",
      "        [-5.8811],\n",
      "        [-5.8802],\n",
      "        [-5.8848],\n",
      "        [-5.8749],\n",
      "        [-5.8791],\n",
      "        [-5.8832],\n",
      "        [-5.8836],\n",
      "        [-5.8800],\n",
      "        [-5.8750],\n",
      "        [-5.8805],\n",
      "        [-5.8807],\n",
      "        [-5.8794],\n",
      "        [-5.8754],\n",
      "        [-5.8745],\n",
      "        [-5.8815],\n",
      "        [-5.8768],\n",
      "        [-5.8774],\n",
      "        [-5.8800],\n",
      "        [-5.8791],\n",
      "        [-5.8762],\n",
      "        [-5.8722],\n",
      "        [-5.8822],\n",
      "        [-5.8804],\n",
      "        [-5.8818],\n",
      "        [-5.8808],\n",
      "        [-5.8805],\n",
      "        [-5.8808],\n",
      "        [-5.8795],\n",
      "        [-5.8805],\n",
      "        [-5.8804],\n",
      "        [-5.8822],\n",
      "        [-5.8801],\n",
      "        [-5.8825],\n",
      "        [-5.8802],\n",
      "        [-5.8800],\n",
      "        [-5.8803],\n",
      "        [-5.8803],\n",
      "        [-5.8793],\n",
      "        [-5.8743],\n",
      "        [-5.8818],\n",
      "        [-5.8804],\n",
      "        [-5.8746],\n",
      "        [-5.8783],\n",
      "        [-5.8804],\n",
      "        [-5.8840],\n",
      "        [-5.8802],\n",
      "        [-5.8802]], requires_grad=True))\n",
      "('hidden_b_var.1', Parameter containing:\n",
      "tensor([[-5.8800],\n",
      "        [-5.8779],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8803],\n",
      "        [-5.8802],\n",
      "        [-5.8789],\n",
      "        [-5.8758],\n",
      "        [-5.8806],\n",
      "        [-5.8771],\n",
      "        [-5.8794],\n",
      "        [-5.8685],\n",
      "        [-5.8793],\n",
      "        [-5.8805],\n",
      "        [-5.8792],\n",
      "        [-5.8796],\n",
      "        [-5.8723],\n",
      "        [-5.8798],\n",
      "        [-5.8798],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8796],\n",
      "        [-5.8796],\n",
      "        [-5.8773],\n",
      "        [-5.8775],\n",
      "        [-5.8717],\n",
      "        [-5.8814],\n",
      "        [-5.8806],\n",
      "        [-5.8801],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8743],\n",
      "        [-5.8802],\n",
      "        [-5.8763],\n",
      "        [-5.8764],\n",
      "        [-5.8726],\n",
      "        [-5.8754],\n",
      "        [-5.8795],\n",
      "        [-5.8804],\n",
      "        [-5.8795],\n",
      "        [-5.8725],\n",
      "        [-5.8837],\n",
      "        [-5.8761],\n",
      "        [-5.8816],\n",
      "        [-5.8817],\n",
      "        [-5.8809],\n",
      "        [-5.8768],\n",
      "        [-5.8670],\n",
      "        [-5.8861],\n",
      "        [-5.8800],\n",
      "        [-5.8787],\n",
      "        [-5.8802],\n",
      "        [-5.8792],\n",
      "        [-5.8730],\n",
      "        [-5.8824],\n",
      "        [-5.8802],\n",
      "        [-5.8788],\n",
      "        [-5.8782],\n",
      "        [-5.8801],\n",
      "        [-5.8796],\n",
      "        [-5.8802],\n",
      "        [-5.8772],\n",
      "        [-5.8790],\n",
      "        [-5.8802],\n",
      "        [-5.8801],\n",
      "        [-5.8799],\n",
      "        [-5.8813],\n",
      "        [-5.8805],\n",
      "        [-5.8805],\n",
      "        [-5.8805],\n",
      "        [-5.8827],\n",
      "        [-5.8802],\n",
      "        [-5.8795],\n",
      "        [-5.8779],\n",
      "        [-5.8802],\n",
      "        [-5.8809],\n",
      "        [-5.8805],\n",
      "        [-5.8843],\n",
      "        [-5.8783],\n",
      "        [-5.8802],\n",
      "        [-5.8796],\n",
      "        [-5.8804],\n",
      "        [-5.8818],\n",
      "        [-5.8791],\n",
      "        [-5.8753],\n",
      "        [-5.8812],\n",
      "        [-5.8802],\n",
      "        [-5.8788],\n",
      "        [-5.8798],\n",
      "        [-5.8770],\n",
      "        [-5.8802],\n",
      "        [-5.8763],\n",
      "        [-5.8750],\n",
      "        [-5.8819],\n",
      "        [-5.8805],\n",
      "        [-5.8821],\n",
      "        [-5.8766],\n",
      "        [-5.8782],\n",
      "        [-5.8801],\n",
      "        [-5.8802],\n",
      "        [-5.8792],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8780],\n",
      "        [-5.8809],\n",
      "        [-5.8797],\n",
      "        [-5.8743],\n",
      "        [-5.8750],\n",
      "        [-5.8772],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8801],\n",
      "        [-5.8784],\n",
      "        [-5.8802],\n",
      "        [-5.8788],\n",
      "        [-5.8814],\n",
      "        [-5.8775],\n",
      "        [-5.8770],\n",
      "        [-5.8792],\n",
      "        [-5.8787],\n",
      "        [-5.8720],\n",
      "        [-5.8802],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8801],\n",
      "        [-5.8807],\n",
      "        [-5.8800],\n",
      "        [-5.8810],\n",
      "        [-5.8798],\n",
      "        [-5.8797],\n",
      "        [-5.8836],\n",
      "        [-5.8764],\n",
      "        [-5.8794],\n",
      "        [-5.8800],\n",
      "        [-5.8779],\n",
      "        [-5.8770],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8840],\n",
      "        [-5.8817],\n",
      "        [-5.8802],\n",
      "        [-5.8760],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8807],\n",
      "        [-5.8805],\n",
      "        [-5.8784],\n",
      "        [-5.8779],\n",
      "        [-5.8810],\n",
      "        [-5.8804],\n",
      "        [-5.8802],\n",
      "        [-5.8798],\n",
      "        [-5.8802],\n",
      "        [-5.8812],\n",
      "        [-5.8802],\n",
      "        [-5.8800],\n",
      "        [-5.8820],\n",
      "        [-5.8812],\n",
      "        [-5.8799],\n",
      "        [-5.8799],\n",
      "        [-5.8790],\n",
      "        [-5.8720],\n",
      "        [-5.8766],\n",
      "        [-5.8802],\n",
      "        [-5.8806],\n",
      "        [-5.8798],\n",
      "        [-5.8800],\n",
      "        [-5.8767],\n",
      "        [-5.8731],\n",
      "        [-5.8847],\n",
      "        [-5.8799],\n",
      "        [-5.8791],\n",
      "        [-5.8786],\n",
      "        [-5.8781],\n",
      "        [-5.8780],\n",
      "        [-5.8802],\n",
      "        [-5.8812],\n",
      "        [-5.8800],\n",
      "        [-5.8812],\n",
      "        [-5.8799],\n",
      "        [-5.8796],\n",
      "        [-5.8789],\n",
      "        [-5.8795],\n",
      "        [-5.8797],\n",
      "        [-5.8753],\n",
      "        [-5.8742],\n",
      "        [-5.8796],\n",
      "        [-5.8785],\n",
      "        [-5.8727],\n",
      "        [-5.8782],\n",
      "        [-5.8768],\n",
      "        [-5.8703],\n",
      "        [-5.8811],\n",
      "        [-5.8804],\n",
      "        [-5.8807],\n",
      "        [-5.8800],\n",
      "        [-5.8783],\n",
      "        [-5.8796],\n",
      "        [-5.8789],\n",
      "        [-5.8815],\n",
      "        [-5.8842],\n",
      "        [-5.8786],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8807],\n",
      "        [-5.8802],\n",
      "        [-5.8810],\n",
      "        [-5.8736],\n",
      "        [-5.8805],\n",
      "        [-5.8805],\n",
      "        [-5.8802],\n",
      "        [-5.8829],\n",
      "        [-5.8802],\n",
      "        [-5.8843],\n",
      "        [-5.8808],\n",
      "        [-5.8797],\n",
      "        [-5.8803],\n",
      "        [-5.8804],\n",
      "        [-5.8815],\n",
      "        [-5.8816],\n",
      "        [-5.8801],\n",
      "        [-5.8802],\n",
      "        [-5.8808],\n",
      "        [-5.8799],\n",
      "        [-5.8782],\n",
      "        [-5.8759],\n",
      "        [-5.8804],\n",
      "        [-5.8769],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8892],\n",
      "        [-5.8805],\n",
      "        [-5.8828],\n",
      "        [-5.8809],\n",
      "        [-5.8771],\n",
      "        [-5.8806],\n",
      "        [-5.8820],\n",
      "        [-5.8805],\n",
      "        [-5.8801],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8811],\n",
      "        [-5.8779],\n",
      "        [-5.8802],\n",
      "        [-5.8777],\n",
      "        [-5.8731],\n",
      "        [-5.8771],\n",
      "        [-5.8793],\n",
      "        [-5.8805],\n",
      "        [-5.8802],\n",
      "        [-5.8799],\n",
      "        [-5.8806],\n",
      "        [-5.8801],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-5.8782]], requires_grad=True))\n",
      "('out_layers_w_mean.0', Parameter containing:\n",
      "tensor([[ 2.0165e-03],\n",
      "        [-1.7265e-01],\n",
      "        [-1.7662e-03],\n",
      "        [ 6.0971e-05],\n",
      "        [-2.1901e-02],\n",
      "        [-1.1287e-05],\n",
      "        [-4.3244e-02],\n",
      "        [-2.7533e-01],\n",
      "        [ 1.0805e-02],\n",
      "        [-1.5046e-01],\n",
      "        [-2.3073e-01],\n",
      "        [ 2.2659e-01],\n",
      "        [ 1.8993e-01],\n",
      "        [ 4.7582e-02],\n",
      "        [ 3.1509e-02],\n",
      "        [ 2.3535e-02],\n",
      "        [-2.1575e-01],\n",
      "        [-7.2218e-02],\n",
      "        [-9.3406e-03],\n",
      "        [ 4.8632e-02],\n",
      "        [-1.6986e-02],\n",
      "        [-1.0963e-01],\n",
      "        [-4.5792e-02],\n",
      "        [-1.0618e-01],\n",
      "        [-1.0393e-01],\n",
      "        [-2.4567e-01],\n",
      "        [ 4.0582e-02],\n",
      "        [-1.6268e-01],\n",
      "        [ 7.7381e-03],\n",
      "        [-3.3809e-03],\n",
      "        [-3.3744e-05],\n",
      "        [-1.5984e-01],\n",
      "        [ 1.8125e-02],\n",
      "        [ 1.4298e-01],\n",
      "        [-1.8286e-01],\n",
      "        [ 1.7189e-01],\n",
      "        [-2.0789e-01],\n",
      "        [ 1.0886e-01],\n",
      "        [ 1.2701e-02],\n",
      "        [ 2.7566e-02],\n",
      "        [ 1.9671e-01],\n",
      "        [ 3.3711e-01],\n",
      "        [ 1.4722e-01],\n",
      "        [ 6.0803e-02],\n",
      "        [ 2.1356e-01],\n",
      "        [-1.0040e-01],\n",
      "        [ 1.0812e-01],\n",
      "        [ 1.9492e-01],\n",
      "        [ 1.7953e-01],\n",
      "        [-1.4573e-02],\n",
      "        [ 5.3436e-02],\n",
      "        [-2.1415e-02],\n",
      "        [ 4.2533e-02],\n",
      "        [-2.0225e-01],\n",
      "        [-1.1261e-01],\n",
      "        [-9.3869e-04],\n",
      "        [ 2.8272e-02],\n",
      "        [ 8.5332e-02],\n",
      "        [-3.5247e-02],\n",
      "        [ 3.0079e-02],\n",
      "        [ 1.2146e-02],\n",
      "        [ 3.6067e-02],\n",
      "        [ 1.1110e-01],\n",
      "        [-6.0333e-03],\n",
      "        [ 7.4176e-03],\n",
      "        [-1.3151e-01],\n",
      "        [ 5.5640e-02],\n",
      "        [-3.8252e-02],\n",
      "        [-3.2399e-02],\n",
      "        [ 2.3668e-02],\n",
      "        [-4.8376e-02],\n",
      "        [-3.4830e-04],\n",
      "        [ 2.7197e-02],\n",
      "        [ 7.8716e-02],\n",
      "        [-1.2796e-02],\n",
      "        [-1.6526e-01],\n",
      "        [-8.2087e-02],\n",
      "        [-1.3573e-01],\n",
      "        [-1.1565e-01],\n",
      "        [ 3.2209e-05],\n",
      "        [-4.0873e-02],\n",
      "        [ 1.2867e-02],\n",
      "        [-1.4457e-01],\n",
      "        [ 4.1871e-02],\n",
      "        [-1.5032e-01],\n",
      "        [ 9.7116e-02],\n",
      "        [-5.6539e-05],\n",
      "        [ 2.9614e-01],\n",
      "        [-4.1324e-02],\n",
      "        [ 2.0103e-01],\n",
      "        [ 7.8375e-04],\n",
      "        [-1.8988e-01],\n",
      "        [-1.3029e-01],\n",
      "        [-1.8462e-01],\n",
      "        [-6.6442e-02],\n",
      "        [ 1.3860e-01],\n",
      "        [-1.1331e-01],\n",
      "        [-6.1270e-02],\n",
      "        [-3.7757e-02],\n",
      "        [ 5.8636e-02],\n",
      "        [-1.0323e-02],\n",
      "        [ 3.7217e-06],\n",
      "        [-2.5474e-02],\n",
      "        [-1.5164e-01],\n",
      "        [ 1.7393e-03],\n",
      "        [-6.5174e-02],\n",
      "        [-1.2442e-01],\n",
      "        [-9.5840e-02],\n",
      "        [-1.4544e-01],\n",
      "        [-4.0270e-02],\n",
      "        [ 9.5900e-03],\n",
      "        [-3.9272e-02],\n",
      "        [ 6.7754e-02],\n",
      "        [ 7.3464e-03],\n",
      "        [ 1.6788e-01],\n",
      "        [-1.2608e-01],\n",
      "        [-7.4308e-02],\n",
      "        [-9.5390e-02],\n",
      "        [-1.2233e-01],\n",
      "        [-6.7624e-02],\n",
      "        [ 1.9540e-01],\n",
      "        [-1.8006e-02],\n",
      "        [ 4.2555e-02],\n",
      "        [-2.5703e-03],\n",
      "        [-1.2810e-02],\n",
      "        [ 5.8363e-03],\n",
      "        [ 9.9593e-02],\n",
      "        [ 1.6739e-02],\n",
      "        [-2.5058e-02],\n",
      "        [-1.0319e-01],\n",
      "        [ 5.6963e-02],\n",
      "        [ 1.3156e-01],\n",
      "        [-1.5832e-01],\n",
      "        [-3.7526e-02],\n",
      "        [ 1.9300e-02],\n",
      "        [ 1.9082e-01],\n",
      "        [-9.3931e-02],\n",
      "        [ 3.4533e-05],\n",
      "        [-2.2223e-03],\n",
      "        [ 2.4717e-05],\n",
      "        [-2.1843e-01],\n",
      "        [-5.3448e-02],\n",
      "        [-1.5160e-01],\n",
      "        [ 5.5073e-02],\n",
      "        [ 7.4474e-05],\n",
      "        [ 5.5013e-03],\n",
      "        [-1.2494e-01],\n",
      "        [ 2.0745e-01],\n",
      "        [-1.9022e-01],\n",
      "        [ 7.5749e-02],\n",
      "        [ 6.3495e-02],\n",
      "        [-2.5964e-02],\n",
      "        [ 2.2943e-02],\n",
      "        [ 1.0298e-01],\n",
      "        [ 5.7047e-04],\n",
      "        [ 1.5890e-01],\n",
      "        [-1.7124e-02],\n",
      "        [-2.8453e-02],\n",
      "        [ 1.2347e-01],\n",
      "        [ 8.5631e-05],\n",
      "        [-3.0027e-02],\n",
      "        [-6.8924e-02],\n",
      "        [ 1.3846e-01],\n",
      "        [ 2.0017e-01],\n",
      "        [-1.5240e-01],\n",
      "        [-2.1329e-05],\n",
      "        [ 1.4738e-02],\n",
      "        [-6.9021e-02],\n",
      "        [ 3.0664e-02],\n",
      "        [ 1.0352e-01],\n",
      "        [-1.7516e-01],\n",
      "        [-1.8558e-01],\n",
      "        [ 8.8368e-02],\n",
      "        [-5.1097e-02],\n",
      "        [ 8.0328e-02],\n",
      "        [-2.4668e-01],\n",
      "        [ 1.6075e-01],\n",
      "        [ 1.3436e-01],\n",
      "        [-4.6077e-02],\n",
      "        [ 6.7098e-02],\n",
      "        [-9.2253e-02],\n",
      "        [-5.8747e-02],\n",
      "        [ 2.5989e-01],\n",
      "        [-1.4903e-01],\n",
      "        [-6.9673e-02],\n",
      "        [ 1.3124e-01],\n",
      "        [ 1.5722e-01],\n",
      "        [ 2.7166e-01],\n",
      "        [ 7.8081e-02],\n",
      "        [-1.0675e-01],\n",
      "        [-2.3126e-01],\n",
      "        [ 7.7908e-02],\n",
      "        [ 1.0076e-01],\n",
      "        [-1.5192e-01],\n",
      "        [ 1.8745e-01],\n",
      "        [-1.2625e-02],\n",
      "        [ 1.0418e-01],\n",
      "        [-1.9146e-02],\n",
      "        [-1.1025e-01],\n",
      "        [ 7.0198e-02],\n",
      "        [-8.7840e-02],\n",
      "        [-1.8933e-02],\n",
      "        [-8.9354e-02],\n",
      "        [ 8.6442e-02],\n",
      "        [ 4.9218e-05],\n",
      "        [-2.1364e-02],\n",
      "        [-4.3434e-04],\n",
      "        [-7.2917e-03],\n",
      "        [ 2.5427e-01],\n",
      "        [ 9.0911e-02],\n",
      "        [-2.7097e-02],\n",
      "        [ 1.3357e-02],\n",
      "        [-1.7363e-02],\n",
      "        [-1.2570e-01],\n",
      "        [ 1.3425e-02],\n",
      "        [ 1.3905e-01],\n",
      "        [-1.0716e-03],\n",
      "        [ 6.0342e-03],\n",
      "        [-3.1517e-03],\n",
      "        [ 4.9907e-04],\n",
      "        [ 4.6921e-02],\n",
      "        [-6.3788e-02],\n",
      "        [ 2.7610e-02],\n",
      "        [-2.5135e-03],\n",
      "        [-7.3243e-02],\n",
      "        [-2.9245e-02],\n",
      "        [-1.4567e-01],\n",
      "        [-1.3257e-01],\n",
      "        [ 8.6144e-02],\n",
      "        [-2.0133e-01],\n",
      "        [ 6.2276e-02],\n",
      "        [ 1.2694e-04],\n",
      "        [ 2.9202e-01],\n",
      "        [ 2.4067e-02],\n",
      "        [ 4.8462e-02],\n",
      "        [ 7.4806e-02],\n",
      "        [-1.2851e-01],\n",
      "        [ 7.6985e-02],\n",
      "        [-9.3647e-02],\n",
      "        [-3.3474e-02],\n",
      "        [-1.3625e-02],\n",
      "        [-3.3716e-02],\n",
      "        [ 3.4271e-02],\n",
      "        [ 2.2879e-01],\n",
      "        [ 1.2053e-01],\n",
      "        [-9.0215e-05],\n",
      "        [ 5.8853e-02],\n",
      "        [ 2.6185e-01],\n",
      "        [-1.6527e-01],\n",
      "        [ 7.2312e-02],\n",
      "        [ 5.9689e-02],\n",
      "        [ 1.0735e-02],\n",
      "        [-2.5367e-02],\n",
      "        [ 3.3574e-02],\n",
      "        [-3.0648e-04],\n",
      "        [-3.0215e-02]], requires_grad=True))\n",
      "('out_layers_w_mean.1', Parameter containing:\n",
      "tensor([[-2.6625e-02],\n",
      "        [-1.6624e-01],\n",
      "        [ 5.7399e-03],\n",
      "        [ 1.9261e-04],\n",
      "        [-2.3184e-02],\n",
      "        [ 6.5201e-05],\n",
      "        [-1.0464e-01],\n",
      "        [-2.6223e-01],\n",
      "        [ 2.5114e-02],\n",
      "        [-1.5653e-01],\n",
      "        [-2.2018e-01],\n",
      "        [ 2.1472e-01],\n",
      "        [ 1.9405e-01],\n",
      "        [ 3.4702e-02],\n",
      "        [ 5.6014e-02],\n",
      "        [ 2.3495e-02],\n",
      "        [-2.0396e-01],\n",
      "        [-5.8094e-02],\n",
      "        [-2.5476e-02],\n",
      "        [ 5.4170e-02],\n",
      "        [-1.8473e-02],\n",
      "        [-9.8852e-02],\n",
      "        [-3.2103e-02],\n",
      "        [-1.0305e-01],\n",
      "        [-9.4236e-02],\n",
      "        [-2.3559e-01],\n",
      "        [ 5.6100e-02],\n",
      "        [-1.5096e-01],\n",
      "        [ 3.3905e-03],\n",
      "        [-2.2513e-03],\n",
      "        [-2.9689e-05],\n",
      "        [-1.4735e-01],\n",
      "        [ 8.7698e-03],\n",
      "        [ 1.3341e-01],\n",
      "        [-1.6956e-01],\n",
      "        [ 1.6495e-01],\n",
      "        [-2.0219e-01],\n",
      "        [ 1.0160e-01],\n",
      "        [ 3.6916e-02],\n",
      "        [ 3.8737e-02],\n",
      "        [ 1.8712e-01],\n",
      "        [ 3.2487e-01],\n",
      "        [ 1.4782e-01],\n",
      "        [ 6.2572e-02],\n",
      "        [ 2.0468e-01],\n",
      "        [-1.2408e-01],\n",
      "        [ 1.1390e-01],\n",
      "        [ 1.9994e-01],\n",
      "        [ 2.1089e-01],\n",
      "        [-3.2696e-03],\n",
      "        [ 6.1724e-02],\n",
      "        [-6.3363e-03],\n",
      "        [ 7.1155e-02],\n",
      "        [-1.9371e-01],\n",
      "        [-1.0890e-01],\n",
      "        [-1.0386e-03],\n",
      "        [ 5.1320e-02],\n",
      "        [ 1.0645e-01],\n",
      "        [-3.7535e-02],\n",
      "        [ 4.9370e-02],\n",
      "        [ 1.5365e-02],\n",
      "        [ 1.0011e-01],\n",
      "        [ 1.1162e-01],\n",
      "        [-2.2224e-02],\n",
      "        [ 8.5546e-03],\n",
      "        [-1.3833e-01],\n",
      "        [ 5.8195e-02],\n",
      "        [-3.4802e-02],\n",
      "        [-1.9237e-02],\n",
      "        [ 2.3121e-02],\n",
      "        [-5.7560e-02],\n",
      "        [-1.0804e-04],\n",
      "        [ 6.9207e-03],\n",
      "        [ 1.2307e-01],\n",
      "        [-1.6080e-02],\n",
      "        [-1.5200e-01],\n",
      "        [-7.4296e-02],\n",
      "        [-1.2184e-01],\n",
      "        [-1.0708e-01],\n",
      "        [ 6.2202e-04],\n",
      "        [-7.1304e-02],\n",
      "        [-9.3273e-03],\n",
      "        [-1.3008e-01],\n",
      "        [ 4.0664e-02],\n",
      "        [-1.5225e-01],\n",
      "        [ 1.2799e-01],\n",
      "        [-2.5126e-04],\n",
      "        [ 2.8284e-01],\n",
      "        [-7.8665e-02],\n",
      "        [ 2.1083e-01],\n",
      "        [ 1.0267e-03],\n",
      "        [-1.8282e-01],\n",
      "        [-1.2481e-01],\n",
      "        [-1.6964e-01],\n",
      "        [-6.4227e-02],\n",
      "        [ 1.3005e-01],\n",
      "        [-1.0423e-01],\n",
      "        [-7.3288e-02],\n",
      "        [-4.3797e-02],\n",
      "        [ 5.8774e-02],\n",
      "        [-3.7260e-02],\n",
      "        [ 4.7140e-05],\n",
      "        [-2.6274e-02],\n",
      "        [-1.6303e-01],\n",
      "        [ 2.1429e-02],\n",
      "        [-6.2930e-02],\n",
      "        [-1.2496e-01],\n",
      "        [-9.1613e-02],\n",
      "        [-1.3777e-01],\n",
      "        [-3.7848e-02],\n",
      "        [ 1.0687e-02],\n",
      "        [-2.3933e-02],\n",
      "        [ 6.9966e-02],\n",
      "        [ 1.0510e-02],\n",
      "        [ 1.6477e-01],\n",
      "        [-1.1235e-01],\n",
      "        [-6.1350e-02],\n",
      "        [-8.5565e-02],\n",
      "        [-1.1116e-01],\n",
      "        [-1.0901e-01],\n",
      "        [ 1.8761e-01],\n",
      "        [-1.9455e-02],\n",
      "        [ 4.3589e-02],\n",
      "        [-4.1212e-03],\n",
      "        [ 5.7740e-03],\n",
      "        [ 8.0304e-03],\n",
      "        [ 9.1541e-02],\n",
      "        [ 1.7459e-02],\n",
      "        [-3.0181e-02],\n",
      "        [-8.9377e-02],\n",
      "        [ 8.3071e-02],\n",
      "        [ 1.2814e-01],\n",
      "        [-1.4544e-01],\n",
      "        [-4.9975e-02],\n",
      "        [ 2.0418e-02],\n",
      "        [ 1.7972e-01],\n",
      "        [-8.7488e-02],\n",
      "        [-7.2623e-05],\n",
      "        [-1.7535e-03],\n",
      "        [ 5.9818e-04],\n",
      "        [-2.2585e-01],\n",
      "        [-4.2852e-02],\n",
      "        [-1.4740e-01],\n",
      "        [ 1.1695e-01],\n",
      "        [ 1.4157e-04],\n",
      "        [ 4.0329e-02],\n",
      "        [-1.1276e-01],\n",
      "        [ 2.0908e-01],\n",
      "        [-1.7704e-01],\n",
      "        [ 1.4612e-01],\n",
      "        [ 9.4557e-02],\n",
      "        [-2.7524e-02],\n",
      "        [ 9.6712e-03],\n",
      "        [ 2.0360e-01],\n",
      "        [ 2.2709e-04],\n",
      "        [ 1.5172e-01],\n",
      "        [-1.8611e-02],\n",
      "        [-2.6899e-02],\n",
      "        [ 1.1894e-01],\n",
      "        [-1.6027e-02],\n",
      "        [-1.0959e-02],\n",
      "        [-6.3649e-02],\n",
      "        [ 1.3179e-01],\n",
      "        [ 1.8896e-01],\n",
      "        [-1.6183e-01],\n",
      "        [ 4.0052e-04],\n",
      "        [ 3.0681e-02],\n",
      "        [-9.9305e-02],\n",
      "        [ 3.7512e-02],\n",
      "        [ 9.8011e-02],\n",
      "        [-1.6076e-01],\n",
      "        [-1.7711e-01],\n",
      "        [ 7.7745e-02],\n",
      "        [-9.2503e-02],\n",
      "        [ 6.9691e-02],\n",
      "        [-2.4525e-01],\n",
      "        [ 1.5052e-01],\n",
      "        [ 1.3600e-01],\n",
      "        [-4.2224e-02],\n",
      "        [ 5.5856e-02],\n",
      "        [-7.8404e-02],\n",
      "        [-4.3066e-02],\n",
      "        [ 2.5814e-01],\n",
      "        [-2.1507e-01],\n",
      "        [-6.3632e-02],\n",
      "        [ 1.2737e-01],\n",
      "        [ 1.4542e-01],\n",
      "        [ 2.6482e-01],\n",
      "        [ 7.3749e-02],\n",
      "        [-9.5583e-02],\n",
      "        [-2.1847e-01],\n",
      "        [ 9.2079e-02],\n",
      "        [ 9.8690e-02],\n",
      "        [-1.4324e-01],\n",
      "        [ 1.7811e-01],\n",
      "        [-2.2434e-02],\n",
      "        [ 9.4701e-02],\n",
      "        [-1.7854e-02],\n",
      "        [-9.5958e-02],\n",
      "        [ 1.2983e-01],\n",
      "        [-9.1416e-02],\n",
      "        [-3.6301e-02],\n",
      "        [-8.1475e-02],\n",
      "        [ 1.3702e-01],\n",
      "        [ 5.6238e-05],\n",
      "        [-2.2436e-02],\n",
      "        [-2.2739e-02],\n",
      "        [-9.2212e-03],\n",
      "        [ 2.5282e-01],\n",
      "        [ 1.3243e-01],\n",
      "        [-3.2502e-02],\n",
      "        [ 2.4913e-02],\n",
      "        [-1.9079e-02],\n",
      "        [-1.1670e-01],\n",
      "        [ 1.6719e-02],\n",
      "        [ 1.3606e-01],\n",
      "        [ 9.3824e-03],\n",
      "        [ 7.6709e-03],\n",
      "        [ 1.0171e-04],\n",
      "        [ 3.3004e-03],\n",
      "        [ 6.2619e-02],\n",
      "        [-6.6339e-02],\n",
      "        [ 4.3841e-02],\n",
      "        [-3.3890e-03],\n",
      "        [-7.0888e-02],\n",
      "        [-4.4665e-02],\n",
      "        [-1.3170e-01],\n",
      "        [-1.4321e-01],\n",
      "        [ 7.4727e-02],\n",
      "        [-1.8780e-01],\n",
      "        [ 5.8113e-02],\n",
      "        [-1.7446e-05],\n",
      "        [ 2.8123e-01],\n",
      "        [ 2.1034e-02],\n",
      "        [ 8.5251e-02],\n",
      "        [ 7.8129e-02],\n",
      "        [-1.3399e-01],\n",
      "        [ 9.4832e-02],\n",
      "        [-1.1609e-01],\n",
      "        [-3.7085e-02],\n",
      "        [ 1.3070e-03],\n",
      "        [-1.6831e-02],\n",
      "        [ 3.4749e-02],\n",
      "        [ 2.1948e-01],\n",
      "        [ 1.2191e-01],\n",
      "        [-3.7298e-04],\n",
      "        [ 9.2613e-02],\n",
      "        [ 2.6641e-01],\n",
      "        [-1.6008e-01],\n",
      "        [ 6.7162e-02],\n",
      "        [ 9.8846e-02],\n",
      "        [ 8.1550e-03],\n",
      "        [-2.6441e-02],\n",
      "        [ 3.3783e-02],\n",
      "        [-2.8228e-03],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-4.7103e-02]], requires_grad=True))\n",
      "('out_layers_w_mean.2', Parameter containing:\n",
      "tensor([[-2.5595e-02],\n",
      "        [-1.7957e-01],\n",
      "        [ 1.7572e-03],\n",
      "        [ 1.9149e-04],\n",
      "        [-2.2487e-02],\n",
      "        [ 3.8739e-05],\n",
      "        [-1.0704e-01],\n",
      "        [-2.6382e-01],\n",
      "        [ 2.8660e-02],\n",
      "        [-1.6752e-01],\n",
      "        [-2.3961e-01],\n",
      "        [ 2.3455e-01],\n",
      "        [ 2.1700e-01],\n",
      "        [ 3.4622e-02],\n",
      "        [ 7.3774e-02],\n",
      "        [ 3.6391e-02],\n",
      "        [-2.0233e-01],\n",
      "        [-6.2057e-02],\n",
      "        [-5.1069e-02],\n",
      "        [ 5.4148e-02],\n",
      "        [-1.8493e-02],\n",
      "        [-1.1473e-01],\n",
      "        [-4.1932e-02],\n",
      "        [-9.9094e-02],\n",
      "        [-1.1776e-01],\n",
      "        [-2.3381e-01],\n",
      "        [ 8.1953e-02],\n",
      "        [-1.6519e-01],\n",
      "        [-3.7347e-03],\n",
      "        [-1.0247e-03],\n",
      "        [-3.4914e-05],\n",
      "        [-1.7858e-01],\n",
      "        [ 6.4974e-03],\n",
      "        [ 1.5321e-01],\n",
      "        [-1.9206e-01],\n",
      "        [ 1.6304e-01],\n",
      "        [-2.0761e-01],\n",
      "        [ 1.3125e-01],\n",
      "        [ 4.8443e-02],\n",
      "        [ 5.0458e-02],\n",
      "        [ 2.0285e-01],\n",
      "        [ 3.2829e-01],\n",
      "        [ 1.6897e-01],\n",
      "        [ 7.3788e-02],\n",
      "        [ 2.1627e-01],\n",
      "        [-1.1638e-01],\n",
      "        [ 1.3539e-01],\n",
      "        [ 2.0631e-01],\n",
      "        [ 2.4087e-01],\n",
      "        [-8.6038e-04],\n",
      "        [ 6.2313e-02],\n",
      "        [-4.4972e-03],\n",
      "        [ 7.4443e-02],\n",
      "        [-2.1602e-01],\n",
      "        [-1.4885e-01],\n",
      "        [-1.3585e-03],\n",
      "        [ 5.0074e-02],\n",
      "        [ 9.6745e-02],\n",
      "        [-3.7130e-02],\n",
      "        [ 4.9976e-02],\n",
      "        [ 1.5342e-02],\n",
      "        [ 1.3300e-01],\n",
      "        [ 1.1302e-01],\n",
      "        [-2.3249e-02],\n",
      "        [ 8.4239e-03],\n",
      "        [-1.6514e-01],\n",
      "        [ 5.3658e-02],\n",
      "        [-3.4944e-02],\n",
      "        [-2.0122e-02],\n",
      "        [ 1.6882e-02],\n",
      "        [-5.1150e-02],\n",
      "        [-1.2678e-04],\n",
      "        [-2.2477e-02],\n",
      "        [ 1.6678e-01],\n",
      "        [-1.6072e-02],\n",
      "        [-1.5143e-01],\n",
      "        [-6.3587e-02],\n",
      "        [-1.6475e-01],\n",
      "        [-1.1818e-01],\n",
      "        [ 6.1017e-04],\n",
      "        [-7.2909e-02],\n",
      "        [-2.5096e-02],\n",
      "        [-1.3917e-01],\n",
      "        [ 4.0295e-02],\n",
      "        [-1.7014e-01],\n",
      "        [ 1.5036e-01],\n",
      "        [ 1.4796e-04],\n",
      "        [ 3.3891e-01],\n",
      "        [-8.3875e-02],\n",
      "        [ 2.5281e-01],\n",
      "        [ 8.4900e-04],\n",
      "        [-2.0113e-01],\n",
      "        [-1.2583e-01],\n",
      "        [-1.7250e-01],\n",
      "        [-8.8019e-02],\n",
      "        [ 1.4006e-01],\n",
      "        [-1.5793e-01],\n",
      "        [-1.1001e-01],\n",
      "        [-4.3901e-02],\n",
      "        [ 5.8586e-02],\n",
      "        [-4.9923e-02],\n",
      "        [-5.6125e-05],\n",
      "        [-2.6363e-02],\n",
      "        [-2.0558e-01],\n",
      "        [ 1.1100e-02],\n",
      "        [-6.2757e-02],\n",
      "        [-1.3360e-01],\n",
      "        [-9.4186e-02],\n",
      "        [-1.6881e-01],\n",
      "        [-3.5882e-02],\n",
      "        [ 1.0017e-02],\n",
      "        [-2.4310e-02],\n",
      "        [ 1.1025e-01],\n",
      "        [ 1.0038e-02],\n",
      "        [ 1.6210e-01],\n",
      "        [-1.0926e-01],\n",
      "        [-5.4696e-02],\n",
      "        [-9.0221e-02],\n",
      "        [-1.0240e-01],\n",
      "        [-1.1728e-01],\n",
      "        [ 1.9075e-01],\n",
      "        [-1.9240e-02],\n",
      "        [ 6.6493e-02],\n",
      "        [-4.1047e-03],\n",
      "        [-4.1079e-03],\n",
      "        [ 8.8887e-03],\n",
      "        [ 9.1712e-02],\n",
      "        [ 1.9487e-02],\n",
      "        [-4.0667e-02],\n",
      "        [-7.5066e-02],\n",
      "        [ 7.2217e-02],\n",
      "        [ 1.4344e-01],\n",
      "        [-1.6112e-01],\n",
      "        [-7.5727e-02],\n",
      "        [ 2.0571e-02],\n",
      "        [ 1.8365e-01],\n",
      "        [-8.8572e-02],\n",
      "        [-1.9709e-03],\n",
      "        [-1.9054e-03],\n",
      "        [ 9.6138e-04],\n",
      "        [-2.4350e-01],\n",
      "        [-3.3729e-02],\n",
      "        [-1.4666e-01],\n",
      "        [ 1.6580e-01],\n",
      "        [ 1.3825e-04],\n",
      "        [ 4.1497e-02],\n",
      "        [-1.1800e-01],\n",
      "        [ 2.1700e-01],\n",
      "        [-1.7310e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [ 9.5686e-02],\n",
      "        [-3.9655e-02],\n",
      "        [-1.8964e-02],\n",
      "        [ 2.4633e-01],\n",
      "        [ 2.8198e-04],\n",
      "        [ 1.7714e-01],\n",
      "        [-1.8740e-02],\n",
      "        [-2.9432e-02],\n",
      "        [ 1.2883e-01],\n",
      "        [-3.7217e-02],\n",
      "        [-1.6649e-02],\n",
      "        [-6.7505e-02],\n",
      "        [ 1.3644e-01],\n",
      "        [ 2.0936e-01],\n",
      "        [-1.6741e-01],\n",
      "        [ 3.9594e-04],\n",
      "        [ 3.9410e-02],\n",
      "        [-1.3258e-01],\n",
      "        [ 4.4249e-02],\n",
      "        [ 1.1305e-01],\n",
      "        [-1.6539e-01],\n",
      "        [-2.2161e-01],\n",
      "        [ 6.9234e-02],\n",
      "        [-1.0596e-01],\n",
      "        [ 8.2904e-02],\n",
      "        [-2.7613e-01],\n",
      "        [ 1.6909e-01],\n",
      "        [ 1.3544e-01],\n",
      "        [-4.3363e-02],\n",
      "        [ 4.7609e-02],\n",
      "        [-9.5191e-02],\n",
      "        [-5.0914e-02],\n",
      "        [ 2.9739e-01],\n",
      "        [-2.5884e-01],\n",
      "        [-7.5672e-02],\n",
      "        [ 1.2767e-01],\n",
      "        [ 1.6821e-01],\n",
      "        [ 2.8373e-01],\n",
      "        [ 1.0007e-01],\n",
      "        [-9.4208e-02],\n",
      "        [-2.1434e-01],\n",
      "        [ 9.4668e-02],\n",
      "        [ 1.1325e-01],\n",
      "        [-1.4306e-01],\n",
      "        [ 1.7138e-01],\n",
      "        [-2.4066e-02],\n",
      "        [ 9.6551e-02],\n",
      "        [-1.8527e-02],\n",
      "        [-8.6145e-02],\n",
      "        [ 1.3856e-01],\n",
      "        [-9.8335e-02],\n",
      "        [-5.8680e-02],\n",
      "        [-1.0173e-01],\n",
      "        [ 1.4646e-01],\n",
      "        [ 2.9520e-04],\n",
      "        [-2.2554e-02],\n",
      "        [-3.1781e-02],\n",
      "        [-9.1786e-03],\n",
      "        [ 2.7061e-01],\n",
      "        [ 1.5087e-01],\n",
      "        [-2.0148e-02],\n",
      "        [ 3.6542e-02],\n",
      "        [-1.9287e-02],\n",
      "        [-1.5517e-01],\n",
      "        [ 1.6706e-02],\n",
      "        [ 1.4661e-01],\n",
      "        [ 1.0390e-02],\n",
      "        [ 1.3464e-02],\n",
      "        [ 9.0292e-03],\n",
      "        [ 2.1668e-03],\n",
      "        [ 6.0015e-02],\n",
      "        [-6.7192e-02],\n",
      "        [ 6.0458e-02],\n",
      "        [-3.4006e-03],\n",
      "        [-6.9772e-02],\n",
      "        [-7.0796e-02],\n",
      "        [-1.3257e-01],\n",
      "        [-1.7639e-01],\n",
      "        [ 7.4179e-02],\n",
      "        [-2.3358e-01],\n",
      "        [ 5.1652e-02],\n",
      "        [-2.6836e-05],\n",
      "        [ 3.1157e-01],\n",
      "        [ 8.5630e-03],\n",
      "        [ 1.1370e-01],\n",
      "        [ 7.8357e-02],\n",
      "        [-1.7625e-01],\n",
      "        [ 1.1704e-01],\n",
      "        [-1.0526e-01],\n",
      "        [-3.6996e-02],\n",
      "        [ 2.0741e-03],\n",
      "        [-3.5452e-02],\n",
      "        [ 3.5077e-02],\n",
      "        [ 2.6009e-01],\n",
      "        [ 1.3125e-01],\n",
      "        [-3.7527e-04],\n",
      "        [ 1.1297e-01],\n",
      "        [ 2.9098e-01],\n",
      "        [-1.8596e-01],\n",
      "        [ 6.3186e-02],\n",
      "        [ 1.2858e-01],\n",
      "        [ 8.3484e-03],\n",
      "        [-2.6438e-02],\n",
      "        [ 2.9176e-02],\n",
      "        [-1.0293e-02],\n",
      "        [-6.1946e-02]], requires_grad=True))\n",
      "('out_layers_w_mean.3', Parameter containing:\n",
      "tensor([[-2.4340e-02],\n",
      "        [-1.8374e-01],\n",
      "        [ 1.7427e-03],\n",
      "        [ 1.8912e-04],\n",
      "        [-2.2698e-02],\n",
      "        [ 5.9969e-05],\n",
      "        [-1.1104e-01],\n",
      "        [-2.6680e-01],\n",
      "        [ 2.9078e-02],\n",
      "        [-1.7167e-01],\n",
      "        [-2.4386e-01],\n",
      "        [ 2.4211e-01],\n",
      "        [ 2.1630e-01],\n",
      "        [ 3.8830e-02],\n",
      "        [ 6.4122e-02],\n",
      "        [ 3.9288e-02],\n",
      "        [-1.9885e-01],\n",
      "        [-6.7405e-02],\n",
      "        [-4.6429e-02],\n",
      "        [ 5.4153e-02],\n",
      "        [-1.8471e-02],\n",
      "        [-1.2564e-01],\n",
      "        [-4.2200e-02],\n",
      "        [-1.1232e-01],\n",
      "        [-1.2424e-01],\n",
      "        [-2.3496e-01],\n",
      "        [ 7.4435e-02],\n",
      "        [-1.6225e-01],\n",
      "        [-4.2143e-03],\n",
      "        [-5.9628e-06],\n",
      "        [-3.9658e-05],\n",
      "        [-1.9462e-01],\n",
      "        [ 1.5309e-02],\n",
      "        [ 1.5973e-01],\n",
      "        [-1.8713e-01],\n",
      "        [ 1.5749e-01],\n",
      "        [-2.0269e-01],\n",
      "        [ 1.2398e-01],\n",
      "        [ 4.5394e-02],\n",
      "        [ 4.8243e-02],\n",
      "        [ 2.0035e-01],\n",
      "        [ 3.3088e-01],\n",
      "        [ 1.6335e-01],\n",
      "        [ 7.3379e-02],\n",
      "        [ 2.1149e-01],\n",
      "        [-1.3316e-01],\n",
      "        [ 1.3066e-01],\n",
      "        [ 2.2109e-01],\n",
      "        [ 2.4044e-01],\n",
      "        [-1.6131e-03],\n",
      "        [ 6.1734e-02],\n",
      "        [ 4.6467e-03],\n",
      "        [ 7.3121e-02],\n",
      "        [-2.1845e-01],\n",
      "        [-1.4816e-01],\n",
      "        [-1.2414e-03],\n",
      "        [ 5.1696e-02],\n",
      "        [ 1.0610e-01],\n",
      "        [-3.6673e-02],\n",
      "        [ 5.9915e-02],\n",
      "        [ 1.5332e-02],\n",
      "        [ 1.2837e-01],\n",
      "        [ 1.1274e-01],\n",
      "        [-3.7705e-02],\n",
      "        [ 8.4178e-03],\n",
      "        [-1.5982e-01],\n",
      "        [ 5.6649e-02],\n",
      "        [-3.4250e-02],\n",
      "        [-2.2282e-02],\n",
      "        [ 2.1467e-02],\n",
      "        [-6.2518e-02],\n",
      "        [-8.7481e-05],\n",
      "        [-2.3120e-02],\n",
      "        [ 1.6274e-01],\n",
      "        [-1.6076e-02],\n",
      "        [-1.5250e-01],\n",
      "        [-7.6744e-02],\n",
      "        [-1.6185e-01],\n",
      "        [-1.2139e-01],\n",
      "        [ 6.0635e-04],\n",
      "        [-6.3942e-02],\n",
      "        [-1.8392e-02],\n",
      "        [-1.5725e-01],\n",
      "        [ 4.2108e-02],\n",
      "        [-1.6472e-01],\n",
      "        [ 1.4964e-01],\n",
      "        [ 9.8199e-06],\n",
      "        [ 3.3342e-01],\n",
      "        [-8.2723e-02],\n",
      "        [ 2.5226e-01],\n",
      "        [ 8.1178e-04],\n",
      "        [-2.1332e-01],\n",
      "        [-1.3195e-01],\n",
      "        [-1.9148e-01],\n",
      "        [-8.2996e-02],\n",
      "        [ 1.3818e-01],\n",
      "        [-1.5558e-01],\n",
      "        [-1.0804e-01],\n",
      "        [-4.3882e-02],\n",
      "        [ 5.8552e-02],\n",
      "        [-5.6011e-02],\n",
      "        [ 6.5394e-05],\n",
      "        [-2.6420e-02],\n",
      "        [-2.0552e-01],\n",
      "        [ 6.2503e-03],\n",
      "        [-6.2189e-02],\n",
      "        [-1.4456e-01],\n",
      "        [-8.8991e-02],\n",
      "        [-1.6451e-01],\n",
      "        [-3.8210e-02],\n",
      "        [ 1.0136e-02],\n",
      "        [-2.5795e-02],\n",
      "        [ 1.0432e-01],\n",
      "        [ 1.0121e-02],\n",
      "        [ 1.7173e-01],\n",
      "        [-1.0895e-01],\n",
      "        [-5.9558e-02],\n",
      "        [-9.5068e-02],\n",
      "        [-1.0607e-01],\n",
      "        [-1.2032e-01],\n",
      "        [ 1.9539e-01],\n",
      "        [-1.9619e-02],\n",
      "        [ 6.0643e-02],\n",
      "        [-4.1075e-03],\n",
      "        [-6.1884e-03],\n",
      "        [ 8.9813e-03],\n",
      "        [ 8.5557e-02],\n",
      "        [ 2.9737e-02],\n",
      "        [-4.5410e-02],\n",
      "        [-7.2558e-02],\n",
      "        [ 7.9057e-02],\n",
      "        [ 1.4497e-01],\n",
      "        [-1.5342e-01],\n",
      "        [-6.7826e-02],\n",
      "        [ 2.0508e-02],\n",
      "        [ 1.9069e-01],\n",
      "        [-9.0156e-02],\n",
      "        [-1.8049e-03],\n",
      "        [-2.0038e-03],\n",
      "        [ 4.5491e-04],\n",
      "        [-2.5052e-01],\n",
      "        [-3.6623e-02],\n",
      "        [-1.4620e-01],\n",
      "        [ 1.5880e-01],\n",
      "        [ 1.3217e-04],\n",
      "        [ 4.7790e-02],\n",
      "        [-1.3250e-01],\n",
      "        [ 2.1806e-01],\n",
      "        [-1.8272e-01],\n",
      "        [ 1.5536e-01],\n",
      "        [ 9.2804e-02],\n",
      "        [-4.1200e-02],\n",
      "        [-8.7505e-03],\n",
      "        [ 2.4353e-01],\n",
      "        [ 3.0564e-04],\n",
      "        [ 1.7450e-01],\n",
      "        [-1.8726e-02],\n",
      "        [-3.1339e-02],\n",
      "        [ 1.3139e-01],\n",
      "        [-3.1610e-02],\n",
      "        [-2.3794e-02],\n",
      "        [-7.9993e-02],\n",
      "        [ 1.4508e-01],\n",
      "        [ 2.0619e-01],\n",
      "        [-1.7867e-01],\n",
      "        [ 4.1555e-04],\n",
      "        [ 3.9897e-02],\n",
      "        [-1.3014e-01],\n",
      "        [ 4.0552e-02],\n",
      "        [ 1.0994e-01],\n",
      "        [-1.7674e-01],\n",
      "        [-2.1429e-01],\n",
      "        [ 6.9721e-02],\n",
      "        [-1.0836e-01],\n",
      "        [ 7.9937e-02],\n",
      "        [-2.7280e-01],\n",
      "        [ 1.7287e-01],\n",
      "        [ 1.3561e-01],\n",
      "        [-5.1054e-02],\n",
      "        [ 5.7571e-02],\n",
      "        [-9.6460e-02],\n",
      "        [-5.9910e-02],\n",
      "        [ 2.8916e-01],\n",
      "        [-2.5051e-01],\n",
      "        [-7.2302e-02],\n",
      "        [ 1.2748e-01],\n",
      "        [ 1.6945e-01],\n",
      "        [ 2.8072e-01],\n",
      "        [ 1.0340e-01],\n",
      "        [-9.4590e-02],\n",
      "        [-2.4681e-01],\n",
      "        [ 9.4057e-02],\n",
      "        [ 1.0878e-01],\n",
      "        [-1.4294e-01],\n",
      "        [ 1.8917e-01],\n",
      "        [-2.4030e-02],\n",
      "        [ 1.0263e-01],\n",
      "        [-1.8579e-02],\n",
      "        [-9.0967e-02],\n",
      "        [ 1.3020e-01],\n",
      "        [-1.0459e-01],\n",
      "        [-5.4570e-02],\n",
      "        [-1.0499e-01],\n",
      "        [ 1.4651e-01],\n",
      "        [ 4.0629e-04],\n",
      "        [-2.2551e-02],\n",
      "        [-3.0347e-02],\n",
      "        [-9.1203e-03],\n",
      "        [ 2.6958e-01],\n",
      "        [ 1.4823e-01],\n",
      "        [-2.7292e-02],\n",
      "        [ 3.1109e-02],\n",
      "        [-1.9029e-02],\n",
      "        [-1.7413e-01],\n",
      "        [ 1.6696e-02],\n",
      "        [ 1.4340e-01],\n",
      "        [ 1.0165e-02],\n",
      "        [ 1.3829e-02],\n",
      "        [ 4.9559e-03],\n",
      "        [ 3.8314e-03],\n",
      "        [ 5.7499e-02],\n",
      "        [-5.8557e-02],\n",
      "        [ 5.3990e-02],\n",
      "        [-3.4271e-03],\n",
      "        [-7.2725e-02],\n",
      "        [-6.5706e-02],\n",
      "        [-1.4884e-01],\n",
      "        [-1.6721e-01],\n",
      "        [ 7.7455e-02],\n",
      "        [-2.5603e-01],\n",
      "        [ 5.6630e-02],\n",
      "        [-3.7013e-05],\n",
      "        [ 3.1069e-01],\n",
      "        [ 1.6356e-02],\n",
      "        [ 1.0716e-01],\n",
      "        [ 7.8311e-02],\n",
      "        [-1.7890e-01],\n",
      "        [ 1.1366e-01],\n",
      "        [-1.2633e-01],\n",
      "        [-3.7073e-02],\n",
      "        [-4.6537e-03],\n",
      "        [-3.9165e-02],\n",
      "        [ 3.5274e-02],\n",
      "        [ 2.5855e-01],\n",
      "        [ 1.3315e-01],\n",
      "        [-3.7441e-04],\n",
      "        [ 1.0648e-01],\n",
      "        [ 2.8797e-01],\n",
      "        [-1.8349e-01],\n",
      "        [ 5.8235e-02],\n",
      "        [ 1.2169e-01],\n",
      "        [ 1.0847e-02],\n",
      "        [-2.6480e-02],\n",
      "        [ 3.0285e-02],\n",
      "        [-8.2390e-03],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-6.8524e-02]], requires_grad=True))\n",
      "('out_layers_w_mean.4', Parameter containing:\n",
      "tensor([[-3.0061e-02],\n",
      "        [-1.8550e-01],\n",
      "        [ 3.6409e-03],\n",
      "        [ 1.8445e-04],\n",
      "        [-2.3359e-02],\n",
      "        [ 6.1399e-05],\n",
      "        [-1.1291e-01],\n",
      "        [-2.6698e-01],\n",
      "        [ 2.7116e-02],\n",
      "        [-1.7200e-01],\n",
      "        [-2.4335e-01],\n",
      "        [ 2.3395e-01],\n",
      "        [ 2.1410e-01],\n",
      "        [ 3.4118e-02],\n",
      "        [ 6.9820e-02],\n",
      "        [ 3.4166e-02],\n",
      "        [-1.9917e-01],\n",
      "        [-7.2559e-02],\n",
      "        [-4.1664e-02],\n",
      "        [ 5.4154e-02],\n",
      "        [-1.8498e-02],\n",
      "        [-1.2105e-01],\n",
      "        [-4.5167e-02],\n",
      "        [-1.1252e-01],\n",
      "        [-1.2613e-01],\n",
      "        [-2.4525e-01],\n",
      "        [ 8.1809e-02],\n",
      "        [-1.5854e-01],\n",
      "        [-5.7806e-03],\n",
      "        [ 3.7710e-04],\n",
      "        [-4.4191e-05],\n",
      "        [-1.9812e-01],\n",
      "        [ 1.3910e-02],\n",
      "        [ 1.5594e-01],\n",
      "        [-1.8489e-01],\n",
      "        [ 1.5601e-01],\n",
      "        [-2.0328e-01],\n",
      "        [ 1.2378e-01],\n",
      "        [ 4.6442e-02],\n",
      "        [ 4.8538e-02],\n",
      "        [ 1.9499e-01],\n",
      "        [ 3.2326e-01],\n",
      "        [ 1.6187e-01],\n",
      "        [ 7.0509e-02],\n",
      "        [ 2.1167e-01],\n",
      "        [-1.3420e-01],\n",
      "        [ 1.2722e-01],\n",
      "        [ 2.2303e-01],\n",
      "        [ 2.3831e-01],\n",
      "        [ 5.4457e-03],\n",
      "        [ 5.8518e-02],\n",
      "        [ 4.7814e-03],\n",
      "        [ 7.5781e-02],\n",
      "        [-2.2147e-01],\n",
      "        [-1.5012e-01],\n",
      "        [-1.3381e-03],\n",
      "        [ 6.3860e-02],\n",
      "        [ 1.1840e-01],\n",
      "        [-3.6727e-02],\n",
      "        [ 5.2459e-02],\n",
      "        [ 1.5354e-02],\n",
      "        [ 1.3165e-01],\n",
      "        [ 1.0993e-01],\n",
      "        [-4.0127e-02],\n",
      "        [ 8.4330e-03],\n",
      "        [-1.6628e-01],\n",
      "        [ 5.3983e-02],\n",
      "        [-3.2744e-02],\n",
      "        [-2.0691e-02],\n",
      "        [ 2.1615e-02],\n",
      "        [-6.5565e-02],\n",
      "        [-1.1160e-04],\n",
      "        [-3.3226e-02],\n",
      "        [ 1.7290e-01],\n",
      "        [-1.6068e-02],\n",
      "        [-1.5209e-01],\n",
      "        [-7.7043e-02],\n",
      "        [-1.6240e-01],\n",
      "        [-1.2022e-01],\n",
      "        [ 4.3588e-04],\n",
      "        [-6.5260e-02],\n",
      "        [-2.4680e-02],\n",
      "        [-1.5329e-01],\n",
      "        [ 3.9610e-02],\n",
      "        [-1.6421e-01],\n",
      "        [ 1.4668e-01],\n",
      "        [-2.0701e-04],\n",
      "        [ 3.2463e-01],\n",
      "        [-8.6204e-02],\n",
      "        [ 2.5250e-01],\n",
      "        [ 8.1745e-04],\n",
      "        [-2.1455e-01],\n",
      "        [-1.3193e-01],\n",
      "        [-1.9749e-01],\n",
      "        [-8.5163e-02],\n",
      "        [ 1.3058e-01],\n",
      "        [-1.5617e-01],\n",
      "        [-1.0561e-01],\n",
      "        [-4.3897e-02],\n",
      "        [ 5.8571e-02],\n",
      "        [-5.9894e-02],\n",
      "        [ 2.8572e-05],\n",
      "        [-2.6369e-02],\n",
      "        [-2.0819e-01],\n",
      "        [ 1.6116e-02],\n",
      "        [-6.2059e-02],\n",
      "        [-1.4715e-01],\n",
      "        [-9.0879e-02],\n",
      "        [-1.6377e-01],\n",
      "        [-3.4936e-02],\n",
      "        [ 1.0147e-02],\n",
      "        [-3.5590e-02],\n",
      "        [ 9.8899e-02],\n",
      "        [ 1.0105e-02],\n",
      "        [ 1.7266e-01],\n",
      "        [-1.0872e-01],\n",
      "        [-7.1971e-02],\n",
      "        [-9.4874e-02],\n",
      "        [-1.1607e-01],\n",
      "        [-1.2441e-01],\n",
      "        [ 1.8884e-01],\n",
      "        [-1.9611e-02],\n",
      "        [ 5.9671e-02],\n",
      "        [-4.1123e-03],\n",
      "        [-5.0496e-04],\n",
      "        [ 9.2411e-03],\n",
      "        [ 8.4445e-02],\n",
      "        [ 2.4513e-02],\n",
      "        [-4.5122e-02],\n",
      "        [-1.0042e-01],\n",
      "        [ 8.5160e-02],\n",
      "        [ 1.4384e-01],\n",
      "        [-1.5385e-01],\n",
      "        [-7.1751e-02],\n",
      "        [ 2.0066e-02],\n",
      "        [ 1.7989e-01],\n",
      "        [-9.0366e-02],\n",
      "        [-1.9412e-03],\n",
      "        [-1.8012e-03],\n",
      "        [ 3.8160e-04],\n",
      "        [-2.5086e-01],\n",
      "        [-3.9592e-02],\n",
      "        [-1.4372e-01],\n",
      "        [ 1.6437e-01],\n",
      "        [ 1.4454e-04],\n",
      "        [ 6.4564e-02],\n",
      "        [-1.3312e-01],\n",
      "        [ 2.2140e-01],\n",
      "        [-1.8023e-01],\n",
      "        [ 1.6134e-01],\n",
      "        [ 1.0311e-01],\n",
      "        [-4.1938e-02],\n",
      "        [-1.0932e-02],\n",
      "        [ 2.5259e-01],\n",
      "        [ 6.6750e-05],\n",
      "        [ 1.7128e-01],\n",
      "        [-1.8955e-02],\n",
      "        [-3.3512e-02],\n",
      "        [ 1.2904e-01],\n",
      "        [-3.2193e-02],\n",
      "        [-1.7268e-02],\n",
      "        [-8.3144e-02],\n",
      "        [ 1.3822e-01],\n",
      "        [ 2.0151e-01],\n",
      "        [-1.7813e-01],\n",
      "        [ 4.1285e-04],\n",
      "        [ 5.7137e-02],\n",
      "        [-1.3097e-01],\n",
      "        [ 4.0685e-02],\n",
      "        [ 1.0699e-01],\n",
      "        [-1.7630e-01],\n",
      "        [-2.1551e-01],\n",
      "        [ 6.5566e-02],\n",
      "        [-1.0805e-01],\n",
      "        [ 7.5292e-02],\n",
      "        [-2.7151e-01],\n",
      "        [ 1.6628e-01],\n",
      "        [ 1.6158e-01],\n",
      "        [-5.2980e-02],\n",
      "        [ 5.2510e-02],\n",
      "        [-9.5491e-02],\n",
      "        [-6.1351e-02],\n",
      "        [ 2.8145e-01],\n",
      "        [-2.5233e-01],\n",
      "        [-7.0708e-02],\n",
      "        [ 1.2519e-01],\n",
      "        [ 1.6202e-01],\n",
      "        [ 2.7825e-01],\n",
      "        [ 1.0598e-01],\n",
      "        [-1.2480e-01],\n",
      "        [-2.4749e-01],\n",
      "        [ 9.2817e-02],\n",
      "        [ 1.0797e-01],\n",
      "        [-1.4302e-01],\n",
      "        [ 1.8057e-01],\n",
      "        [-2.4018e-02],\n",
      "        [ 9.8293e-02],\n",
      "        [-1.8794e-02],\n",
      "        [-1.1570e-01],\n",
      "        [ 1.3421e-01],\n",
      "        [-1.1231e-01],\n",
      "        [-4.9660e-02],\n",
      "        [-1.0319e-01],\n",
      "        [ 1.4809e-01],\n",
      "        [ 7.0642e-04],\n",
      "        [-2.2565e-02],\n",
      "        [-3.2732e-02],\n",
      "        [-8.6931e-03],\n",
      "        [ 2.6622e-01],\n",
      "        [ 1.5753e-01],\n",
      "        [-3.2639e-02],\n",
      "        [ 2.9099e-02],\n",
      "        [-1.9080e-02],\n",
      "        [-1.7462e-01],\n",
      "        [ 1.6698e-02],\n",
      "        [ 1.4130e-01],\n",
      "        [ 1.7918e-02],\n",
      "        [ 1.0388e-02],\n",
      "        [ 4.3814e-04],\n",
      "        [ 4.4636e-03],\n",
      "        [ 5.2148e-02],\n",
      "        [-5.9608e-02],\n",
      "        [ 5.2320e-02],\n",
      "        [-3.4051e-03],\n",
      "        [-9.6792e-02],\n",
      "        [-6.7196e-02],\n",
      "        [-1.4798e-01],\n",
      "        [-1.6721e-01],\n",
      "        [ 7.2267e-02],\n",
      "        [-2.5658e-01],\n",
      "        [ 5.4205e-02],\n",
      "        [-2.4208e-05],\n",
      "        [ 3.0199e-01],\n",
      "        [ 1.3069e-02],\n",
      "        [ 1.1120e-01],\n",
      "        [ 7.8154e-02],\n",
      "        [-1.7676e-01],\n",
      "        [ 1.0777e-01],\n",
      "        [-1.3680e-01],\n",
      "        [-3.6893e-02],\n",
      "        [-1.6703e-03],\n",
      "        [-3.2953e-02],\n",
      "        [ 3.5583e-02],\n",
      "        [ 2.5410e-01],\n",
      "        [ 1.2674e-01],\n",
      "        [-3.6926e-04],\n",
      "        [ 1.0767e-01],\n",
      "        [ 2.8642e-01],\n",
      "        [-1.8199e-01],\n",
      "        [ 5.2766e-02],\n",
      "        [ 1.1471e-01],\n",
      "        [ 5.7474e-03],\n",
      "        [-2.8202e-02],\n",
      "        [ 4.5288e-02],\n",
      "        [-8.1799e-03],\n",
      "        [-6.5786e-02]], requires_grad=True))\n",
      "('out_layers_b_mean.0', Parameter containing:\n",
      "tensor([[-0.1453]], requires_grad=True))\n",
      "('out_layers_b_mean.1', Parameter containing:\n",
      "tensor([[-0.1227]], requires_grad=True))\n",
      "('out_layers_b_mean.2', Parameter containing:\n",
      "tensor([[-0.1351]], requires_grad=True))\n",
      "('out_layers_b_mean.3', Parameter containing:\n",
      "tensor([[-0.1399]], requires_grad=True))\n",
      "('out_layers_b_mean.4', Parameter containing:\n",
      "tensor([[-0.1418]], requires_grad=True))\n",
      "('out_layers_w_var.0', Parameter containing:\n",
      "tensor([[-5.8708],\n",
      "        [-5.8713],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8710],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8710],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8711],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8704],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8702],\n",
      "        [-5.8711],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8716],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8715],\n",
      "        [-5.8708],\n",
      "        [-5.8705],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8710],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8707],\n",
      "        [-5.8710],\n",
      "        [-5.8706],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8709],\n",
      "        [-5.8710],\n",
      "        [-5.8706],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8711],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8713],\n",
      "        [-5.8711],\n",
      "        [-5.8708],\n",
      "        [-5.8712],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8706],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8703],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8715],\n",
      "        [-5.8709],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8703],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8710],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8712],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8716],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8711],\n",
      "        [-5.8709],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8707],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8709],\n",
      "        [-5.8709],\n",
      "        [-5.8709],\n",
      "        [-5.8707],\n",
      "        [-5.8711],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n",
      "        [-5.8708],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-5.8708]], requires_grad=True))\n",
      "('out_layers_w_var.1', Parameter containing:\n",
      "tensor([[-5.8766],\n",
      "        [-5.8710],\n",
      "        [-5.8786],\n",
      "        [-5.8801],\n",
      "        [-5.8800],\n",
      "        [-5.8801],\n",
      "        [-5.8840],\n",
      "        [-5.8752],\n",
      "        [-5.8791],\n",
      "        [-5.8763],\n",
      "        [-5.8657],\n",
      "        [-5.8680],\n",
      "        [-5.8785],\n",
      "        [-5.8694],\n",
      "        [-5.8762],\n",
      "        [-5.8803],\n",
      "        [-5.8712],\n",
      "        [-5.8640],\n",
      "        [-5.8797],\n",
      "        [-5.8801],\n",
      "        [-5.8801],\n",
      "        [-5.8653],\n",
      "        [-5.8715],\n",
      "        [-5.8768],\n",
      "        [-5.8720],\n",
      "        [-5.8698],\n",
      "        [-5.8782],\n",
      "        [-5.8597],\n",
      "        [-5.8803],\n",
      "        [-5.8813],\n",
      "        [-5.8801],\n",
      "        [-5.8695],\n",
      "        [-5.8786],\n",
      "        [-5.8800],\n",
      "        [-5.8685],\n",
      "        [-5.8788],\n",
      "        [-5.8812],\n",
      "        [-5.8769],\n",
      "        [-5.8654],\n",
      "        [-5.8703],\n",
      "        [-5.8690],\n",
      "        [-5.8787],\n",
      "        [-5.8769],\n",
      "        [-5.8801],\n",
      "        [-5.8706],\n",
      "        [-5.8797],\n",
      "        [-5.8797],\n",
      "        [-5.8715],\n",
      "        [-5.8796],\n",
      "        [-5.8801],\n",
      "        [-5.8722],\n",
      "        [-5.8705],\n",
      "        [-5.8765],\n",
      "        [-5.8736],\n",
      "        [-5.8692],\n",
      "        [-5.8800],\n",
      "        [-5.8786],\n",
      "        [-5.8787],\n",
      "        [-5.8799],\n",
      "        [-5.8758],\n",
      "        [-5.8801],\n",
      "        [-5.8862],\n",
      "        [-5.8802],\n",
      "        [-5.8777],\n",
      "        [-5.8801],\n",
      "        [-5.8663],\n",
      "        [-5.8766],\n",
      "        [-5.8797],\n",
      "        [-5.8776],\n",
      "        [-5.8785],\n",
      "        [-5.8807],\n",
      "        [-5.8801],\n",
      "        [-5.8764],\n",
      "        [-5.8716],\n",
      "        [-5.8801],\n",
      "        [-5.8809],\n",
      "        [-5.8764],\n",
      "        [-5.8747],\n",
      "        [-5.8798],\n",
      "        [-5.8802],\n",
      "        [-5.8752],\n",
      "        [-5.8735],\n",
      "        [-5.8670],\n",
      "        [-5.8796],\n",
      "        [-5.8731],\n",
      "        [-5.8685],\n",
      "        [-5.8801],\n",
      "        [-5.8711],\n",
      "        [-5.8724],\n",
      "        [-5.8717],\n",
      "        [-5.8801],\n",
      "        [-5.8675],\n",
      "        [-5.8640],\n",
      "        [-5.8682],\n",
      "        [-5.8771],\n",
      "        [-5.8682],\n",
      "        [-5.8744],\n",
      "        [-5.8810],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8791],\n",
      "        [-5.8801],\n",
      "        [-5.8802],\n",
      "        [-5.8782],\n",
      "        [-5.8723],\n",
      "        [-5.8806],\n",
      "        [-5.8767],\n",
      "        [-5.8765],\n",
      "        [-5.8626],\n",
      "        [-5.8802],\n",
      "        [-5.8803],\n",
      "        [-5.8674],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8785],\n",
      "        [-5.8737],\n",
      "        [-5.8772],\n",
      "        [-5.8717],\n",
      "        [-5.8702],\n",
      "        [-5.8775],\n",
      "        [-5.8709],\n",
      "        [-5.8802],\n",
      "        [-5.8748],\n",
      "        [-5.8801],\n",
      "        [-5.8775],\n",
      "        [-5.8815],\n",
      "        [-5.8783],\n",
      "        [-5.8767],\n",
      "        [-5.8694],\n",
      "        [-5.8770],\n",
      "        [-5.8720],\n",
      "        [-5.8668],\n",
      "        [-5.8710],\n",
      "        [-5.8826],\n",
      "        [-5.8810],\n",
      "        [-5.8701],\n",
      "        [-5.8683],\n",
      "        [-5.8803],\n",
      "        [-5.8801],\n",
      "        [-5.8801],\n",
      "        [-5.8674],\n",
      "        [-5.8625],\n",
      "        [-5.8800],\n",
      "        [-5.8737],\n",
      "        [-5.8801],\n",
      "        [-5.8804],\n",
      "        [-5.8663],\n",
      "        [-5.8678],\n",
      "        [-5.8780],\n",
      "        [-5.8759],\n",
      "        [-5.8730],\n",
      "        [-5.8805],\n",
      "        [-5.8770],\n",
      "        [-5.8929],\n",
      "        [-5.8802],\n",
      "        [-5.8681],\n",
      "        [-5.8801],\n",
      "        [-5.8787],\n",
      "        [-5.8784],\n",
      "        [-5.8809],\n",
      "        [-5.8744],\n",
      "        [-5.8694],\n",
      "        [-5.8766],\n",
      "        [-5.8722],\n",
      "        [-5.8716],\n",
      "        [-5.8801],\n",
      "        [-5.8784],\n",
      "        [-5.8770],\n",
      "        [-5.8753],\n",
      "        [-5.8676],\n",
      "        [-5.8807],\n",
      "        [-5.8723],\n",
      "        [-5.8792],\n",
      "        [-5.8864],\n",
      "        [-5.8716],\n",
      "        [-5.8725],\n",
      "        [-5.8690],\n",
      "        [-5.8801],\n",
      "        [-5.8781],\n",
      "        [-5.8724],\n",
      "        [-5.8763],\n",
      "        [-5.8667],\n",
      "        [-5.8808],\n",
      "        [-5.8822],\n",
      "        [-5.8788],\n",
      "        [-5.8802],\n",
      "        [-5.8729],\n",
      "        [-5.8666],\n",
      "        [-5.8787],\n",
      "        [-5.8741],\n",
      "        [-5.8758],\n",
      "        [-5.8674],\n",
      "        [-5.8768],\n",
      "        [-5.8800],\n",
      "        [-5.8791],\n",
      "        [-5.8801],\n",
      "        [-5.8764],\n",
      "        [-5.8802],\n",
      "        [-5.8769],\n",
      "        [-5.8786],\n",
      "        [-5.8755],\n",
      "        [-5.8790],\n",
      "        [-5.8743],\n",
      "        [-5.8787],\n",
      "        [-5.8802],\n",
      "        [-5.8800],\n",
      "        [-5.8806],\n",
      "        [-5.8803],\n",
      "        [-5.8758],\n",
      "        [-5.8793],\n",
      "        [-5.8763],\n",
      "        [-5.8677],\n",
      "        [-5.8805],\n",
      "        [-5.8764],\n",
      "        [-5.8802],\n",
      "        [-5.8783],\n",
      "        [-5.8804],\n",
      "        [-5.8800],\n",
      "        [-5.8794],\n",
      "        [-5.8801],\n",
      "        [-5.8806],\n",
      "        [-5.8819],\n",
      "        [-5.8765],\n",
      "        [-5.8801],\n",
      "        [-5.8806],\n",
      "        [-5.8796],\n",
      "        [-5.8731],\n",
      "        [-5.8724],\n",
      "        [-5.8751],\n",
      "        [-5.8664],\n",
      "        [-5.8817],\n",
      "        [-5.8801],\n",
      "        [-5.8788],\n",
      "        [-5.8694],\n",
      "        [-5.8714],\n",
      "        [-5.8801],\n",
      "        [-5.8782],\n",
      "        [-5.8778],\n",
      "        [-5.8829],\n",
      "        [-5.8799],\n",
      "        [-5.8773],\n",
      "        [-5.8713],\n",
      "        [-5.8802],\n",
      "        [-5.8623],\n",
      "        [-5.8761],\n",
      "        [-5.8802],\n",
      "        [-5.8778],\n",
      "        [-5.8803],\n",
      "        [-5.8664],\n",
      "        [-5.8794],\n",
      "        [-5.8829],\n",
      "        [-5.8799],\n",
      "        [-5.8801],\n",
      "        [-5.8798],\n",
      "        [-5.8806],\n",
      "        [-5.8740]], requires_grad=True))\n",
      "('out_layers_w_var.2', Parameter containing:\n",
      "tensor([[-5.8759],\n",
      "        [-5.8650],\n",
      "        [-5.8767],\n",
      "        [-5.8802],\n",
      "        [-5.8793],\n",
      "        [-5.8802],\n",
      "        [-5.8889],\n",
      "        [-5.8752],\n",
      "        [-5.8787],\n",
      "        [-5.8746],\n",
      "        [-5.8598],\n",
      "        [-5.8701],\n",
      "        [-5.8806],\n",
      "        [-5.8689],\n",
      "        [-5.8736],\n",
      "        [-5.8837],\n",
      "        [-5.8674],\n",
      "        [-5.8631],\n",
      "        [-5.8785],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8714],\n",
      "        [-5.8712],\n",
      "        [-5.8804],\n",
      "        [-5.8760],\n",
      "        [-5.8689],\n",
      "        [-5.8826],\n",
      "        [-5.8564],\n",
      "        [-5.8789],\n",
      "        [-5.8800],\n",
      "        [-5.8802],\n",
      "        [-5.8686],\n",
      "        [-5.8775],\n",
      "        [-5.8818],\n",
      "        [-5.8715],\n",
      "        [-5.8788],\n",
      "        [-5.8846],\n",
      "        [-5.8747],\n",
      "        [-5.8667],\n",
      "        [-5.8684],\n",
      "        [-5.8707],\n",
      "        [-5.8820],\n",
      "        [-5.8756],\n",
      "        [-5.8821],\n",
      "        [-5.8779],\n",
      "        [-5.8789],\n",
      "        [-5.8811],\n",
      "        [-5.8743],\n",
      "        [-5.8727],\n",
      "        [-5.8793],\n",
      "        [-5.8672],\n",
      "        [-5.8703],\n",
      "        [-5.8756],\n",
      "        [-5.8769],\n",
      "        [-5.8734],\n",
      "        [-5.8803],\n",
      "        [-5.8781],\n",
      "        [-5.8762],\n",
      "        [-5.8800],\n",
      "        [-5.8757],\n",
      "        [-5.8802],\n",
      "        [-5.8912],\n",
      "        [-5.8801],\n",
      "        [-5.8770],\n",
      "        [-5.8803],\n",
      "        [-5.8603],\n",
      "        [-5.8758],\n",
      "        [-5.8796],\n",
      "        [-5.8762],\n",
      "        [-5.8768],\n",
      "        [-5.8788],\n",
      "        [-5.8802],\n",
      "        [-5.8742],\n",
      "        [-5.8708],\n",
      "        [-5.8802],\n",
      "        [-5.8816],\n",
      "        [-5.8737],\n",
      "        [-5.8779],\n",
      "        [-5.8744],\n",
      "        [-5.8802],\n",
      "        [-5.8746],\n",
      "        [-5.8732],\n",
      "        [-5.8711],\n",
      "        [-5.8804],\n",
      "        [-5.8698],\n",
      "        [-5.8678],\n",
      "        [-5.8801],\n",
      "        [-5.8709],\n",
      "        [-5.8710],\n",
      "        [-5.8594],\n",
      "        [-5.8805],\n",
      "        [-5.8622],\n",
      "        [-5.8674],\n",
      "        [-5.8677],\n",
      "        [-5.8768],\n",
      "        [-5.8656],\n",
      "        [-5.8763],\n",
      "        [-5.8782],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8776],\n",
      "        [-5.8803],\n",
      "        [-5.8802],\n",
      "        [-5.8698],\n",
      "        [-5.8682],\n",
      "        [-5.8806],\n",
      "        [-5.8800],\n",
      "        [-5.8748],\n",
      "        [-5.8632],\n",
      "        [-5.8794],\n",
      "        [-5.8797],\n",
      "        [-5.8667],\n",
      "        [-5.8813],\n",
      "        [-5.8797],\n",
      "        [-5.8816],\n",
      "        [-5.8728],\n",
      "        [-5.8791],\n",
      "        [-5.8712],\n",
      "        [-5.8723],\n",
      "        [-5.8772],\n",
      "        [-5.8699],\n",
      "        [-5.8802],\n",
      "        [-5.8756],\n",
      "        [-5.8802],\n",
      "        [-5.8759],\n",
      "        [-5.8799],\n",
      "        [-5.8797],\n",
      "        [-5.8763],\n",
      "        [-5.8669],\n",
      "        [-5.8776],\n",
      "        [-5.8691],\n",
      "        [-5.8696],\n",
      "        [-5.8739],\n",
      "        [-5.8796],\n",
      "        [-5.8807],\n",
      "        [-5.8683],\n",
      "        [-5.8613],\n",
      "        [-5.8795],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8655],\n",
      "        [-5.8619],\n",
      "        [-5.8800],\n",
      "        [-5.8792],\n",
      "        [-5.8802],\n",
      "        [-5.8784],\n",
      "        [-5.8668],\n",
      "        [-5.8716],\n",
      "        [-5.8774],\n",
      "        [-5.8783],\n",
      "        [-5.8733],\n",
      "        [-5.8787],\n",
      "        [-5.8802],\n",
      "        [-5.8936],\n",
      "        [-5.8802],\n",
      "        [-5.8688],\n",
      "        [-5.8802],\n",
      "        [-5.8813],\n",
      "        [-5.8714],\n",
      "        [-5.8787],\n",
      "        [-5.8728],\n",
      "        [-5.8718],\n",
      "        [-5.8762],\n",
      "        [-5.8672],\n",
      "        [-5.8715],\n",
      "        [-5.8802],\n",
      "        [-5.8787],\n",
      "        [-5.8779],\n",
      "        [-5.8751],\n",
      "        [-5.8659],\n",
      "        [-5.8790],\n",
      "        [-5.8763],\n",
      "        [-5.8785],\n",
      "        [-5.8871],\n",
      "        [-5.8779],\n",
      "        [-5.8764],\n",
      "        [-5.8721],\n",
      "        [-5.8800],\n",
      "        [-5.8735],\n",
      "        [-5.8726],\n",
      "        [-5.8792],\n",
      "        [-5.8646],\n",
      "        [-5.8704],\n",
      "        [-5.8864],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8712],\n",
      "        [-5.8633],\n",
      "        [-5.8810],\n",
      "        [-5.8740],\n",
      "        [-5.8719],\n",
      "        [-5.8665],\n",
      "        [-5.8699],\n",
      "        [-5.8800],\n",
      "        [-5.8796],\n",
      "        [-5.8801],\n",
      "        [-5.8751],\n",
      "        [-5.8806],\n",
      "        [-5.8755],\n",
      "        [-5.8774],\n",
      "        [-5.8735],\n",
      "        [-5.8815],\n",
      "        [-5.8794],\n",
      "        [-5.8818],\n",
      "        [-5.8802],\n",
      "        [-5.8801],\n",
      "        [-5.8797],\n",
      "        [-5.8802],\n",
      "        [-5.8754],\n",
      "        [-5.8745],\n",
      "        [-5.8764],\n",
      "        [-5.8643],\n",
      "        [-5.8802],\n",
      "        [-5.8726],\n",
      "        [-5.8801],\n",
      "        [-5.8766],\n",
      "        [-5.8808],\n",
      "        [-5.8794],\n",
      "        [-5.8804],\n",
      "        [-5.8803],\n",
      "        [-5.8811],\n",
      "        [-5.8804],\n",
      "        [-5.8731],\n",
      "        [-5.8802],\n",
      "        [-5.8810],\n",
      "        [-5.8759],\n",
      "        [-5.8755],\n",
      "        [-5.8753],\n",
      "        [-5.8775],\n",
      "        [-5.8580],\n",
      "        [-5.8811],\n",
      "        [-5.8802],\n",
      "        [-5.8661],\n",
      "        [-5.8661],\n",
      "        [-5.8702],\n",
      "        [-5.8805],\n",
      "        [-5.8797],\n",
      "        [-5.8799],\n",
      "        [-5.8841],\n",
      "        [-5.8801],\n",
      "        [-5.8756],\n",
      "        [-5.8717],\n",
      "        [-5.8802],\n",
      "        [-5.8649],\n",
      "        [-5.8751],\n",
      "        [-5.8802],\n",
      "        [-5.8753],\n",
      "        [-5.8850],\n",
      "        [-5.8581],\n",
      "        [-5.8795],\n",
      "        [-5.8790],\n",
      "        [-5.8804],\n",
      "        [-5.8801],\n",
      "        [-5.8788],\n",
      "        [-5.8808],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-5.8752]], requires_grad=True))\n",
      "('out_layers_w_var.3', Parameter containing:\n",
      "tensor([[-5.8761],\n",
      "        [-5.8590],\n",
      "        [-5.8774],\n",
      "        [-5.8802],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8896],\n",
      "        [-5.8752],\n",
      "        [-5.8786],\n",
      "        [-5.8753],\n",
      "        [-5.8639],\n",
      "        [-5.8670],\n",
      "        [-5.8779],\n",
      "        [-5.8656],\n",
      "        [-5.8716],\n",
      "        [-5.8808],\n",
      "        [-5.8623],\n",
      "        [-5.8631],\n",
      "        [-5.8835],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8712],\n",
      "        [-5.8690],\n",
      "        [-5.8806],\n",
      "        [-5.8746],\n",
      "        [-5.8697],\n",
      "        [-5.8842],\n",
      "        [-5.8527],\n",
      "        [-5.8792],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8675],\n",
      "        [-5.8765],\n",
      "        [-5.8797],\n",
      "        [-5.8756],\n",
      "        [-5.8797],\n",
      "        [-5.8915],\n",
      "        [-5.8741],\n",
      "        [-5.8655],\n",
      "        [-5.8722],\n",
      "        [-5.8751],\n",
      "        [-5.8821],\n",
      "        [-5.8715],\n",
      "        [-5.8814],\n",
      "        [-5.8830],\n",
      "        [-5.8791],\n",
      "        [-5.8759],\n",
      "        [-5.8683],\n",
      "        [-5.8644],\n",
      "        [-5.8798],\n",
      "        [-5.8600],\n",
      "        [-5.8672],\n",
      "        [-5.8767],\n",
      "        [-5.8727],\n",
      "        [-5.8710],\n",
      "        [-5.8802],\n",
      "        [-5.8782],\n",
      "        [-5.8747],\n",
      "        [-5.8805],\n",
      "        [-5.8746],\n",
      "        [-5.8802],\n",
      "        [-5.8939],\n",
      "        [-5.8799],\n",
      "        [-5.8760],\n",
      "        [-5.8802],\n",
      "        [-5.8567],\n",
      "        [-5.8758],\n",
      "        [-5.8795],\n",
      "        [-5.8767],\n",
      "        [-5.8771],\n",
      "        [-5.8777],\n",
      "        [-5.8802],\n",
      "        [-5.8744],\n",
      "        [-5.8746],\n",
      "        [-5.8802],\n",
      "        [-5.8815],\n",
      "        [-5.8733],\n",
      "        [-5.8808],\n",
      "        [-5.8738],\n",
      "        [-5.8803],\n",
      "        [-5.8772],\n",
      "        [-5.8728],\n",
      "        [-5.8670],\n",
      "        [-5.8798],\n",
      "        [-5.8684],\n",
      "        [-5.8706],\n",
      "        [-5.8800],\n",
      "        [-5.8681],\n",
      "        [-5.8695],\n",
      "        [-5.8650],\n",
      "        [-5.8802],\n",
      "        [-5.8594],\n",
      "        [-5.8733],\n",
      "        [-5.8600],\n",
      "        [-5.8784],\n",
      "        [-5.8605],\n",
      "        [-5.8770],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8811],\n",
      "        [-5.8802],\n",
      "        [-5.8801],\n",
      "        [-5.8704],\n",
      "        [-5.8702],\n",
      "        [-5.8810],\n",
      "        [-5.8803],\n",
      "        [-5.8762],\n",
      "        [-5.8649],\n",
      "        [-5.8804],\n",
      "        [-5.8801],\n",
      "        [-5.8668],\n",
      "        [-5.8860],\n",
      "        [-5.8800],\n",
      "        [-5.8832],\n",
      "        [-5.8737],\n",
      "        [-5.8782],\n",
      "        [-5.8775],\n",
      "        [-5.8724],\n",
      "        [-5.8750],\n",
      "        [-5.8693],\n",
      "        [-5.8809],\n",
      "        [-5.8711],\n",
      "        [-5.8802],\n",
      "        [-5.8763],\n",
      "        [-5.8798],\n",
      "        [-5.8730],\n",
      "        [-5.8767],\n",
      "        [-5.8669],\n",
      "        [-5.8750],\n",
      "        [-5.8739],\n",
      "        [-5.8658],\n",
      "        [-5.8785],\n",
      "        [-5.8809],\n",
      "        [-5.8802],\n",
      "        [-5.8662],\n",
      "        [-5.8639],\n",
      "        [-5.8804],\n",
      "        [-5.8801],\n",
      "        [-5.8810],\n",
      "        [-5.8636],\n",
      "        [-5.8617],\n",
      "        [-5.8789],\n",
      "        [-5.8783],\n",
      "        [-5.8802],\n",
      "        [-5.8790],\n",
      "        [-5.8660],\n",
      "        [-5.8773],\n",
      "        [-5.8738],\n",
      "        [-5.8746],\n",
      "        [-5.8744],\n",
      "        [-5.8798],\n",
      "        [-5.8807],\n",
      "        [-5.8895],\n",
      "        [-5.8801],\n",
      "        [-5.8649],\n",
      "        [-5.8802],\n",
      "        [-5.8799],\n",
      "        [-5.8658],\n",
      "        [-5.8788],\n",
      "        [-5.8731],\n",
      "        [-5.8680],\n",
      "        [-5.8761],\n",
      "        [-5.8709],\n",
      "        [-5.8760],\n",
      "        [-5.8802],\n",
      "        [-5.8777],\n",
      "        [-5.8731],\n",
      "        [-5.8760],\n",
      "        [-5.8692],\n",
      "        [-5.8781],\n",
      "        [-5.8705],\n",
      "        [-5.8762],\n",
      "        [-5.8890],\n",
      "        [-5.8702],\n",
      "        [-5.8785],\n",
      "        [-5.8757],\n",
      "        [-5.8800],\n",
      "        [-5.8678],\n",
      "        [-5.8726],\n",
      "        [-5.8827],\n",
      "        [-5.8657],\n",
      "        [-5.8721],\n",
      "        [-5.8793],\n",
      "        [-5.8794],\n",
      "        [-5.8802],\n",
      "        [-5.8699],\n",
      "        [-5.8676],\n",
      "        [-5.8817],\n",
      "        [-5.8748],\n",
      "        [-5.8739],\n",
      "        [-5.8699],\n",
      "        [-5.8703],\n",
      "        [-5.8799],\n",
      "        [-5.8753],\n",
      "        [-5.8801],\n",
      "        [-5.8753],\n",
      "        [-5.8806],\n",
      "        [-5.8766],\n",
      "        [-5.8816],\n",
      "        [-5.8763],\n",
      "        [-5.8816],\n",
      "        [-5.8821],\n",
      "        [-5.8771],\n",
      "        [-5.8801],\n",
      "        [-5.8801],\n",
      "        [-5.8789],\n",
      "        [-5.8802],\n",
      "        [-5.8762],\n",
      "        [-5.8726],\n",
      "        [-5.8804],\n",
      "        [-5.8684],\n",
      "        [-5.8802],\n",
      "        [-5.8716],\n",
      "        [-5.8802],\n",
      "        [-5.8822],\n",
      "        [-5.8804],\n",
      "        [-5.8789],\n",
      "        [-5.8785],\n",
      "        [-5.8808],\n",
      "        [-5.8807],\n",
      "        [-5.8815],\n",
      "        [-5.8737],\n",
      "        [-5.8802],\n",
      "        [-5.8800],\n",
      "        [-5.8744],\n",
      "        [-5.8777],\n",
      "        [-5.8841],\n",
      "        [-5.8717],\n",
      "        [-5.8611],\n",
      "        [-5.8846],\n",
      "        [-5.8802],\n",
      "        [-5.8670],\n",
      "        [-5.8677],\n",
      "        [-5.8762],\n",
      "        [-5.8803],\n",
      "        [-5.8783],\n",
      "        [-5.8781],\n",
      "        [-5.8834],\n",
      "        [-5.8802],\n",
      "        [-5.8767],\n",
      "        [-5.8721],\n",
      "        [-5.8800],\n",
      "        [-5.8691],\n",
      "        [-5.8799],\n",
      "        [-5.8802],\n",
      "        [-5.8733],\n",
      "        [-5.8798],\n",
      "        [-5.8557],\n",
      "        [-5.8802],\n",
      "        [-5.8810],\n",
      "        [-5.8804],\n",
      "        [-5.8802],\n",
      "        [-5.8792],\n",
      "        [-5.8793],\n",
      "        [-5.8726]], requires_grad=True))\n",
      "('out_layers_w_var.4', Parameter containing:\n",
      "tensor([[-5.8770],\n",
      "        [-5.8579],\n",
      "        [-5.8774],\n",
      "        [-5.8802],\n",
      "        [-5.8797],\n",
      "        [-5.8802],\n",
      "        [-5.8892],\n",
      "        [-5.8744],\n",
      "        [-5.8782],\n",
      "        [-5.8796],\n",
      "        [-5.8691],\n",
      "        [-5.8638],\n",
      "        [-5.8821],\n",
      "        [-5.8639],\n",
      "        [-5.8690],\n",
      "        [-5.8828],\n",
      "        [-5.8556],\n",
      "        [-5.8612],\n",
      "        [-5.8854],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8690],\n",
      "        [-5.8721],\n",
      "        [-5.8837],\n",
      "        [-5.8668],\n",
      "        [-5.8741],\n",
      "        [-5.8852],\n",
      "        [-5.8504],\n",
      "        [-5.8786],\n",
      "        [-5.8801],\n",
      "        [-5.8802],\n",
      "        [-5.8670],\n",
      "        [-5.8827],\n",
      "        [-5.8850],\n",
      "        [-5.8741],\n",
      "        [-5.8792],\n",
      "        [-5.8882],\n",
      "        [-5.8765],\n",
      "        [-5.8662],\n",
      "        [-5.8629],\n",
      "        [-5.8771],\n",
      "        [-5.8773],\n",
      "        [-5.8676],\n",
      "        [-5.8776],\n",
      "        [-5.8778],\n",
      "        [-5.8769],\n",
      "        [-5.8703],\n",
      "        [-5.8695],\n",
      "        [-5.8712],\n",
      "        [-5.8786],\n",
      "        [-5.8513],\n",
      "        [-5.8713],\n",
      "        [-5.8760],\n",
      "        [-5.8652],\n",
      "        [-5.8738],\n",
      "        [-5.8800],\n",
      "        [-5.8774],\n",
      "        [-5.8814],\n",
      "        [-5.8801],\n",
      "        [-5.8696],\n",
      "        [-5.8802],\n",
      "        [-5.8978],\n",
      "        [-5.8803],\n",
      "        [-5.8765],\n",
      "        [-5.8802],\n",
      "        [-5.8581],\n",
      "        [-5.8756],\n",
      "        [-5.8781],\n",
      "        [-5.8768],\n",
      "        [-5.8776],\n",
      "        [-5.8742],\n",
      "        [-5.8802],\n",
      "        [-5.8758],\n",
      "        [-5.8753],\n",
      "        [-5.8802],\n",
      "        [-5.8813],\n",
      "        [-5.8744],\n",
      "        [-5.8844],\n",
      "        [-5.8805],\n",
      "        [-5.8803],\n",
      "        [-5.8780],\n",
      "        [-5.8754],\n",
      "        [-5.8738],\n",
      "        [-5.8791],\n",
      "        [-5.8620],\n",
      "        [-5.8715],\n",
      "        [-5.8801],\n",
      "        [-5.8741],\n",
      "        [-5.8618],\n",
      "        [-5.8719],\n",
      "        [-5.8802],\n",
      "        [-5.8549],\n",
      "        [-5.8666],\n",
      "        [-5.8634],\n",
      "        [-5.8811],\n",
      "        [-5.8672],\n",
      "        [-5.8796],\n",
      "        [-5.8805],\n",
      "        [-5.8802],\n",
      "        [-5.8802],\n",
      "        [-5.8791],\n",
      "        [-5.8802],\n",
      "        [-5.8801],\n",
      "        [-5.8791],\n",
      "        [-5.8745],\n",
      "        [-5.8809],\n",
      "        [-5.8863],\n",
      "        [-5.8809],\n",
      "        [-5.8588],\n",
      "        [-5.8803],\n",
      "        [-5.8801],\n",
      "        [-5.8652],\n",
      "        [-5.8895],\n",
      "        [-5.8800],\n",
      "        [-5.8742],\n",
      "        [-5.8731],\n",
      "        [-5.8780],\n",
      "        [-5.8751],\n",
      "        [-5.8714],\n",
      "        [-5.8756],\n",
      "        [-5.8687],\n",
      "        [-5.8801],\n",
      "        [-5.8710],\n",
      "        [-5.8802],\n",
      "        [-5.8775],\n",
      "        [-5.8798],\n",
      "        [-5.8763],\n",
      "        [-5.8805],\n",
      "        [-5.8682],\n",
      "        [-5.8742],\n",
      "        [-5.8772],\n",
      "        [-5.8725],\n",
      "        [-5.8798],\n",
      "        [-5.8829],\n",
      "        [-5.8803],\n",
      "        [-5.8613],\n",
      "        [-5.8650],\n",
      "        [-5.8804],\n",
      "        [-5.8802],\n",
      "        [-5.8808],\n",
      "        [-5.8734],\n",
      "        [-5.8601],\n",
      "        [-5.8805],\n",
      "        [-5.8779],\n",
      "        [-5.8802],\n",
      "        [-5.8777],\n",
      "        [-5.8624],\n",
      "        [-5.8850],\n",
      "        [-5.8762],\n",
      "        [-5.8735],\n",
      "        [-5.8732],\n",
      "        [-5.8800],\n",
      "        [-5.8789],\n",
      "        [-5.8916],\n",
      "        [-5.8801],\n",
      "        [-5.8674],\n",
      "        [-5.8801],\n",
      "        [-5.8838],\n",
      "        [-5.8642],\n",
      "        [-5.8767],\n",
      "        [-5.8711],\n",
      "        [-5.8695],\n",
      "        [-5.8778],\n",
      "        [-5.8701],\n",
      "        [-5.8695],\n",
      "        [-5.8802],\n",
      "        [-5.8763],\n",
      "        [-5.8740],\n",
      "        [-5.8718],\n",
      "        [-5.8654],\n",
      "        [-5.8748],\n",
      "        [-5.8748],\n",
      "        [-5.8739],\n",
      "        [-5.8820],\n",
      "        [-5.8599],\n",
      "        [-5.8790],\n",
      "        [-5.8828],\n",
      "        [-5.8795],\n",
      "        [-5.8767],\n",
      "        [-5.8717],\n",
      "        [-5.8781],\n",
      "        [-5.8693],\n",
      "        [-5.8659],\n",
      "        [-5.8708],\n",
      "        [-5.8803],\n",
      "        [-5.8803],\n",
      "        [-5.8675],\n",
      "        [-5.8727],\n",
      "        [-5.8844],\n",
      "        [-5.8745],\n",
      "        [-5.8720],\n",
      "        [-5.8761],\n",
      "        [-5.8766],\n",
      "        [-5.8800],\n",
      "        [-5.8746],\n",
      "        [-5.8801],\n",
      "        [-5.8752],\n",
      "        [-5.8807],\n",
      "        [-5.8786],\n",
      "        [-5.8825],\n",
      "        [-5.8776],\n",
      "        [-5.8738],\n",
      "        [-5.8924],\n",
      "        [-5.8787],\n",
      "        [-5.8806],\n",
      "        [-5.8801],\n",
      "        [-5.8757],\n",
      "        [-5.8803],\n",
      "        [-5.8677],\n",
      "        [-5.8821],\n",
      "        [-5.8839],\n",
      "        [-5.8769],\n",
      "        [-5.8803],\n",
      "        [-5.8716],\n",
      "        [-5.8802],\n",
      "        [-5.8809],\n",
      "        [-5.8810],\n",
      "        [-5.8780],\n",
      "        [-5.8771],\n",
      "        [-5.8808],\n",
      "        [-5.8836],\n",
      "        [-5.8897],\n",
      "        [-5.8687],\n",
      "        [-5.8802],\n",
      "        [-5.8798],\n",
      "        [-5.8685],\n",
      "        [-5.8837],\n",
      "        [-5.8825],\n",
      "        [-5.8693],\n",
      "        [-5.8603],\n",
      "        [-5.8845],\n",
      "        [-5.8802],\n",
      "        [-5.8644],\n",
      "        [-5.8757],\n",
      "        [-5.8754],\n",
      "        [-5.8799],\n",
      "        [-5.8805],\n",
      "        [-5.8802],\n",
      "        [-5.8842],\n",
      "        [-5.8801],\n",
      "        [-5.8798],\n",
      "        [-5.8792],\n",
      "        [-5.8803],\n",
      "        [-5.8694],\n",
      "        [-5.8750],\n",
      "        [-5.8802],\n",
      "        [-5.8745],\n",
      "        [-5.8769],\n",
      "        [-5.8530],\n",
      "        [-5.8800],\n",
      "        [-5.8818],\n",
      "        [-5.8828],\n",
      "        [-5.8801],\n",
      "        [-5.8799],\n",
      "        [-5.8794],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-5.8766]], requires_grad=True))\n",
      "('out_layers_b_var.0', Parameter containing:\n",
      "tensor([[-5.8721]], requires_grad=True))\n",
      "('out_layers_b_var.1', Parameter containing:\n",
      "tensor([[-5.8816]], requires_grad=True))\n",
      "('out_layers_b_var.2', Parameter containing:\n",
      "tensor([[-5.8872]], requires_grad=True))\n",
      "('out_layers_b_var.3', Parameter containing:\n",
      "tensor([[-5.8926]], requires_grad=True))\n",
      "('out_layers_b_var.4', Parameter containing:\n",
      "tensor([[-5.8923]], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in net.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of Net()>\n"
     ]
    }
   ],
   "source": [
    "print(net.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.0323)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(0.0024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(net.out_layers_b_var[0].requires_grad)\n",
    "print(net.pri_out_layers_b_var[0].requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hidden_w_mean.0', Parameter containing:\n",
      "tensor([[ 2.1353, -2.3715,  2.3291,  ..., -2.3068,  2.3694,  2.3030],\n",
      "        [ 2.3663, -2.2922,  2.3625,  ..., -2.3557, -2.3699, -2.3070],\n",
      "        [ 2.3397,  2.3608,  2.2949,  ..., -2.1888,  2.3516,  2.3501],\n",
      "        ...,\n",
      "        [ 2.3077, -2.3618, -2.2659,  ..., -2.3371, -2.3140,  2.2923],\n",
      "        [ 2.3638, -2.3181, -2.3490,  ...,  2.3543,  2.3608, -2.3579],\n",
      "        [-2.3075, -2.3575, -2.3455,  ...,  2.3712, -2.3460,  2.3696]],\n",
      "       requires_grad=True))\n",
      "('hidden_w_mean.1', Parameter containing:\n",
      "tensor([[-0.2620,  0.3067, -0.0851,  ..., -0.1688,  0.1854,  0.1521],\n",
      "        [ 1.0431,  2.3428,  0.9990,  ...,  2.3702,  2.2967,  2.1707],\n",
      "        [ 0.1489,  0.1878, -0.1783,  ...,  0.3391,  0.3604,  0.5605],\n",
      "        ...,\n",
      "        [ 2.0066,  2.3320, -0.0949,  ..., -2.3012, -2.3646, -2.3490],\n",
      "        [ 1.0625,  0.3373, -0.0715,  ..., -0.3154,  1.1491,  0.8978],\n",
      "        [ 1.0238,  0.9340, -0.1178,  ..., -1.0098, -1.0133, -0.9456]],\n",
      "       requires_grad=True))\n",
      "('hidden_b_mean.0', Parameter containing:\n",
      "tensor([[ 7.3184e-02],\n",
      "        [ 2.3095e+00],\n",
      "        [ 2.3928e-01],\n",
      "        [-6.4068e-01],\n",
      "        [-1.7990e+00],\n",
      "        [-1.4562e-01],\n",
      "        [-1.9122e+00],\n",
      "        [-2.1879e+00],\n",
      "        [-3.2464e-01],\n",
      "        [ 2.1377e+00],\n",
      "        [-1.0339e+00],\n",
      "        [-2.1257e+00],\n",
      "        [ 1.5887e-01],\n",
      "        [-2.2501e+00],\n",
      "        [ 1.8045e+00],\n",
      "        [-1.4799e-01],\n",
      "        [-2.0567e-01],\n",
      "        [ 1.8289e+00],\n",
      "        [ 3.6023e-01],\n",
      "        [-1.6240e+00],\n",
      "        [ 4.3147e-01],\n",
      "        [-4.6853e-01],\n",
      "        [ 1.6872e+00],\n",
      "        [ 1.2820e+00],\n",
      "        [-1.9373e+00],\n",
      "        [-4.3383e-02],\n",
      "        [-9.8448e-01],\n",
      "        [ 1.9939e+00],\n",
      "        [ 2.0662e+00],\n",
      "        [-1.8107e-01],\n",
      "        [-1.5909e-01],\n",
      "        [ 1.9802e-01],\n",
      "        [ 1.0824e+00],\n",
      "        [-2.9198e-01],\n",
      "        [ 3.6427e-01],\n",
      "        [ 1.4874e+00],\n",
      "        [ 6.5592e-01],\n",
      "        [ 2.2273e+00],\n",
      "        [ 1.6841e-01],\n",
      "        [-1.2515e+00],\n",
      "        [ 2.1709e+00],\n",
      "        [ 1.5919e+00],\n",
      "        [-1.5683e+00],\n",
      "        [ 2.0946e+00],\n",
      "        [-1.4337e-01],\n",
      "        [-4.7994e-01],\n",
      "        [ 2.1111e+00],\n",
      "        [-2.3243e+00],\n",
      "        [-1.6241e+00],\n",
      "        [ 1.4818e+00],\n",
      "        [-1.1841e+00],\n",
      "        [-2.3649e+00],\n",
      "        [ 8.9621e-01],\n",
      "        [ 2.2648e+00],\n",
      "        [-1.0091e+00],\n",
      "        [-2.2968e-02],\n",
      "        [-1.9315e+00],\n",
      "        [ 6.4050e-01],\n",
      "        [-1.0873e+00],\n",
      "        [-3.4036e-01],\n",
      "        [ 2.1877e-01],\n",
      "        [ 1.6753e+00],\n",
      "        [ 1.0929e-01],\n",
      "        [ 7.7575e-01],\n",
      "        [ 1.9257e+00],\n",
      "        [-1.9215e+00],\n",
      "        [-1.5054e+00],\n",
      "        [-2.1113e+00],\n",
      "        [ 6.9371e-01],\n",
      "        [ 8.2430e-01],\n",
      "        [ 2.0484e+00],\n",
      "        [-2.0822e+00],\n",
      "        [ 2.2434e+00],\n",
      "        [ 3.8886e-01],\n",
      "        [ 1.8353e+00],\n",
      "        [ 2.3222e+00],\n",
      "        [-9.8905e-01],\n",
      "        [ 1.9898e-01],\n",
      "        [ 1.7899e+00],\n",
      "        [-2.2631e+00],\n",
      "        [-2.9900e-01],\n",
      "        [ 1.3400e+00],\n",
      "        [-1.4398e+00],\n",
      "        [-4.5716e-01],\n",
      "        [-1.8784e+00],\n",
      "        [ 1.5705e+00],\n",
      "        [ 1.4737e+00],\n",
      "        [ 2.0819e+00],\n",
      "        [ 1.5742e+00],\n",
      "        [ 1.7253e+00],\n",
      "        [-4.8422e-04],\n",
      "        [ 2.2888e+00],\n",
      "        [ 1.7451e+00],\n",
      "        [-2.3041e+00],\n",
      "        [ 1.9469e+00],\n",
      "        [ 1.5928e-02],\n",
      "        [-1.6836e+00],\n",
      "        [ 3.2561e-02],\n",
      "        [-2.4873e-01],\n",
      "        [-9.2043e-02],\n",
      "        [ 1.0977e+00],\n",
      "        [-5.3692e-01],\n",
      "        [ 2.2932e+00],\n",
      "        [ 2.2232e+00],\n",
      "        [-8.9688e-01],\n",
      "        [-1.8646e+00],\n",
      "        [-1.7328e+00],\n",
      "        [-2.3480e+00],\n",
      "        [-2.3502e+00],\n",
      "        [-2.2532e+00],\n",
      "        [-5.4669e-02],\n",
      "        [ 2.3352e+00],\n",
      "        [-1.6414e+00],\n",
      "        [-2.3347e+00],\n",
      "        [-3.9569e-01],\n",
      "        [ 5.7118e-01],\n",
      "        [-2.1611e+00],\n",
      "        [ 3.3158e-01],\n",
      "        [-2.2303e+00],\n",
      "        [ 1.5624e+00],\n",
      "        [ 6.3964e-01],\n",
      "        [ 2.1244e+00],\n",
      "        [ 1.1079e+00],\n",
      "        [ 2.3239e+00],\n",
      "        [-2.0749e+00],\n",
      "        [-2.3692e+00],\n",
      "        [-6.4252e-01],\n",
      "        [-1.2143e-01],\n",
      "        [-3.6193e-01],\n",
      "        [-1.7455e+00],\n",
      "        [ 5.9657e-01],\n",
      "        [ 1.9306e+00],\n",
      "        [-1.2006e+00],\n",
      "        [-1.7680e+00],\n",
      "        [-4.0732e-01],\n",
      "        [ 1.6800e+00],\n",
      "        [ 1.9934e+00],\n",
      "        [ 1.8685e+00],\n",
      "        [-9.0322e-01],\n",
      "        [ 7.2160e-01],\n",
      "        [ 9.7510e-01],\n",
      "        [-1.6433e+00],\n",
      "        [ 1.6456e+00],\n",
      "        [ 2.2558e+00],\n",
      "        [-2.5056e-01],\n",
      "        [ 1.5971e+00],\n",
      "        [ 1.8624e+00],\n",
      "        [-1.3201e+00],\n",
      "        [-2.2802e+00],\n",
      "        [-9.4493e-01],\n",
      "        [ 2.2291e+00],\n",
      "        [ 2.0318e+00],\n",
      "        [-1.4662e+00],\n",
      "        [ 1.7874e+00],\n",
      "        [ 5.5809e-01],\n",
      "        [ 3.2492e-01],\n",
      "        [ 9.5593e-01],\n",
      "        [ 1.5520e+00],\n",
      "        [ 1.1289e+00],\n",
      "        [-1.9133e+00],\n",
      "        [-1.5007e+00],\n",
      "        [-5.1735e-01],\n",
      "        [-1.3164e+00],\n",
      "        [-1.1719e+00],\n",
      "        [-8.8193e-02],\n",
      "        [-2.7175e-01],\n",
      "        [ 8.1259e-01],\n",
      "        [ 1.5646e+00],\n",
      "        [-1.3514e+00],\n",
      "        [ 1.4241e+00],\n",
      "        [-2.1133e+00],\n",
      "        [ 4.6230e-01],\n",
      "        [ 8.1658e-01],\n",
      "        [ 1.9523e+00],\n",
      "        [ 3.3370e-01],\n",
      "        [-7.5962e-01],\n",
      "        [-6.6080e-01],\n",
      "        [ 1.0954e+00],\n",
      "        [ 5.7147e-01],\n",
      "        [ 2.2426e+00],\n",
      "        [ 2.0248e+00],\n",
      "        [-3.1514e-01],\n",
      "        [ 1.2594e+00],\n",
      "        [ 1.2579e+00],\n",
      "        [-1.4259e+00],\n",
      "        [-2.3306e+00],\n",
      "        [ 3.7031e-01],\n",
      "        [ 2.9298e-01],\n",
      "        [-6.0299e-01],\n",
      "        [ 4.9932e-03],\n",
      "        [ 1.6673e+00],\n",
      "        [ 1.3413e-01],\n",
      "        [ 1.8450e-01],\n",
      "        [-1.8123e+00],\n",
      "        [ 1.1755e+00],\n",
      "        [ 1.8019e+00],\n",
      "        [ 2.3171e+00],\n",
      "        [ 2.1262e+00],\n",
      "        [-1.4032e+00],\n",
      "        [ 9.0120e-03],\n",
      "        [-2.3621e+00],\n",
      "        [ 1.4306e+00],\n",
      "        [ 4.9074e-01],\n",
      "        [-2.1489e+00],\n",
      "        [-5.8219e-01],\n",
      "        [-1.9163e-01],\n",
      "        [-1.3347e+00],\n",
      "        [-1.9459e+00],\n",
      "        [ 1.8615e+00],\n",
      "        [ 2.2288e+00],\n",
      "        [-1.7391e+00],\n",
      "        [ 1.5195e+00],\n",
      "        [-2.2377e+00],\n",
      "        [-1.3816e+00],\n",
      "        [ 2.2324e+00],\n",
      "        [-1.6699e+00],\n",
      "        [ 1.6949e+00],\n",
      "        [ 1.4249e-01],\n",
      "        [ 2.2246e+00],\n",
      "        [-1.1422e+00],\n",
      "        [-7.6349e-02],\n",
      "        [-2.2832e+00],\n",
      "        [ 2.0721e+00],\n",
      "        [ 2.1739e+00],\n",
      "        [-5.3654e-01],\n",
      "        [ 1.3899e+00],\n",
      "        [-2.2327e+00],\n",
      "        [-2.2353e+00],\n",
      "        [-1.3775e+00],\n",
      "        [-2.0349e+00],\n",
      "        [-1.9381e-02],\n",
      "        [-2.2919e+00],\n",
      "        [-1.9251e+00],\n",
      "        [ 6.7566e-02],\n",
      "        [ 2.3295e+00],\n",
      "        [-5.6011e-01],\n",
      "        [-2.0987e+00],\n",
      "        [-4.4961e-02],\n",
      "        [ 2.1857e+00],\n",
      "        [-1.7167e+00],\n",
      "        [ 1.6171e+00],\n",
      "        [ 1.1269e+00],\n",
      "        [ 3.8000e-01],\n",
      "        [ 2.8544e-02],\n",
      "        [-1.7354e+00],\n",
      "        [-1.9645e-01],\n",
      "        [ 9.8288e-01],\n",
      "        [-1.9034e+00],\n",
      "        [ 1.1573e-01],\n",
      "        [-6.8918e-01],\n",
      "        [-1.2816e+00],\n",
      "        [ 1.0396e+00],\n",
      "        [-1.2297e+00],\n",
      "        [ 2.3051e+00],\n",
      "        [-1.7230e+00],\n",
      "        [ 9.5795e-01]], requires_grad=True))\n",
      "('hidden_b_mean.1', Parameter containing:\n",
      "tensor([[ 2.3284],\n",
      "        [-2.2878],\n",
      "        [ 2.3243],\n",
      "        [ 2.2949],\n",
      "        [ 2.2987],\n",
      "        [-2.3647],\n",
      "        [ 2.2774],\n",
      "        [-2.3026],\n",
      "        [-2.3524],\n",
      "        [-2.3574],\n",
      "        [-1.9553],\n",
      "        [ 2.2866],\n",
      "        [ 2.3241],\n",
      "        [ 2.2968],\n",
      "        [-2.3202],\n",
      "        [ 2.3536],\n",
      "        [-2.3653],\n",
      "        [-2.3072],\n",
      "        [ 2.2792],\n",
      "        [-2.3388],\n",
      "        [ 2.3295],\n",
      "        [ 2.3564],\n",
      "        [ 2.3659],\n",
      "        [ 2.2979],\n",
      "        [ 2.3445],\n",
      "        [-2.2872],\n",
      "        [ 2.3401],\n",
      "        [-2.3069],\n",
      "        [ 2.3704],\n",
      "        [ 2.3466],\n",
      "        [ 2.3628],\n",
      "        [-2.2957],\n",
      "        [-2.3082],\n",
      "        [-2.2802],\n",
      "        [-2.3298],\n",
      "        [ 2.3469],\n",
      "        [ 2.3365],\n",
      "        [-2.3269],\n",
      "        [-2.3694],\n",
      "        [-2.3457],\n",
      "        [ 2.2776],\n",
      "        [ 2.2621],\n",
      "        [-2.3373],\n",
      "        [-2.2931],\n",
      "        [-2.3598],\n",
      "        [-2.3182],\n",
      "        [ 2.3262],\n",
      "        [-2.3710],\n",
      "        [ 2.3650],\n",
      "        [-2.3577],\n",
      "        [-1.8887],\n",
      "        [-2.3508],\n",
      "        [ 2.3511],\n",
      "        [ 2.3332],\n",
      "        [ 2.3098],\n",
      "        [-2.3287],\n",
      "        [ 2.3653],\n",
      "        [ 2.3656],\n",
      "        [ 2.2948],\n",
      "        [-2.3042],\n",
      "        [-2.3792],\n",
      "        [ 2.3684],\n",
      "        [ 2.3656],\n",
      "        [ 2.3088],\n",
      "        [ 2.3282],\n",
      "        [ 2.3370],\n",
      "        [-2.3430],\n",
      "        [-2.3169],\n",
      "        [ 2.2968],\n",
      "        [ 2.3291],\n",
      "        [-2.3328],\n",
      "        [ 2.3664],\n",
      "        [-2.3319],\n",
      "        [ 2.3057],\n",
      "        [ 2.3442],\n",
      "        [-2.2979],\n",
      "        [-2.3433],\n",
      "        [-2.3009],\n",
      "        [ 2.3592],\n",
      "        [ 2.3472],\n",
      "        [-2.3461],\n",
      "        [ 2.3012],\n",
      "        [ 2.3420],\n",
      "        [-2.3672],\n",
      "        [-2.3662],\n",
      "        [ 2.3282],\n",
      "        [ 2.2819],\n",
      "        [ 2.3574],\n",
      "        [-2.3191],\n",
      "        [ 2.3138],\n",
      "        [ 2.3170],\n",
      "        [-2.3093],\n",
      "        [ 2.3199],\n",
      "        [-2.2916],\n",
      "        [-2.3305],\n",
      "        [-2.3099],\n",
      "        [-2.2948],\n",
      "        [-2.3504],\n",
      "        [-2.2695],\n",
      "        [-2.3451],\n",
      "        [ 2.3058],\n",
      "        [-2.3656],\n",
      "        [-2.2801],\n",
      "        [-2.3643],\n",
      "        [ 1.8750],\n",
      "        [-2.2265],\n",
      "        [ 2.2886],\n",
      "        [-2.3628],\n",
      "        [ 2.2371],\n",
      "        [-2.3357],\n",
      "        [-2.3137],\n",
      "        [-2.3420],\n",
      "        [-2.2875],\n",
      "        [-2.3271],\n",
      "        [-2.2890],\n",
      "        [-2.3204],\n",
      "        [ 2.3380],\n",
      "        [ 1.8184],\n",
      "        [-2.3558],\n",
      "        [-2.3475],\n",
      "        [ 2.3649],\n",
      "        [-2.3241],\n",
      "        [-2.3274],\n",
      "        [ 2.3552],\n",
      "        [-2.2963],\n",
      "        [ 2.3693],\n",
      "        [-2.3324],\n",
      "        [-2.3361],\n",
      "        [-2.3443],\n",
      "        [-2.3695],\n",
      "        [-2.3119],\n",
      "        [-2.3477],\n",
      "        [-2.3212],\n",
      "        [-2.3517],\n",
      "        [-2.2951],\n",
      "        [-2.3110],\n",
      "        [ 2.3643],\n",
      "        [-2.3010],\n",
      "        [-2.3569],\n",
      "        [ 2.3329],\n",
      "        [-2.3310],\n",
      "        [-1.7785],\n",
      "        [-2.3209],\n",
      "        [ 2.2924],\n",
      "        [ 2.3718],\n",
      "        [ 2.3123],\n",
      "        [-2.3400],\n",
      "        [-2.3383],\n",
      "        [ 2.3310],\n",
      "        [-2.3521],\n",
      "        [ 2.3703],\n",
      "        [-2.3221],\n",
      "        [ 2.3252],\n",
      "        [-2.1616],\n",
      "        [ 2.2350],\n",
      "        [-2.3053],\n",
      "        [ 2.3177],\n",
      "        [ 2.3522],\n",
      "        [-2.3342],\n",
      "        [-2.3005],\n",
      "        [-2.2968],\n",
      "        [ 2.3373],\n",
      "        [ 2.2686],\n",
      "        [ 2.3101],\n",
      "        [ 2.3499],\n",
      "        [-2.3389],\n",
      "        [-2.2929],\n",
      "        [ 2.3472],\n",
      "        [-2.3122],\n",
      "        [-2.3185],\n",
      "        [ 2.3090],\n",
      "        [ 2.3157],\n",
      "        [-2.2910],\n",
      "        [-2.3282],\n",
      "        [-2.2993],\n",
      "        [ 2.3680],\n",
      "        [-2.3551],\n",
      "        [ 2.3056],\n",
      "        [-2.3530],\n",
      "        [-2.3505],\n",
      "        [ 2.3072],\n",
      "        [ 2.3607],\n",
      "        [-2.2717],\n",
      "        [-2.3275],\n",
      "        [ 2.2858],\n",
      "        [-2.3661],\n",
      "        [-2.3214],\n",
      "        [ 2.3426],\n",
      "        [ 2.3242],\n",
      "        [-2.3657],\n",
      "        [-2.3042],\n",
      "        [ 2.3584],\n",
      "        [ 2.3047],\n",
      "        [-2.2786],\n",
      "        [-2.3598],\n",
      "        [-2.3631],\n",
      "        [ 2.3590],\n",
      "        [-2.3500],\n",
      "        [ 2.3580],\n",
      "        [-2.3660],\n",
      "        [ 2.3535],\n",
      "        [ 2.3250],\n",
      "        [-2.3521],\n",
      "        [ 2.2906],\n",
      "        [ 2.3656],\n",
      "        [ 2.3079],\n",
      "        [-2.3331],\n",
      "        [ 2.3408],\n",
      "        [-2.3617],\n",
      "        [-2.2947],\n",
      "        [-2.2921],\n",
      "        [ 2.3076],\n",
      "        [-2.3033],\n",
      "        [ 2.3467],\n",
      "        [-2.2843],\n",
      "        [ 2.3641],\n",
      "        [-2.3158],\n",
      "        [-2.3615],\n",
      "        [ 2.3284],\n",
      "        [-2.3645],\n",
      "        [ 2.3521],\n",
      "        [ 1.8501],\n",
      "        [ 2.3185],\n",
      "        [ 2.3118],\n",
      "        [-2.3156],\n",
      "        [-2.3615],\n",
      "        [ 2.3002],\n",
      "        [ 2.3662],\n",
      "        [-2.3595],\n",
      "        [-2.3262],\n",
      "        [-2.2898],\n",
      "        [-2.2942],\n",
      "        [-2.3319],\n",
      "        [-2.2954],\n",
      "        [-2.3178],\n",
      "        [-2.3587],\n",
      "        [-2.2946],\n",
      "        [ 2.3545],\n",
      "        [ 2.3711],\n",
      "        [ 2.3465],\n",
      "        [-2.3293],\n",
      "        [ 2.3500],\n",
      "        [ 2.3704],\n",
      "        [-2.3585],\n",
      "        [-2.3441],\n",
      "        [ 2.3054],\n",
      "        [ 2.2893],\n",
      "        [ 2.3242],\n",
      "        [-2.3352],\n",
      "        [ 2.3248],\n",
      "        [ 2.2629],\n",
      "        [ 2.3529],\n",
      "        [-2.3582],\n",
      "        [ 2.3660],\n",
      "        [-2.2939],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 1.7611]], requires_grad=True))\n",
      "('hidden_w_var.0', Parameter containing:\n",
      "tensor([[-2.0060, -2.0060, -2.0060,  ..., -2.0060, -2.0060, -2.0060],\n",
      "        [-2.0060, -2.0060, -2.0060,  ..., -2.0060, -2.0060, -2.0060],\n",
      "        [-2.0060, -2.0060, -2.0060,  ..., -2.0060, -2.0060, -2.0060],\n",
      "        ...,\n",
      "        [-2.0060, -2.0060, -2.0060,  ..., -2.0060, -2.0060, -2.0060],\n",
      "        [-2.0060, -2.0060, -2.0060,  ..., -2.0060, -2.0060, -2.0060],\n",
      "        [-2.0060, -2.0060, -2.0060,  ..., -2.0060, -2.0060, -2.0060]],\n",
      "       requires_grad=True))\n",
      "('hidden_w_var.1', Parameter containing:\n",
      "tensor([[-2.0043, -1.9662, -1.9985,  ..., -2.0133, -2.0021, -2.0196],\n",
      "        [-1.9822, -2.0060, -2.0309,  ..., -2.0060, -2.0060, -2.0060],\n",
      "        [-1.9854, -2.0167, -1.9416,  ..., -2.0111, -2.0151, -1.9843],\n",
      "        ...,\n",
      "        [-2.0060, -2.0061, -2.0152,  ..., -2.0060, -2.0060, -2.0062],\n",
      "        [-2.0036, -2.0177, -1.9933,  ..., -2.0207, -1.9812, -2.0193],\n",
      "        [-1.9610, -2.0431, -1.9964,  ..., -2.0184, -1.9940, -2.0399]],\n",
      "       requires_grad=True))\n",
      "('hidden_b_var.0', Parameter containing:\n",
      "tensor([[-2.0101],\n",
      "        [-2.0063],\n",
      "        [-2.0104],\n",
      "        [-2.0159],\n",
      "        [-2.0087],\n",
      "        [-2.0054],\n",
      "        [-2.0009],\n",
      "        [-2.0058],\n",
      "        [-2.0135],\n",
      "        [-2.0087],\n",
      "        [-2.0133],\n",
      "        [-2.0069],\n",
      "        [-2.0025],\n",
      "        [-2.0082],\n",
      "        [-2.0030],\n",
      "        [-2.0068],\n",
      "        [-2.0014],\n",
      "        [-2.0048],\n",
      "        [-1.9935],\n",
      "        [-2.0063],\n",
      "        [-2.0007],\n",
      "        [-2.0073],\n",
      "        [-2.0175],\n",
      "        [-2.0107],\n",
      "        [-2.0053],\n",
      "        [-2.0074],\n",
      "        [-2.0087],\n",
      "        [-2.0094],\n",
      "        [-2.0048],\n",
      "        [-2.0108],\n",
      "        [-2.0042],\n",
      "        [-2.0062],\n",
      "        [-2.0028],\n",
      "        [-2.0072],\n",
      "        [-2.0056],\n",
      "        [-2.0032],\n",
      "        [-2.0057],\n",
      "        [-2.0073],\n",
      "        [-2.0074],\n",
      "        [-2.0134],\n",
      "        [-2.0010],\n",
      "        [-2.0171],\n",
      "        [-2.0095],\n",
      "        [-2.0109],\n",
      "        [-2.0014],\n",
      "        [-2.0016],\n",
      "        [-2.0065],\n",
      "        [-2.0059],\n",
      "        [-2.0039],\n",
      "        [-1.9952],\n",
      "        [-2.0125],\n",
      "        [-2.0060],\n",
      "        [-2.0204],\n",
      "        [-2.0062],\n",
      "        [-2.0043],\n",
      "        [-2.0124],\n",
      "        [-2.0060],\n",
      "        [-2.0061],\n",
      "        [-2.0111],\n",
      "        [-2.0034],\n",
      "        [-2.0058],\n",
      "        [-1.9966],\n",
      "        [-2.0069],\n",
      "        [-1.9872],\n",
      "        [-2.0090],\n",
      "        [-2.0001],\n",
      "        [-2.0036],\n",
      "        [-2.0069],\n",
      "        [-2.0111],\n",
      "        [-2.0021],\n",
      "        [-2.0064],\n",
      "        [-2.0044],\n",
      "        [-2.0053],\n",
      "        [-2.0086],\n",
      "        [-2.0017],\n",
      "        [-2.0079],\n",
      "        [-2.0048],\n",
      "        [-2.0113],\n",
      "        [-2.0017],\n",
      "        [-2.0064],\n",
      "        [-1.9941],\n",
      "        [-2.0079],\n",
      "        [-2.0107],\n",
      "        [-2.0097],\n",
      "        [-2.0072],\n",
      "        [-2.0078],\n",
      "        [-2.0086],\n",
      "        [-2.0065],\n",
      "        [-2.0031],\n",
      "        [-2.0183],\n",
      "        [-2.0065],\n",
      "        [-2.0055],\n",
      "        [-2.0117],\n",
      "        [-2.0094],\n",
      "        [-2.0049],\n",
      "        [-2.0131],\n",
      "        [-1.9951],\n",
      "        [-2.0027],\n",
      "        [-2.0082],\n",
      "        [-2.0073],\n",
      "        [-2.0050],\n",
      "        [-2.0063],\n",
      "        [-2.0050],\n",
      "        [-2.0026],\n",
      "        [-2.0010],\n",
      "        [-2.0096],\n",
      "        [-2.0064],\n",
      "        [-2.0066],\n",
      "        [-2.0060],\n",
      "        [-2.0066],\n",
      "        [-2.0013],\n",
      "        [-2.0063],\n",
      "        [-2.0059],\n",
      "        [-2.0061],\n",
      "        [-2.0084],\n",
      "        [-2.0078],\n",
      "        [-2.0081],\n",
      "        [-2.0111],\n",
      "        [-2.0061],\n",
      "        [-1.9988],\n",
      "        [-2.0034],\n",
      "        [-2.0077],\n",
      "        [-1.9921],\n",
      "        [-2.0059],\n",
      "        [-2.0113],\n",
      "        [-2.0060],\n",
      "        [-2.0018],\n",
      "        [-2.0096],\n",
      "        [-2.0079],\n",
      "        [-2.0130],\n",
      "        [-2.0019],\n",
      "        [-2.0062],\n",
      "        [-2.0035],\n",
      "        [-2.0042],\n",
      "        [-1.9977],\n",
      "        [-2.0091],\n",
      "        [-2.0061],\n",
      "        [-1.9996],\n",
      "        [-2.0078],\n",
      "        [-1.9990],\n",
      "        [-1.9877],\n",
      "        [-1.9953],\n",
      "        [-2.0069],\n",
      "        [-2.0092],\n",
      "        [-2.0102],\n",
      "        [-2.0072],\n",
      "        [-2.0144],\n",
      "        [-2.0274],\n",
      "        [-2.0061],\n",
      "        [-2.0083],\n",
      "        [-2.0063],\n",
      "        [-2.0097],\n",
      "        [-2.0142],\n",
      "        [-2.0083],\n",
      "        [-1.9908],\n",
      "        [-1.9995],\n",
      "        [-2.0051],\n",
      "        [-2.0081],\n",
      "        [-2.0121],\n",
      "        [-2.0018],\n",
      "        [-2.0018],\n",
      "        [-2.0002],\n",
      "        [-2.0078],\n",
      "        [-2.0035],\n",
      "        [-1.9985],\n",
      "        [-2.0131],\n",
      "        [-2.0095],\n",
      "        [-2.0092],\n",
      "        [-2.0184],\n",
      "        [-2.0050],\n",
      "        [-2.0073],\n",
      "        [-2.0098],\n",
      "        [-2.0039],\n",
      "        [-2.0061],\n",
      "        [-2.0031],\n",
      "        [-2.0078],\n",
      "        [-2.0055],\n",
      "        [-2.0065],\n",
      "        [-2.0126],\n",
      "        [-2.0057],\n",
      "        [-2.0040],\n",
      "        [-2.0015],\n",
      "        [-2.0131],\n",
      "        [-2.0094],\n",
      "        [-2.0109],\n",
      "        [-2.0060],\n",
      "        [-2.0096],\n",
      "        [-2.0061],\n",
      "        [-2.0048],\n",
      "        [-2.0158],\n",
      "        [-2.0007],\n",
      "        [-2.0118],\n",
      "        [-2.0074],\n",
      "        [-2.0099],\n",
      "        [-2.0048],\n",
      "        [-1.9970],\n",
      "        [-2.0060],\n",
      "        [-2.0047],\n",
      "        [-2.0082],\n",
      "        [-2.0048],\n",
      "        [-2.0060],\n",
      "        [-2.0051],\n",
      "        [-2.0054],\n",
      "        [-2.0029],\n",
      "        [-1.9978],\n",
      "        [-2.0140],\n",
      "        [-2.0060],\n",
      "        [-2.0056],\n",
      "        [-2.0139],\n",
      "        [-2.0053],\n",
      "        [-2.0061],\n",
      "        [-2.0106],\n",
      "        [-2.0060],\n",
      "        [-2.0056],\n",
      "        [-2.0066],\n",
      "        [-2.0058],\n",
      "        [-2.0053],\n",
      "        [-2.0129],\n",
      "        [-2.0085],\n",
      "        [-2.0033],\n",
      "        [-2.0090],\n",
      "        [-2.0069],\n",
      "        [-2.0084],\n",
      "        [-2.0064],\n",
      "        [-2.0051],\n",
      "        [-2.0069],\n",
      "        [-2.0088],\n",
      "        [-2.0052],\n",
      "        [-2.0102],\n",
      "        [-2.0066],\n",
      "        [-2.0023],\n",
      "        [-2.0064],\n",
      "        [-2.0062],\n",
      "        [-2.0010],\n",
      "        [-2.0060],\n",
      "        [-2.0003],\n",
      "        [-2.0064],\n",
      "        [-2.0046],\n",
      "        [-2.0054],\n",
      "        [-2.0075],\n",
      "        [-2.0028],\n",
      "        [-2.0136],\n",
      "        [-2.0021],\n",
      "        [-2.0050],\n",
      "        [-2.0121],\n",
      "        [-2.0113],\n",
      "        [-2.0069],\n",
      "        [-2.0112],\n",
      "        [-2.0068],\n",
      "        [-2.0152],\n",
      "        [-2.0085],\n",
      "        [-2.0128],\n",
      "        [-2.0059],\n",
      "        [-2.0060],\n",
      "        [-2.0033],\n",
      "        [-2.0102]], requires_grad=True))\n",
      "('hidden_b_var.1', Parameter containing:\n",
      "tensor([[-2.0057],\n",
      "        [-2.0049],\n",
      "        [-2.0053],\n",
      "        [-2.0057],\n",
      "        [-2.0065],\n",
      "        [-2.0060],\n",
      "        [-2.0062],\n",
      "        [-2.0066],\n",
      "        [-2.0066],\n",
      "        [-2.0061],\n",
      "        [-2.0048],\n",
      "        [-2.0061],\n",
      "        [-2.0057],\n",
      "        [-2.0067],\n",
      "        [-2.0048],\n",
      "        [-2.0060],\n",
      "        [-2.0061],\n",
      "        [-2.0062],\n",
      "        [-2.0061],\n",
      "        [-2.0061],\n",
      "        [-2.0057],\n",
      "        [-2.0052],\n",
      "        [-2.0065],\n",
      "        [-2.0063],\n",
      "        [-2.0058],\n",
      "        [-2.0056],\n",
      "        [-2.0070],\n",
      "        [-2.0065],\n",
      "        [-2.0058],\n",
      "        [-2.0061],\n",
      "        [-2.0061],\n",
      "        [-2.0052],\n",
      "        [-2.0060],\n",
      "        [-2.0064],\n",
      "        [-2.0061],\n",
      "        [-2.0056],\n",
      "        [-2.0060],\n",
      "        [-2.0061],\n",
      "        [-2.0060],\n",
      "        [-2.0062],\n",
      "        [-2.0053],\n",
      "        [-2.0061],\n",
      "        [-2.0063],\n",
      "        [-2.0055],\n",
      "        [-2.0061],\n",
      "        [-2.0054],\n",
      "        [-2.0059],\n",
      "        [-2.0061],\n",
      "        [-2.0060],\n",
      "        [-2.0068],\n",
      "        [-2.0059],\n",
      "        [-2.0045],\n",
      "        [-2.0058],\n",
      "        [-2.0056],\n",
      "        [-2.0061],\n",
      "        [-2.0066],\n",
      "        [-2.0052],\n",
      "        [-2.0065],\n",
      "        [-2.0051],\n",
      "        [-2.0064],\n",
      "        [-2.0060],\n",
      "        [-2.0058],\n",
      "        [-2.0069],\n",
      "        [-2.0074],\n",
      "        [-2.0070],\n",
      "        [-2.0055],\n",
      "        [-2.0061],\n",
      "        [-2.0060],\n",
      "        [-2.0066],\n",
      "        [-2.0078],\n",
      "        [-2.0059],\n",
      "        [-2.0060],\n",
      "        [-2.0069],\n",
      "        [-2.0049],\n",
      "        [-2.0072],\n",
      "        [-2.0064],\n",
      "        [-2.0054],\n",
      "        [-2.0061],\n",
      "        [-2.0053],\n",
      "        [-2.0063],\n",
      "        [-2.0052],\n",
      "        [-2.0064],\n",
      "        [-2.0062],\n",
      "        [-2.0060],\n",
      "        [-2.0070],\n",
      "        [-2.0048],\n",
      "        [-2.0068],\n",
      "        [-2.0060],\n",
      "        [-2.0062],\n",
      "        [-2.0057],\n",
      "        [-2.0053],\n",
      "        [-2.0060],\n",
      "        [-2.0051],\n",
      "        [-2.0072],\n",
      "        [-2.0060],\n",
      "        [-2.0051],\n",
      "        [-2.0052],\n",
      "        [-2.0067],\n",
      "        [-2.0048],\n",
      "        [-2.0047],\n",
      "        [-2.0055],\n",
      "        [-2.0060],\n",
      "        [-2.0063],\n",
      "        [-2.0061],\n",
      "        [-2.0057],\n",
      "        [-2.0044],\n",
      "        [-2.0059],\n",
      "        [-2.0059],\n",
      "        [-2.0042],\n",
      "        [-2.0063],\n",
      "        [-2.0062],\n",
      "        [-2.0061],\n",
      "        [-2.0066],\n",
      "        [-2.0058],\n",
      "        [-2.0054],\n",
      "        [-2.0054],\n",
      "        [-2.0061],\n",
      "        [-2.0057],\n",
      "        [-2.0070],\n",
      "        [-2.0062],\n",
      "        [-2.0065],\n",
      "        [-2.0070],\n",
      "        [-2.0069],\n",
      "        [-2.0055],\n",
      "        [-2.0064],\n",
      "        [-2.0057],\n",
      "        [-2.0072],\n",
      "        [-2.0060],\n",
      "        [-2.0059],\n",
      "        [-2.0061],\n",
      "        [-2.0064],\n",
      "        [-2.0060],\n",
      "        [-2.0055],\n",
      "        [-2.0069],\n",
      "        [-2.0062],\n",
      "        [-2.0058],\n",
      "        [-2.0057],\n",
      "        [-2.0064],\n",
      "        [-2.0066],\n",
      "        [-2.0060],\n",
      "        [-2.0068],\n",
      "        [-2.0062],\n",
      "        [-2.0059],\n",
      "        [-2.0064],\n",
      "        [-2.0061],\n",
      "        [-2.0067],\n",
      "        [-2.0060],\n",
      "        [-2.0060],\n",
      "        [-2.0064],\n",
      "        [-2.0071],\n",
      "        [-2.0060],\n",
      "        [-2.0060],\n",
      "        [-2.0056],\n",
      "        [-2.0071],\n",
      "        [-2.0061],\n",
      "        [-2.0063],\n",
      "        [-2.0066],\n",
      "        [-2.0062],\n",
      "        [-2.0064],\n",
      "        [-2.0064],\n",
      "        [-2.0060],\n",
      "        [-2.0066],\n",
      "        [-2.0066],\n",
      "        [-2.0060],\n",
      "        [-2.0061],\n",
      "        [-2.0060],\n",
      "        [-2.0058],\n",
      "        [-2.0058],\n",
      "        [-2.0062],\n",
      "        [-2.0058],\n",
      "        [-2.0060],\n",
      "        [-2.0060],\n",
      "        [-2.0078],\n",
      "        [-2.0060],\n",
      "        [-2.0060],\n",
      "        [-2.0068],\n",
      "        [-2.0062],\n",
      "        [-2.0064],\n",
      "        [-2.0057],\n",
      "        [-2.0062],\n",
      "        [-2.0069],\n",
      "        [-2.0063],\n",
      "        [-2.0063],\n",
      "        [-2.0066],\n",
      "        [-2.0067],\n",
      "        [-2.0061],\n",
      "        [-2.0060],\n",
      "        [-2.0069],\n",
      "        [-2.0061],\n",
      "        [-2.0064],\n",
      "        [-2.0060],\n",
      "        [-2.0070],\n",
      "        [-2.0061],\n",
      "        [-2.0059],\n",
      "        [-2.0060],\n",
      "        [-2.0059],\n",
      "        [-2.0057],\n",
      "        [-2.0056],\n",
      "        [-2.0063],\n",
      "        [-2.0055],\n",
      "        [-2.0060],\n",
      "        [-2.0063],\n",
      "        [-2.0062],\n",
      "        [-2.0058],\n",
      "        [-2.0062],\n",
      "        [-2.0053],\n",
      "        [-2.0060],\n",
      "        [-2.0059],\n",
      "        [-2.0060],\n",
      "        [-2.0060],\n",
      "        [-2.0056],\n",
      "        [-2.0062],\n",
      "        [-2.0054],\n",
      "        [-2.0058],\n",
      "        [-2.0062],\n",
      "        [-2.0061],\n",
      "        [-2.0060],\n",
      "        [-2.0060],\n",
      "        [-2.0074],\n",
      "        [-2.0062],\n",
      "        [-2.0060],\n",
      "        [-2.0075],\n",
      "        [-2.0054],\n",
      "        [-2.0061],\n",
      "        [-2.0058],\n",
      "        [-2.0074],\n",
      "        [-2.0059],\n",
      "        [-2.0061],\n",
      "        [-2.0058],\n",
      "        [-2.0061],\n",
      "        [-2.0063],\n",
      "        [-2.0063],\n",
      "        [-2.0060],\n",
      "        [-2.0062],\n",
      "        [-2.0065],\n",
      "        [-2.0055],\n",
      "        [-2.0060],\n",
      "        [-2.0060],\n",
      "        [-2.0061],\n",
      "        [-2.0054],\n",
      "        [-2.0060],\n",
      "        [-2.0063],\n",
      "        [-2.0060],\n",
      "        [-2.0056],\n",
      "        [-2.0070],\n",
      "        [-2.0061],\n",
      "        [-2.0052],\n",
      "        [-2.0066],\n",
      "        [-2.0068],\n",
      "        [-2.0060],\n",
      "        [-2.0045],\n",
      "        [-2.0069],\n",
      "        [-2.0060],\n",
      "        [-2.0059],\n",
      "        [-2.0059],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-2.0059]], requires_grad=True))\n",
      "('out_layers_w_mean.0', Parameter containing:\n",
      "tensor([[-0.1903],\n",
      "        [ 0.0262],\n",
      "        [-0.0187],\n",
      "        [ 0.0391],\n",
      "        [-0.0975],\n",
      "        [ 0.1049],\n",
      "        [-0.0994],\n",
      "        [ 0.0796],\n",
      "        [ 0.1510],\n",
      "        [-0.2374],\n",
      "        [ 0.1518],\n",
      "        [ 0.1402],\n",
      "        [ 0.1292],\n",
      "        [ 0.0045],\n",
      "        [ 0.0320],\n",
      "        [-0.0529],\n",
      "        [-0.1723],\n",
      "        [-0.0487],\n",
      "        [-0.0101],\n",
      "        [-0.1039],\n",
      "        [ 0.0980],\n",
      "        [-0.0898],\n",
      "        [ 0.0149],\n",
      "        [-0.2111],\n",
      "        [-0.2005],\n",
      "        [-0.0352],\n",
      "        [-0.0243],\n",
      "        [ 0.0324],\n",
      "        [ 0.1276],\n",
      "        [-0.0008],\n",
      "        [-0.0485],\n",
      "        [ 0.0467],\n",
      "        [-0.1710],\n",
      "        [-0.0421],\n",
      "        [ 0.1007],\n",
      "        [-0.0359],\n",
      "        [ 0.0170],\n",
      "        [-0.0017],\n",
      "        [ 0.0028],\n",
      "        [ 0.1358],\n",
      "        [ 0.1168],\n",
      "        [ 0.0400],\n",
      "        [-0.1053],\n",
      "        [ 0.1915],\n",
      "        [-0.0676],\n",
      "        [-0.1115],\n",
      "        [ 0.0798],\n",
      "        [-0.1054],\n",
      "        [-0.0671],\n",
      "        [ 0.1163],\n",
      "        [-0.0285],\n",
      "        [ 0.0332],\n",
      "        [ 0.0678],\n",
      "        [-0.1401],\n",
      "        [-0.0023],\n",
      "        [ 0.1802],\n",
      "        [-0.0314],\n",
      "        [ 0.1172],\n",
      "        [ 0.0535],\n",
      "        [ 0.0785],\n",
      "        [-0.0885],\n",
      "        [ 0.1050],\n",
      "        [ 0.1351],\n",
      "        [-0.0167],\n",
      "        [ 0.1122],\n",
      "        [-0.0486],\n",
      "        [ 0.0296],\n",
      "        [ 0.1171],\n",
      "        [-0.1351],\n",
      "        [-0.0918],\n",
      "        [-0.0133],\n",
      "        [-0.0442],\n",
      "        [ 0.1277],\n",
      "        [ 0.0197],\n",
      "        [ 0.1515],\n",
      "        [-0.1221],\n",
      "        [-0.0461],\n",
      "        [-0.0314],\n",
      "        [-0.1424],\n",
      "        [ 0.1186],\n",
      "        [ 0.0110],\n",
      "        [ 0.1450],\n",
      "        [-0.0545],\n",
      "        [ 0.1462],\n",
      "        [-0.1460],\n",
      "        [ 0.0074],\n",
      "        [-0.1978],\n",
      "        [-0.0649],\n",
      "        [-0.2025],\n",
      "        [-0.0720],\n",
      "        [ 0.0533],\n",
      "        [-0.1790],\n",
      "        [ 0.1728],\n",
      "        [ 0.0539],\n",
      "        [-0.1613],\n",
      "        [ 0.1614],\n",
      "        [-0.0549],\n",
      "        [ 0.2185],\n",
      "        [ 0.1172],\n",
      "        [-0.1163],\n",
      "        [ 0.0862],\n",
      "        [ 0.0622],\n",
      "        [ 0.0773],\n",
      "        [-0.0410],\n",
      "        [-0.1419],\n",
      "        [ 0.0584],\n",
      "        [-0.1348],\n",
      "        [ 0.0312],\n",
      "        [-0.0038],\n",
      "        [ 0.2127],\n",
      "        [ 0.1029],\n",
      "        [ 0.0215],\n",
      "        [ 0.1136],\n",
      "        [ 0.0414],\n",
      "        [ 0.0475],\n",
      "        [ 0.0827],\n",
      "        [-0.1627],\n",
      "        [-0.0519],\n",
      "        [ 0.1619],\n",
      "        [-0.2396],\n",
      "        [-0.0534],\n",
      "        [-0.0651],\n",
      "        [ 0.0792],\n",
      "        [-0.0251],\n",
      "        [ 0.1267],\n",
      "        [ 0.0574],\n",
      "        [ 0.2329],\n",
      "        [-0.0465],\n",
      "        [-0.0632],\n",
      "        [-0.0525],\n",
      "        [-0.1053],\n",
      "        [-0.0538],\n",
      "        [-0.0968],\n",
      "        [ 0.1452],\n",
      "        [ 0.0578],\n",
      "        [ 0.0832],\n",
      "        [-0.1313],\n",
      "        [ 0.0547],\n",
      "        [-0.1050],\n",
      "        [ 0.0265],\n",
      "        [ 0.0327],\n",
      "        [ 0.0266],\n",
      "        [-0.1569],\n",
      "        [-0.1224],\n",
      "        [ 0.1686],\n",
      "        [-0.1877],\n",
      "        [ 0.0422],\n",
      "        [-0.0204],\n",
      "        [ 0.0697],\n",
      "        [-0.1029],\n",
      "        [ 0.0396],\n",
      "        [-0.0398],\n",
      "        [-0.0204],\n",
      "        [ 0.1085],\n",
      "        [-0.1440],\n",
      "        [-0.0699],\n",
      "        [ 0.0198],\n",
      "        [ 0.2530],\n",
      "        [-0.1037],\n",
      "        [-0.0459],\n",
      "        [ 0.0216],\n",
      "        [ 0.1995],\n",
      "        [-0.0495],\n",
      "        [ 0.1277],\n",
      "        [-0.0535],\n",
      "        [-0.0426],\n",
      "        [-0.0938],\n",
      "        [ 0.0283],\n",
      "        [-0.0525],\n",
      "        [-0.0584],\n",
      "        [ 0.0382],\n",
      "        [ 0.0835],\n",
      "        [ 0.0363],\n",
      "        [-0.1242],\n",
      "        [ 0.2544],\n",
      "        [-0.1829],\n",
      "        [ 0.2067],\n",
      "        [ 0.0278],\n",
      "        [ 0.0611],\n",
      "        [-0.1123],\n",
      "        [-0.0398],\n",
      "        [-0.1421],\n",
      "        [ 0.1490],\n",
      "        [-0.0761],\n",
      "        [-0.2486],\n",
      "        [ 0.0662],\n",
      "        [-0.1427],\n",
      "        [-0.0423],\n",
      "        [-0.1042],\n",
      "        [ 0.0082],\n",
      "        [ 0.1954],\n",
      "        [-0.0098],\n",
      "        [-0.0691],\n",
      "        [-0.0991],\n",
      "        [-0.0357],\n",
      "        [ 0.0610],\n",
      "        [-0.1260],\n",
      "        [ 0.0281],\n",
      "        [-0.1012],\n",
      "        [-0.0977],\n",
      "        [-0.0024],\n",
      "        [-0.0953],\n",
      "        [ 0.1132],\n",
      "        [-0.0343],\n",
      "        [ 0.1176],\n",
      "        [ 0.0745],\n",
      "        [-0.1688],\n",
      "        [ 0.0394],\n",
      "        [-0.0161],\n",
      "        [ 0.1912],\n",
      "        [ 0.0105],\n",
      "        [-0.2989],\n",
      "        [-0.1098],\n",
      "        [ 0.0101],\n",
      "        [-0.0427],\n",
      "        [ 0.1688],\n",
      "        [-0.0034],\n",
      "        [-0.1422],\n",
      "        [-0.1134],\n",
      "        [ 0.0763],\n",
      "        [-0.0176],\n",
      "        [-0.0466],\n",
      "        [-0.0147],\n",
      "        [ 0.1515],\n",
      "        [ 0.1368],\n",
      "        [-0.0672],\n",
      "        [-0.0848],\n",
      "        [ 0.0688],\n",
      "        [ 0.0496],\n",
      "        [-0.1586],\n",
      "        [-0.0080],\n",
      "        [ 0.1623],\n",
      "        [ 0.1054],\n",
      "        [-0.1195],\n",
      "        [ 0.1287],\n",
      "        [-0.1423],\n",
      "        [-0.0843],\n",
      "        [-0.1362],\n",
      "        [-0.0705],\n",
      "        [ 0.0331],\n",
      "        [-0.2247],\n",
      "        [ 0.0587],\n",
      "        [ 0.1032],\n",
      "        [ 0.0142],\n",
      "        [-0.0516],\n",
      "        [-0.1659],\n",
      "        [ 0.0073],\n",
      "        [ 0.1867],\n",
      "        [-0.0581],\n",
      "        [ 0.1499],\n",
      "        [-0.0184],\n",
      "        [-0.0625],\n",
      "        [ 0.0140],\n",
      "        [ 0.0201],\n",
      "        [ 0.0906],\n",
      "        [-0.0815]], requires_grad=True))\n",
      "('out_layers_w_mean.1', Parameter containing:\n",
      "tensor([[-0.1903],\n",
      "        [ 0.0262],\n",
      "        [-0.0187],\n",
      "        [ 0.0391],\n",
      "        [-0.0975],\n",
      "        [ 0.1049],\n",
      "        [-0.0994],\n",
      "        [ 0.0796],\n",
      "        [ 0.1510],\n",
      "        [-0.2374],\n",
      "        [ 0.1518],\n",
      "        [ 0.1402],\n",
      "        [ 0.1292],\n",
      "        [ 0.0045],\n",
      "        [ 0.0320],\n",
      "        [-0.0529],\n",
      "        [-0.1723],\n",
      "        [-0.0487],\n",
      "        [-0.0101],\n",
      "        [-0.1039],\n",
      "        [ 0.0980],\n",
      "        [-0.0898],\n",
      "        [ 0.0149],\n",
      "        [-0.2111],\n",
      "        [-0.2005],\n",
      "        [-0.0352],\n",
      "        [-0.0243],\n",
      "        [ 0.0324],\n",
      "        [ 0.1276],\n",
      "        [-0.0008],\n",
      "        [-0.0485],\n",
      "        [ 0.0467],\n",
      "        [-0.1710],\n",
      "        [-0.0421],\n",
      "        [ 0.1007],\n",
      "        [-0.0359],\n",
      "        [ 0.0170],\n",
      "        [-0.0017],\n",
      "        [ 0.0028],\n",
      "        [ 0.1358],\n",
      "        [ 0.1168],\n",
      "        [ 0.0400],\n",
      "        [-0.1053],\n",
      "        [ 0.1915],\n",
      "        [-0.0676],\n",
      "        [-0.1115],\n",
      "        [ 0.0798],\n",
      "        [-0.1054],\n",
      "        [-0.0671],\n",
      "        [ 0.1163],\n",
      "        [-0.0285],\n",
      "        [ 0.0332],\n",
      "        [ 0.0678],\n",
      "        [-0.1401],\n",
      "        [-0.0023],\n",
      "        [ 0.1802],\n",
      "        [-0.0314],\n",
      "        [ 0.1172],\n",
      "        [ 0.0535],\n",
      "        [ 0.0785],\n",
      "        [-0.0885],\n",
      "        [ 0.1050],\n",
      "        [ 0.1351],\n",
      "        [-0.0167],\n",
      "        [ 0.1122],\n",
      "        [-0.0486],\n",
      "        [ 0.0296],\n",
      "        [ 0.1171],\n",
      "        [-0.1351],\n",
      "        [-0.0918],\n",
      "        [-0.0133],\n",
      "        [-0.0442],\n",
      "        [ 0.1277],\n",
      "        [ 0.0197],\n",
      "        [ 0.1515],\n",
      "        [-0.1221],\n",
      "        [-0.0461],\n",
      "        [-0.0314],\n",
      "        [-0.1424],\n",
      "        [ 0.1186],\n",
      "        [ 0.0110],\n",
      "        [ 0.1450],\n",
      "        [-0.0545],\n",
      "        [ 0.1462],\n",
      "        [-0.1460],\n",
      "        [ 0.0074],\n",
      "        [-0.1978],\n",
      "        [-0.0649],\n",
      "        [-0.2025],\n",
      "        [-0.0720],\n",
      "        [ 0.0533],\n",
      "        [-0.1790],\n",
      "        [ 0.1728],\n",
      "        [ 0.0539],\n",
      "        [-0.1613],\n",
      "        [ 0.1614],\n",
      "        [-0.0549],\n",
      "        [ 0.2185],\n",
      "        [ 0.1172],\n",
      "        [-0.1163],\n",
      "        [ 0.0862],\n",
      "        [ 0.0622],\n",
      "        [ 0.0773],\n",
      "        [-0.0410],\n",
      "        [-0.1419],\n",
      "        [ 0.0584],\n",
      "        [-0.1348],\n",
      "        [ 0.0312],\n",
      "        [-0.0038],\n",
      "        [ 0.2127],\n",
      "        [ 0.1029],\n",
      "        [ 0.0215],\n",
      "        [ 0.1136],\n",
      "        [ 0.0414],\n",
      "        [ 0.0475],\n",
      "        [ 0.0827],\n",
      "        [-0.1627],\n",
      "        [-0.0519],\n",
      "        [ 0.1619],\n",
      "        [-0.2396],\n",
      "        [-0.0534],\n",
      "        [-0.0651],\n",
      "        [ 0.0792],\n",
      "        [-0.0251],\n",
      "        [ 0.1267],\n",
      "        [ 0.0574],\n",
      "        [ 0.2329],\n",
      "        [-0.0465],\n",
      "        [-0.0632],\n",
      "        [-0.0525],\n",
      "        [-0.1053],\n",
      "        [-0.0538],\n",
      "        [-0.0968],\n",
      "        [ 0.1452],\n",
      "        [ 0.0578],\n",
      "        [ 0.0832],\n",
      "        [-0.1313],\n",
      "        [ 0.0547],\n",
      "        [-0.1050],\n",
      "        [ 0.0265],\n",
      "        [ 0.0327],\n",
      "        [ 0.0266],\n",
      "        [-0.1569],\n",
      "        [-0.1224],\n",
      "        [ 0.1686],\n",
      "        [-0.1877],\n",
      "        [ 0.0422],\n",
      "        [-0.0204],\n",
      "        [ 0.0697],\n",
      "        [-0.1029],\n",
      "        [ 0.0396],\n",
      "        [-0.0398],\n",
      "        [-0.0204],\n",
      "        [ 0.1085],\n",
      "        [-0.1440],\n",
      "        [-0.0699],\n",
      "        [ 0.0198],\n",
      "        [ 0.2530],\n",
      "        [-0.1037],\n",
      "        [-0.0459],\n",
      "        [ 0.0216],\n",
      "        [ 0.1995],\n",
      "        [-0.0495],\n",
      "        [ 0.1277],\n",
      "        [-0.0535],\n",
      "        [-0.0426],\n",
      "        [-0.0938],\n",
      "        [ 0.0283],\n",
      "        [-0.0525],\n",
      "        [-0.0584],\n",
      "        [ 0.0382],\n",
      "        [ 0.0835],\n",
      "        [ 0.0363],\n",
      "        [-0.1242],\n",
      "        [ 0.2544],\n",
      "        [-0.1829],\n",
      "        [ 0.2067],\n",
      "        [ 0.0278],\n",
      "        [ 0.0611],\n",
      "        [-0.1123],\n",
      "        [-0.0398],\n",
      "        [-0.1421],\n",
      "        [ 0.1490],\n",
      "        [-0.0761],\n",
      "        [-0.2486],\n",
      "        [ 0.0662],\n",
      "        [-0.1427],\n",
      "        [-0.0423],\n",
      "        [-0.1042],\n",
      "        [ 0.0082],\n",
      "        [ 0.1954],\n",
      "        [-0.0098],\n",
      "        [-0.0691],\n",
      "        [-0.0991],\n",
      "        [-0.0357],\n",
      "        [ 0.0610],\n",
      "        [-0.1260],\n",
      "        [ 0.0281],\n",
      "        [-0.1012],\n",
      "        [-0.0977],\n",
      "        [-0.0024],\n",
      "        [-0.0953],\n",
      "        [ 0.1132],\n",
      "        [-0.0343],\n",
      "        [ 0.1176],\n",
      "        [ 0.0745],\n",
      "        [-0.1688],\n",
      "        [ 0.0394],\n",
      "        [-0.0161],\n",
      "        [ 0.1912],\n",
      "        [ 0.0105],\n",
      "        [-0.2989],\n",
      "        [-0.1098],\n",
      "        [ 0.0101],\n",
      "        [-0.0427],\n",
      "        [ 0.1688],\n",
      "        [-0.0034],\n",
      "        [-0.1422],\n",
      "        [-0.1134],\n",
      "        [ 0.0763],\n",
      "        [-0.0176],\n",
      "        [-0.0466],\n",
      "        [-0.0147],\n",
      "        [ 0.1515],\n",
      "        [ 0.1368],\n",
      "        [-0.0672],\n",
      "        [-0.0848],\n",
      "        [ 0.0688],\n",
      "        [ 0.0496],\n",
      "        [-0.1586],\n",
      "        [-0.0080],\n",
      "        [ 0.1623],\n",
      "        [ 0.1054],\n",
      "        [-0.1195],\n",
      "        [ 0.1287],\n",
      "        [-0.1423],\n",
      "        [-0.0843],\n",
      "        [-0.1362],\n",
      "        [-0.0705],\n",
      "        [ 0.0331],\n",
      "        [-0.2247],\n",
      "        [ 0.0587],\n",
      "        [ 0.1032],\n",
      "        [ 0.0142],\n",
      "        [-0.0516],\n",
      "        [-0.1659],\n",
      "        [ 0.0073],\n",
      "        [ 0.1867],\n",
      "        [-0.0581],\n",
      "        [ 0.1499],\n",
      "        [-0.0184],\n",
      "        [-0.0625],\n",
      "        [ 0.0140],\n",
      "        [ 0.0201],\n",
      "        [ 0.0906],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-0.0815]], requires_grad=True))\n",
      "('out_layers_w_mean.2', Parameter containing:\n",
      "tensor([[-0.1903],\n",
      "        [ 0.0262],\n",
      "        [-0.0187],\n",
      "        [ 0.0391],\n",
      "        [-0.0975],\n",
      "        [ 0.1049],\n",
      "        [-0.0994],\n",
      "        [ 0.0796],\n",
      "        [ 0.1510],\n",
      "        [-0.2374],\n",
      "        [ 0.1518],\n",
      "        [ 0.1402],\n",
      "        [ 0.1292],\n",
      "        [ 0.0045],\n",
      "        [ 0.0320],\n",
      "        [-0.0529],\n",
      "        [-0.1723],\n",
      "        [-0.0487],\n",
      "        [-0.0101],\n",
      "        [-0.1039],\n",
      "        [ 0.0980],\n",
      "        [-0.0898],\n",
      "        [ 0.0149],\n",
      "        [-0.2111],\n",
      "        [-0.2005],\n",
      "        [-0.0352],\n",
      "        [-0.0243],\n",
      "        [ 0.0324],\n",
      "        [ 0.1276],\n",
      "        [-0.0008],\n",
      "        [-0.0485],\n",
      "        [ 0.0467],\n",
      "        [-0.1710],\n",
      "        [-0.0421],\n",
      "        [ 0.1007],\n",
      "        [-0.0359],\n",
      "        [ 0.0170],\n",
      "        [-0.0017],\n",
      "        [ 0.0028],\n",
      "        [ 0.1358],\n",
      "        [ 0.1168],\n",
      "        [ 0.0400],\n",
      "        [-0.1053],\n",
      "        [ 0.1915],\n",
      "        [-0.0676],\n",
      "        [-0.1115],\n",
      "        [ 0.0798],\n",
      "        [-0.1054],\n",
      "        [-0.0671],\n",
      "        [ 0.1163],\n",
      "        [-0.0285],\n",
      "        [ 0.0332],\n",
      "        [ 0.0678],\n",
      "        [-0.1401],\n",
      "        [-0.0023],\n",
      "        [ 0.1802],\n",
      "        [-0.0314],\n",
      "        [ 0.1172],\n",
      "        [ 0.0535],\n",
      "        [ 0.0785],\n",
      "        [-0.0885],\n",
      "        [ 0.1050],\n",
      "        [ 0.1351],\n",
      "        [-0.0167],\n",
      "        [ 0.1122],\n",
      "        [-0.0486],\n",
      "        [ 0.0296],\n",
      "        [ 0.1171],\n",
      "        [-0.1351],\n",
      "        [-0.0918],\n",
      "        [-0.0133],\n",
      "        [-0.0442],\n",
      "        [ 0.1277],\n",
      "        [ 0.0197],\n",
      "        [ 0.1515],\n",
      "        [-0.1221],\n",
      "        [-0.0461],\n",
      "        [-0.0314],\n",
      "        [-0.1424],\n",
      "        [ 0.1186],\n",
      "        [ 0.0110],\n",
      "        [ 0.1450],\n",
      "        [-0.0545],\n",
      "        [ 0.1462],\n",
      "        [-0.1460],\n",
      "        [ 0.0074],\n",
      "        [-0.1978],\n",
      "        [-0.0649],\n",
      "        [-0.2025],\n",
      "        [-0.0720],\n",
      "        [ 0.0533],\n",
      "        [-0.1790],\n",
      "        [ 0.1728],\n",
      "        [ 0.0539],\n",
      "        [-0.1613],\n",
      "        [ 0.1614],\n",
      "        [-0.0549],\n",
      "        [ 0.2185],\n",
      "        [ 0.1172],\n",
      "        [-0.1163],\n",
      "        [ 0.0862],\n",
      "        [ 0.0622],\n",
      "        [ 0.0773],\n",
      "        [-0.0410],\n",
      "        [-0.1419],\n",
      "        [ 0.0584],\n",
      "        [-0.1348],\n",
      "        [ 0.0312],\n",
      "        [-0.0038],\n",
      "        [ 0.2127],\n",
      "        [ 0.1029],\n",
      "        [ 0.0215],\n",
      "        [ 0.1136],\n",
      "        [ 0.0414],\n",
      "        [ 0.0475],\n",
      "        [ 0.0827],\n",
      "        [-0.1627],\n",
      "        [-0.0519],\n",
      "        [ 0.1619],\n",
      "        [-0.2396],\n",
      "        [-0.0534],\n",
      "        [-0.0651],\n",
      "        [ 0.0792],\n",
      "        [-0.0251],\n",
      "        [ 0.1267],\n",
      "        [ 0.0574],\n",
      "        [ 0.2329],\n",
      "        [-0.0465],\n",
      "        [-0.0632],\n",
      "        [-0.0525],\n",
      "        [-0.1053],\n",
      "        [-0.0538],\n",
      "        [-0.0968],\n",
      "        [ 0.1452],\n",
      "        [ 0.0578],\n",
      "        [ 0.0832],\n",
      "        [-0.1313],\n",
      "        [ 0.0547],\n",
      "        [-0.1050],\n",
      "        [ 0.0265],\n",
      "        [ 0.0327],\n",
      "        [ 0.0266],\n",
      "        [-0.1569],\n",
      "        [-0.1224],\n",
      "        [ 0.1686],\n",
      "        [-0.1877],\n",
      "        [ 0.0422],\n",
      "        [-0.0204],\n",
      "        [ 0.0697],\n",
      "        [-0.1029],\n",
      "        [ 0.0396],\n",
      "        [-0.0398],\n",
      "        [-0.0204],\n",
      "        [ 0.1085],\n",
      "        [-0.1440],\n",
      "        [-0.0699],\n",
      "        [ 0.0198],\n",
      "        [ 0.2530],\n",
      "        [-0.1037],\n",
      "        [-0.0459],\n",
      "        [ 0.0216],\n",
      "        [ 0.1995],\n",
      "        [-0.0495],\n",
      "        [ 0.1277],\n",
      "        [-0.0535],\n",
      "        [-0.0426],\n",
      "        [-0.0938],\n",
      "        [ 0.0283],\n",
      "        [-0.0525],\n",
      "        [-0.0584],\n",
      "        [ 0.0382],\n",
      "        [ 0.0835],\n",
      "        [ 0.0363],\n",
      "        [-0.1242],\n",
      "        [ 0.2544],\n",
      "        [-0.1829],\n",
      "        [ 0.2067],\n",
      "        [ 0.0278],\n",
      "        [ 0.0611],\n",
      "        [-0.1123],\n",
      "        [-0.0398],\n",
      "        [-0.1421],\n",
      "        [ 0.1490],\n",
      "        [-0.0761],\n",
      "        [-0.2486],\n",
      "        [ 0.0662],\n",
      "        [-0.1427],\n",
      "        [-0.0423],\n",
      "        [-0.1042],\n",
      "        [ 0.0082],\n",
      "        [ 0.1954],\n",
      "        [-0.0098],\n",
      "        [-0.0691],\n",
      "        [-0.0991],\n",
      "        [-0.0357],\n",
      "        [ 0.0610],\n",
      "        [-0.1260],\n",
      "        [ 0.0281],\n",
      "        [-0.1012],\n",
      "        [-0.0977],\n",
      "        [-0.0024],\n",
      "        [-0.0953],\n",
      "        [ 0.1132],\n",
      "        [-0.0343],\n",
      "        [ 0.1176],\n",
      "        [ 0.0745],\n",
      "        [-0.1688],\n",
      "        [ 0.0394],\n",
      "        [-0.0161],\n",
      "        [ 0.1912],\n",
      "        [ 0.0105],\n",
      "        [-0.2989],\n",
      "        [-0.1098],\n",
      "        [ 0.0101],\n",
      "        [-0.0427],\n",
      "        [ 0.1688],\n",
      "        [-0.0034],\n",
      "        [-0.1422],\n",
      "        [-0.1134],\n",
      "        [ 0.0763],\n",
      "        [-0.0176],\n",
      "        [-0.0466],\n",
      "        [-0.0147],\n",
      "        [ 0.1515],\n",
      "        [ 0.1368],\n",
      "        [-0.0672],\n",
      "        [-0.0848],\n",
      "        [ 0.0688],\n",
      "        [ 0.0496],\n",
      "        [-0.1586],\n",
      "        [-0.0080],\n",
      "        [ 0.1623],\n",
      "        [ 0.1054],\n",
      "        [-0.1195],\n",
      "        [ 0.1287],\n",
      "        [-0.1423],\n",
      "        [-0.0843],\n",
      "        [-0.1362],\n",
      "        [-0.0705],\n",
      "        [ 0.0331],\n",
      "        [-0.2247],\n",
      "        [ 0.0587],\n",
      "        [ 0.1032],\n",
      "        [ 0.0142],\n",
      "        [-0.0516],\n",
      "        [-0.1659],\n",
      "        [ 0.0073],\n",
      "        [ 0.1867],\n",
      "        [-0.0581],\n",
      "        [ 0.1499],\n",
      "        [-0.0184],\n",
      "        [-0.0625],\n",
      "        [ 0.0140],\n",
      "        [ 0.0201],\n",
      "        [ 0.0906],\n",
      "        [-0.0815]], requires_grad=True))\n",
      "('out_layers_b_mean.0', Parameter containing:\n",
      "tensor([[-0.0843]], requires_grad=True))\n",
      "('out_layers_b_mean.1', Parameter containing:\n",
      "tensor([[-0.0843]], requires_grad=True))\n",
      "('out_layers_b_mean.2', Parameter containing:\n",
      "tensor([[-0.0843]], requires_grad=True))\n",
      "('out_layers_w_var.0', Parameter containing:\n",
      "tensor([[-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-2.]], requires_grad=True))\n",
      "('out_layers_w_var.1', Parameter containing:\n",
      "tensor([[-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.]], requires_grad=True))\n",
      "('out_layers_w_var.2', Parameter containing:\n",
      "tensor([[-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.],\n",
      "        [-2.]], requires_grad=True))\n",
      "('out_layers_b_var.0', Parameter containing:\n",
      "tensor([[-2.]], requires_grad=True))\n",
      "('out_layers_b_var.1', Parameter containing:\n",
      "tensor([[-2.]], requires_grad=True))\n",
      "('out_layers_b_var.2', Parameter containing:\n",
      "tensor([[-2.]], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in net.named_parameters():\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "print(a[slice(1,4)])\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
